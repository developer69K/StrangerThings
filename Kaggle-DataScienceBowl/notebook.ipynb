{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e61ef2d8-f315-4f7f-b07e-1de0f4e8441a",
    "_uuid": "1677fddbb95f7545b6540e9201f3339a0fdbfc5d"
   },
   "source": [
    "# Intro\n",
    "Hello! This rather quick and dirty kernel shows how to get started on segmenting nuclei using a neural network in Keras. \n",
    "\n",
    "The architecture used is the so-called [U-Net](https://arxiv.org/abs/1505.04597), which is very common for image segmentation problems such as this. I believe they also have a tendency to work quite well even on small datasets.\n",
    "\n",
    "Let's get started importing everything we need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sananand\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "c332549b-8d23-4bb5-8497-e7a8eb8b21d2",
    "_uuid": "5c38504af3a84bee68c66d3cde74443c58df422f"
   },
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "#TRAIN_PATH = '../input/stage1_train/'\n",
    "#TEST_PATH = '../input/stage1_test/'\n",
    "\n",
    "TRAIN_PATH = \"C:/Public/ML/Kaggle/DataScienceBowl/stage1_train/\"\n",
    "TEST_PATH = \"C:/Public/ML/Kaggle/DataScienceBowl/stage1_test/\"\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 64\n",
    "random.seed = seed\n",
    "np.random.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "ffa0caf0-2d1b-40f2-865b-8e6db88526b6",
    "_uuid": "3fb9d6530fbbd0e22e41fc4fd9fd9fc0bff027ac"
   },
   "outputs": [],
   "source": [
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00071198d059ba7f5914a526d124d28e6d010c92466da21d4a04cd5413362552 \n",
      " 0114f484a16c152baa2d82fdd43740880a762c93f436c8988ac461c5c9dbe7d5\n"
     ]
    }
   ],
   "source": [
    "print(train_ids[0],'\\n', test_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520, 696, 4) \n",
      "\n",
      "(520, 696, 4) \n",
      "\n",
      "(256, 256, 4) \n",
      "\n",
      "(256, 256, 4) \n",
      "\n",
      "(256, 256, 4) \n",
      "\n",
      "(256, 256, 4) \n",
      "\n",
      "(1024, 1024, 4) \n",
      "\n",
      "(256, 320, 4) \n",
      "\n",
      "(520, 696, 4) \n",
      "\n",
      "(256, 256, 4) \n",
      "\n",
      "(520, 696, 4) \n",
      "\n",
      "(360, 360, 4) \n",
      "\n",
      "(256, 256, 4) \n",
      "\n",
      "(256, 256, 4) \n",
      "\n",
      "(256, 256, 4) \n",
      "\n",
      "(256, 256, 4) \n",
      "\n",
      "(256, 320, 4) \n",
      "\n",
      "(360, 360, 4) \n",
      "\n",
      "(360, 360, 4) \n",
      "\n",
      "(256, 256, 4) \n",
      "\n",
      "(390, 239, 4) \n",
      "\n",
      "(256, 256, 4) \n",
      "\n",
      "(256, 256, 4) \n",
      "\n",
      "(256, 256, 3) \n",
      "\n",
      "(512, 680, 3) \n",
      "\n",
      "(260, 347, 4) \n",
      "\n",
      "(256, 256, 4) \n",
      "\n",
      "(524, 348, 3) \n",
      "\n",
      "(519, 253, 3) \n",
      "\n",
      "(256, 256, 4) \n",
      "\n",
      "(256, 256, 4) \n",
      "\n",
      "(256, 256, 3) \n",
      "\n",
      "(256, 256, 4) \n",
      "\n",
      "(256, 256, 4) \n",
      "\n",
      "(512, 680, 3) \n",
      "\n",
      "(520, 348, 3) \n",
      "\n",
      "(256, 256, 3) \n",
      "\n",
      "(520, 348, 3) \n",
      "\n",
      "(519, 162, 3) \n",
      "\n",
      "(512, 640, 4) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the original image sizes for some of the random images in the training set\n",
    "trainings = [train_ids[random.randint(0,len(train_ids))] for i in range(20)]\n",
    "paths = [TRAIN_PATH+id_+'/images/'+id_+'.png' for id_ in trainings]\n",
    "imsize = [imread(path).shape for path in paths]\n",
    "for size in imsize:\n",
    "    print(size,'\\n') \n",
    "\n",
    "testings = [test_ids[random.randint(0,len(test_ids))] for i in range(20)]\n",
    "paths_t = [TEST_PATH+id_+'/images/'+id_+'.png' for id_ in testings]\n",
    "imsize_t = [imread(path).shape for path in paths_t]\n",
    "for size in imsize_t:\n",
    "    print(size,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "59c4a25d-645f-4b74-9c53-145ac78cc481",
    "_uuid": "875af74f980236825de3a650825b46e25632422c"
   },
   "source": [
    "# Get the data\n",
    "Let's first import all the images and associated masks. I downsample both the training and test images to keep things light and manageable, but we need to keep a record of the original sizes of the test images to upsample our predicted masks and create correct run-length encodings later on. There are definitely better ways to handle this, but it works fine for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "ca0cc34b-c26f-41ee-88d7-975aebdb634e",
    "_uuid": "9e389ba8bdb5b6fc03b231b6a6c84a8bde634053"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing train images and masks ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 670/670 [02:44<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing test images ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 59.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Get and resize train images and masks\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in next(os.walk(path + '/masks/'))[2]:\n",
    "        mask_ = imread(path + '/masks/' + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask\n",
    "\n",
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = imread(path + '/images/' + id_ + '.png')[:,:,:IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ First for the Training iamges Above we get the features(X_train) and the labels (Y_train) , which are the images and the masks respectively\n",
    "+ Second the same has been done for the test images, tests have only the images , there are no masks for the test images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c0523b03-1fc5-4505-a1b8-eb35ee617c8a",
    "_uuid": "d4f8327802a1ec6139ce0585953986272ba62ce1"
   },
   "source": [
    "Let's see if things look all right by drawing some random images and their associated masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "88829b53-50ce-45d9-9540-77dd7384ad4c",
    "_uuid": "283af26f0860b7069bdfd133c746e5d20971542c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sananand\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\skimage\\io\\_plugins\\matplotlib_plugin.py:51: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  out_of_range_float = (np.issubdtype(image.dtype, np.float) and\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUEAAAEYCAYAAADCj0QOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1809c433240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASEAAAEYCAYAAAATaEB+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuQmZWVL/B5DDhzITbzKsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1809f340f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASEAAAEYCAYAAAATaEB+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCQkJlSJNQgkJCZXi/zKSbNJ7PAx5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1809c427c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if training data looks all right\n",
    "ix = random.randint(0, len(train_ids))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()\n",
    "\n",
    "# Test images as well\n",
    "it = random.randint(0, len(test_ids))\n",
    "imshow(X_test[it])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2574ffe9-b911-4bfd-a00f-9ba5c25f45de",
    "_uuid": "938648da705689a0f940ff462477c801db3f0737"
   },
   "source": [
    "Seems good!\n",
    "\n",
    "# Create our Keras metric\n",
    "\n",
    "Now we try to define the *mean average precision at different intersection over union (IoU) thresholds* metric in Keras. TensorFlow has a mean IoU metric, but it doesn't have any native support for the mean over multiple thresholds, so I tried to implement this. **I'm by no means certain that this implementation is correct, though!** Any assistance in verifying this would be most welcome! \n",
    "\n",
    "*Update: This implementation is most definitely not correct due to the very large discrepancy between the results reported here and the LB results. It also seems to just increase over time no matter what when you train ... *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "c1df6f3a-d58f-434b-9216-ef7be38637d4",
    "_uuid": "5abd38950ae99b60f8afec7656eb654a48d449fe"
   },
   "outputs": [],
   "source": [
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.03):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 128, 128, 3)\n",
      "(?, 2048)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_10 (InputLayer)            (None, 128, 128, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)               (None, 128, 128, 3)   0           input_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_755 (Conv2D)              (None, 63, 63, 32)    864         lambda_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_753 (BatchNo (None, 63, 63, 32)    96          conv2d_755[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_753 (Activation)      (None, 63, 63, 32)    0           batch_normalization_753[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_756 (Conv2D)              (None, 61, 61, 32)    9216        activation_753[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_754 (BatchNo (None, 61, 61, 32)    96          conv2d_756[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_754 (Activation)      (None, 61, 61, 32)    0           batch_normalization_754[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_757 (Conv2D)              (None, 61, 61, 64)    18432       activation_754[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_755 (BatchNo (None, 61, 61, 64)    192         conv2d_757[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_755 (Activation)      (None, 61, 61, 64)    0           batch_normalization_755[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling2D)  (None, 30, 30, 64)    0           activation_755[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_758 (Conv2D)              (None, 30, 30, 80)    5120        max_pooling2d_33[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_756 (BatchNo (None, 30, 30, 80)    240         conv2d_758[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_756 (Activation)      (None, 30, 30, 80)    0           batch_normalization_756[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_759 (Conv2D)              (None, 28, 28, 192)   138240      activation_756[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_757 (BatchNo (None, 28, 28, 192)   576         conv2d_759[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_757 (Activation)      (None, 28, 28, 192)   0           batch_normalization_757[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling2D)  (None, 13, 13, 192)   0           activation_757[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_763 (Conv2D)              (None, 13, 13, 64)    12288       max_pooling2d_34[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_761 (BatchNo (None, 13, 13, 64)    192         conv2d_763[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_761 (Activation)      (None, 13, 13, 64)    0           batch_normalization_761[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_761 (Conv2D)              (None, 13, 13, 48)    9216        max_pooling2d_34[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_764 (Conv2D)              (None, 13, 13, 96)    55296       activation_761[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_759 (BatchNo (None, 13, 13, 48)    144         conv2d_761[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_762 (BatchNo (None, 13, 13, 96)    288         conv2d_764[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_759 (Activation)      (None, 13, 13, 48)    0           batch_normalization_759[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_762 (Activation)      (None, 13, 13, 96)    0           batch_normalization_762[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_73 (AveragePoo (None, 13, 13, 192)   0           max_pooling2d_34[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_760 (Conv2D)              (None, 13, 13, 64)    12288       max_pooling2d_34[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_762 (Conv2D)              (None, 13, 13, 64)    76800       activation_759[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_765 (Conv2D)              (None, 13, 13, 96)    82944       activation_762[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_766 (Conv2D)              (None, 13, 13, 32)    6144        average_pooling2d_73[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_758 (BatchNo (None, 13, 13, 64)    192         conv2d_760[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_760 (BatchNo (None, 13, 13, 64)    192         conv2d_762[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_763 (BatchNo (None, 13, 13, 96)    288         conv2d_765[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_764 (BatchNo (None, 13, 13, 32)    96          conv2d_766[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_758 (Activation)      (None, 13, 13, 64)    0           batch_normalization_758[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_760 (Activation)      (None, 13, 13, 64)    0           batch_normalization_760[0][0]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "activation_763 (Activation)      (None, 13, 13, 96)    0           batch_normalization_763[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_764 (Activation)      (None, 13, 13, 32)    0           batch_normalization_764[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)             (None, 13, 13, 256)   0           activation_758[0][0]             \n",
      "                                                                   activation_760[0][0]             \n",
      "                                                                   activation_763[0][0]             \n",
      "                                                                   activation_764[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_770 (Conv2D)              (None, 13, 13, 64)    16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_768 (BatchNo (None, 13, 13, 64)    192         conv2d_770[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_768 (Activation)      (None, 13, 13, 64)    0           batch_normalization_768[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_768 (Conv2D)              (None, 13, 13, 48)    12288       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_771 (Conv2D)              (None, 13, 13, 96)    55296       activation_768[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_766 (BatchNo (None, 13, 13, 48)    144         conv2d_768[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_769 (BatchNo (None, 13, 13, 96)    288         conv2d_771[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_766 (Activation)      (None, 13, 13, 48)    0           batch_normalization_766[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_769 (Activation)      (None, 13, 13, 96)    0           batch_normalization_769[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_74 (AveragePoo (None, 13, 13, 256)   0           mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_767 (Conv2D)              (None, 13, 13, 64)    16384       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_769 (Conv2D)              (None, 13, 13, 64)    76800       activation_766[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_772 (Conv2D)              (None, 13, 13, 96)    82944       activation_769[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_773 (Conv2D)              (None, 13, 13, 64)    16384       average_pooling2d_74[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_765 (BatchNo (None, 13, 13, 64)    192         conv2d_767[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_767 (BatchNo (None, 13, 13, 64)    192         conv2d_769[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_770 (BatchNo (None, 13, 13, 96)    288         conv2d_772[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_771 (BatchNo (None, 13, 13, 64)    192         conv2d_773[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_765 (Activation)      (None, 13, 13, 64)    0           batch_normalization_765[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_767 (Activation)      (None, 13, 13, 64)    0           batch_normalization_767[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_770 (Activation)      (None, 13, 13, 96)    0           batch_normalization_770[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_771 (Activation)      (None, 13, 13, 64)    0           batch_normalization_771[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)             (None, 13, 13, 288)   0           activation_765[0][0]             \n",
      "                                                                   activation_767[0][0]             \n",
      "                                                                   activation_770[0][0]             \n",
      "                                                                   activation_771[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_777 (Conv2D)              (None, 13, 13, 64)    18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_775 (BatchNo (None, 13, 13, 64)    192         conv2d_777[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_775 (Activation)      (None, 13, 13, 64)    0           batch_normalization_775[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_775 (Conv2D)              (None, 13, 13, 48)    13824       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_778 (Conv2D)              (None, 13, 13, 96)    55296       activation_775[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_773 (BatchNo (None, 13, 13, 48)    144         conv2d_775[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_776 (BatchNo (None, 13, 13, 96)    288         conv2d_778[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_773 (Activation)      (None, 13, 13, 48)    0           batch_normalization_773[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_776 (Activation)      (None, 13, 13, 96)    0           batch_normalization_776[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_75 (AveragePoo (None, 13, 13, 288)   0           mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_774 (Conv2D)              (None, 13, 13, 64)    18432       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_776 (Conv2D)              (None, 13, 13, 64)    76800       activation_773[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_779 (Conv2D)              (None, 13, 13, 96)    82944       activation_776[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_780 (Conv2D)              (None, 13, 13, 64)    18432       average_pooling2d_75[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_772 (BatchNo (None, 13, 13, 64)    192         conv2d_774[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_774 (BatchNo (None, 13, 13, 64)    192         conv2d_776[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_777 (BatchNo (None, 13, 13, 96)    288         conv2d_779[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_778 (BatchNo (None, 13, 13, 64)    192         conv2d_780[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_772 (Activation)      (None, 13, 13, 64)    0           batch_normalization_772[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_774 (Activation)      (None, 13, 13, 64)    0           batch_normalization_774[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_777 (Activation)      (None, 13, 13, 96)    0           batch_normalization_777[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_778 (Activation)      (None, 13, 13, 64)    0           batch_normalization_778[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)             (None, 13, 13, 288)   0           activation_772[0][0]             \n",
      "                                                                   activation_774[0][0]             \n",
      "                                                                   activation_777[0][0]             \n",
      "                                                                   activation_778[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_782 (Conv2D)              (None, 13, 13, 64)    18432       mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_780 (BatchNo (None, 13, 13, 64)    192         conv2d_782[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_780 (Activation)      (None, 13, 13, 64)    0           batch_normalization_780[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_783 (Conv2D)              (None, 13, 13, 96)    55296       activation_780[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_781 (BatchNo (None, 13, 13, 96)    288         conv2d_783[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_781 (Activation)      (None, 13, 13, 96)    0           batch_normalization_781[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_781 (Conv2D)              (None, 6, 6, 384)     995328      mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_784 (Conv2D)              (None, 6, 6, 96)      82944       activation_781[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_779 (BatchNo (None, 6, 6, 384)     1152        conv2d_781[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_782 (BatchNo (None, 6, 6, 96)      288         conv2d_784[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_779 (Activation)      (None, 6, 6, 384)     0           batch_normalization_779[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_782 (Activation)      (None, 6, 6, 96)      0           batch_normalization_782[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling2D)  (None, 6, 6, 288)     0           mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)             (None, 6, 6, 768)     0           activation_779[0][0]             \n",
      "                                                                   activation_782[0][0]             \n",
      "                                                                   max_pooling2d_35[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_789 (Conv2D)              (None, 6, 6, 128)     98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_787 (BatchNo (None, 6, 6, 128)     384         conv2d_789[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_787 (Activation)      (None, 6, 6, 128)     0           batch_normalization_787[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_790 (Conv2D)              (None, 6, 6, 128)     114688      activation_787[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_788 (BatchNo (None, 6, 6, 128)     384         conv2d_790[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_788 (Activation)      (None, 6, 6, 128)     0           batch_normalization_788[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_786 (Conv2D)              (None, 6, 6, 128)     98304       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_791 (Conv2D)              (None, 6, 6, 128)     114688      activation_788[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_784 (BatchNo (None, 6, 6, 128)     384         conv2d_786[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_789 (BatchNo (None, 6, 6, 128)     384         conv2d_791[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_784 (Activation)      (None, 6, 6, 128)     0           batch_normalization_784[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_789 (Activation)      (None, 6, 6, 128)     0           batch_normalization_789[0][0]    \n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_787 (Conv2D)              (None, 6, 6, 128)     114688      activation_784[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_792 (Conv2D)              (None, 6, 6, 128)     114688      activation_789[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_785 (BatchNo (None, 6, 6, 128)     384         conv2d_787[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_790 (BatchNo (None, 6, 6, 128)     384         conv2d_792[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_785 (Activation)      (None, 6, 6, 128)     0           batch_normalization_785[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_790 (Activation)      (None, 6, 6, 128)     0           batch_normalization_790[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_76 (AveragePoo (None, 6, 6, 768)     0           mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_785 (Conv2D)              (None, 6, 6, 192)     147456      mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_788 (Conv2D)              (None, 6, 6, 192)     172032      activation_785[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_793 (Conv2D)              (None, 6, 6, 192)     172032      activation_790[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_794 (Conv2D)              (None, 6, 6, 192)     147456      average_pooling2d_76[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_783 (BatchNo (None, 6, 6, 192)     576         conv2d_785[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_786 (BatchNo (None, 6, 6, 192)     576         conv2d_788[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_791 (BatchNo (None, 6, 6, 192)     576         conv2d_793[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_792 (BatchNo (None, 6, 6, 192)     576         conv2d_794[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_783 (Activation)      (None, 6, 6, 192)     0           batch_normalization_783[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_786 (Activation)      (None, 6, 6, 192)     0           batch_normalization_786[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_791 (Activation)      (None, 6, 6, 192)     0           batch_normalization_791[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_792 (Activation)      (None, 6, 6, 192)     0           batch_normalization_792[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)             (None, 6, 6, 768)     0           activation_783[0][0]             \n",
      "                                                                   activation_786[0][0]             \n",
      "                                                                   activation_791[0][0]             \n",
      "                                                                   activation_792[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_799 (Conv2D)              (None, 6, 6, 160)     122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_797 (BatchNo (None, 6, 6, 160)     480         conv2d_799[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_797 (Activation)      (None, 6, 6, 160)     0           batch_normalization_797[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_800 (Conv2D)              (None, 6, 6, 160)     179200      activation_797[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_798 (BatchNo (None, 6, 6, 160)     480         conv2d_800[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_798 (Activation)      (None, 6, 6, 160)     0           batch_normalization_798[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_796 (Conv2D)              (None, 6, 6, 160)     122880      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_801 (Conv2D)              (None, 6, 6, 160)     179200      activation_798[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_794 (BatchNo (None, 6, 6, 160)     480         conv2d_796[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_799 (BatchNo (None, 6, 6, 160)     480         conv2d_801[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_794 (Activation)      (None, 6, 6, 160)     0           batch_normalization_794[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_799 (Activation)      (None, 6, 6, 160)     0           batch_normalization_799[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_797 (Conv2D)              (None, 6, 6, 160)     179200      activation_794[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_802 (Conv2D)              (None, 6, 6, 160)     179200      activation_799[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_795 (BatchNo (None, 6, 6, 160)     480         conv2d_797[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_800 (BatchNo (None, 6, 6, 160)     480         conv2d_802[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_795 (Activation)      (None, 6, 6, 160)     0           batch_normalization_795[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_800 (Activation)      (None, 6, 6, 160)     0           batch_normalization_800[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_77 (AveragePoo (None, 6, 6, 768)     0           mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_795 (Conv2D)              (None, 6, 6, 192)     147456      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_798 (Conv2D)              (None, 6, 6, 192)     215040      activation_795[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_803 (Conv2D)              (None, 6, 6, 192)     215040      activation_800[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_804 (Conv2D)              (None, 6, 6, 192)     147456      average_pooling2d_77[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_793 (BatchNo (None, 6, 6, 192)     576         conv2d_795[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_796 (BatchNo (None, 6, 6, 192)     576         conv2d_798[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_801 (BatchNo (None, 6, 6, 192)     576         conv2d_803[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_802 (BatchNo (None, 6, 6, 192)     576         conv2d_804[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_793 (Activation)      (None, 6, 6, 192)     0           batch_normalization_793[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_796 (Activation)      (None, 6, 6, 192)     0           batch_normalization_796[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_801 (Activation)      (None, 6, 6, 192)     0           batch_normalization_801[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_802 (Activation)      (None, 6, 6, 192)     0           batch_normalization_802[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)             (None, 6, 6, 768)     0           activation_793[0][0]             \n",
      "                                                                   activation_796[0][0]             \n",
      "                                                                   activation_801[0][0]             \n",
      "                                                                   activation_802[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_809 (Conv2D)              (None, 6, 6, 160)     122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_807 (BatchNo (None, 6, 6, 160)     480         conv2d_809[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_807 (Activation)      (None, 6, 6, 160)     0           batch_normalization_807[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_810 (Conv2D)              (None, 6, 6, 160)     179200      activation_807[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_808 (BatchNo (None, 6, 6, 160)     480         conv2d_810[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_808 (Activation)      (None, 6, 6, 160)     0           batch_normalization_808[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_806 (Conv2D)              (None, 6, 6, 160)     122880      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_811 (Conv2D)              (None, 6, 6, 160)     179200      activation_808[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_804 (BatchNo (None, 6, 6, 160)     480         conv2d_806[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_809 (BatchNo (None, 6, 6, 160)     480         conv2d_811[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_804 (Activation)      (None, 6, 6, 160)     0           batch_normalization_804[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_809 (Activation)      (None, 6, 6, 160)     0           batch_normalization_809[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_807 (Conv2D)              (None, 6, 6, 160)     179200      activation_804[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_812 (Conv2D)              (None, 6, 6, 160)     179200      activation_809[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_805 (BatchNo (None, 6, 6, 160)     480         conv2d_807[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_810 (BatchNo (None, 6, 6, 160)     480         conv2d_812[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_805 (Activation)      (None, 6, 6, 160)     0           batch_normalization_805[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_810 (Activation)      (None, 6, 6, 160)     0           batch_normalization_810[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_78 (AveragePoo (None, 6, 6, 768)     0           mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_805 (Conv2D)              (None, 6, 6, 192)     147456      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_808 (Conv2D)              (None, 6, 6, 192)     215040      activation_805[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_813 (Conv2D)              (None, 6, 6, 192)     215040      activation_810[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_814 (Conv2D)              (None, 6, 6, 192)     147456      average_pooling2d_78[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_803 (BatchNo (None, 6, 6, 192)     576         conv2d_805[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_806 (BatchNo (None, 6, 6, 192)     576         conv2d_808[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_811 (BatchNo (None, 6, 6, 192)     576         conv2d_813[0][0]                 \n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_812 (BatchNo (None, 6, 6, 192)     576         conv2d_814[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_803 (Activation)      (None, 6, 6, 192)     0           batch_normalization_803[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_806 (Activation)      (None, 6, 6, 192)     0           batch_normalization_806[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_811 (Activation)      (None, 6, 6, 192)     0           batch_normalization_811[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_812 (Activation)      (None, 6, 6, 192)     0           batch_normalization_812[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)             (None, 6, 6, 768)     0           activation_803[0][0]             \n",
      "                                                                   activation_806[0][0]             \n",
      "                                                                   activation_811[0][0]             \n",
      "                                                                   activation_812[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_819 (Conv2D)              (None, 6, 6, 192)     147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_817 (BatchNo (None, 6, 6, 192)     576         conv2d_819[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_817 (Activation)      (None, 6, 6, 192)     0           batch_normalization_817[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_820 (Conv2D)              (None, 6, 6, 192)     258048      activation_817[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_818 (BatchNo (None, 6, 6, 192)     576         conv2d_820[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_818 (Activation)      (None, 6, 6, 192)     0           batch_normalization_818[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_816 (Conv2D)              (None, 6, 6, 192)     147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_821 (Conv2D)              (None, 6, 6, 192)     258048      activation_818[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_814 (BatchNo (None, 6, 6, 192)     576         conv2d_816[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_819 (BatchNo (None, 6, 6, 192)     576         conv2d_821[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_814 (Activation)      (None, 6, 6, 192)     0           batch_normalization_814[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_819 (Activation)      (None, 6, 6, 192)     0           batch_normalization_819[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_817 (Conv2D)              (None, 6, 6, 192)     258048      activation_814[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_822 (Conv2D)              (None, 6, 6, 192)     258048      activation_819[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_815 (BatchNo (None, 6, 6, 192)     576         conv2d_817[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_820 (BatchNo (None, 6, 6, 192)     576         conv2d_822[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_815 (Activation)      (None, 6, 6, 192)     0           batch_normalization_815[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_820 (Activation)      (None, 6, 6, 192)     0           batch_normalization_820[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_79 (AveragePoo (None, 6, 6, 768)     0           mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_815 (Conv2D)              (None, 6, 6, 192)     147456      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_818 (Conv2D)              (None, 6, 6, 192)     258048      activation_815[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_823 (Conv2D)              (None, 6, 6, 192)     258048      activation_820[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_824 (Conv2D)              (None, 6, 6, 192)     147456      average_pooling2d_79[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_813 (BatchNo (None, 6, 6, 192)     576         conv2d_815[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_816 (BatchNo (None, 6, 6, 192)     576         conv2d_818[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_821 (BatchNo (None, 6, 6, 192)     576         conv2d_823[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_822 (BatchNo (None, 6, 6, 192)     576         conv2d_824[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_813 (Activation)      (None, 6, 6, 192)     0           batch_normalization_813[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_816 (Activation)      (None, 6, 6, 192)     0           batch_normalization_816[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_821 (Activation)      (None, 6, 6, 192)     0           batch_normalization_821[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_822 (Activation)      (None, 6, 6, 192)     0           batch_normalization_822[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)             (None, 6, 6, 768)     0           activation_813[0][0]             \n",
      "                                                                   activation_816[0][0]             \n",
      "                                                                   activation_821[0][0]             \n",
      "                                                                   activation_822[0][0]             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "conv2d_827 (Conv2D)              (None, 6, 6, 192)     147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_825 (BatchNo (None, 6, 6, 192)     576         conv2d_827[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_825 (Activation)      (None, 6, 6, 192)     0           batch_normalization_825[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_828 (Conv2D)              (None, 6, 6, 192)     258048      activation_825[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_826 (BatchNo (None, 6, 6, 192)     576         conv2d_828[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_826 (Activation)      (None, 6, 6, 192)     0           batch_normalization_826[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_825 (Conv2D)              (None, 6, 6, 192)     147456      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_829 (Conv2D)              (None, 6, 6, 192)     258048      activation_826[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_823 (BatchNo (None, 6, 6, 192)     576         conv2d_825[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_827 (BatchNo (None, 6, 6, 192)     576         conv2d_829[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_823 (Activation)      (None, 6, 6, 192)     0           batch_normalization_823[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_827 (Activation)      (None, 6, 6, 192)     0           batch_normalization_827[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_826 (Conv2D)              (None, 2, 2, 320)     552960      activation_823[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_830 (Conv2D)              (None, 2, 2, 192)     331776      activation_827[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_824 (BatchNo (None, 2, 2, 320)     960         conv2d_826[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_828 (BatchNo (None, 2, 2, 192)     576         conv2d_830[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_824 (Activation)      (None, 2, 2, 320)     0           batch_normalization_824[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_828 (Activation)      (None, 2, 2, 192)     0           batch_normalization_828[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling2D)  (None, 2, 2, 768)     0           mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)             (None, 2, 2, 1280)    0           activation_824[0][0]             \n",
      "                                                                   activation_828[0][0]             \n",
      "                                                                   max_pooling2d_36[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_835 (Conv2D)              (None, 2, 2, 448)     573440      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_833 (BatchNo (None, 2, 2, 448)     1344        conv2d_835[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_833 (Activation)      (None, 2, 2, 448)     0           batch_normalization_833[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_832 (Conv2D)              (None, 2, 2, 384)     491520      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_836 (Conv2D)              (None, 2, 2, 384)     1548288     activation_833[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_830 (BatchNo (None, 2, 2, 384)     1152        conv2d_832[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_834 (BatchNo (None, 2, 2, 384)     1152        conv2d_836[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_830 (Activation)      (None, 2, 2, 384)     0           batch_normalization_830[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_834 (Activation)      (None, 2, 2, 384)     0           batch_normalization_834[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_833 (Conv2D)              (None, 2, 2, 384)     442368      activation_830[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_834 (Conv2D)              (None, 2, 2, 384)     442368      activation_830[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_837 (Conv2D)              (None, 2, 2, 384)     442368      activation_834[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_838 (Conv2D)              (None, 2, 2, 384)     442368      activation_834[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_80 (AveragePoo (None, 2, 2, 1280)    0           mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_831 (Conv2D)              (None, 2, 2, 320)     409600      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_831 (BatchNo (None, 2, 2, 384)     1152        conv2d_833[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_832 (BatchNo (None, 2, 2, 384)     1152        conv2d_834[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_835 (BatchNo (None, 2, 2, 384)     1152        conv2d_837[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_836 (BatchNo (None, 2, 2, 384)     1152        conv2d_838[0][0]                 \n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_839 (Conv2D)              (None, 2, 2, 192)     245760      average_pooling2d_80[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_829 (BatchNo (None, 2, 2, 320)     960         conv2d_831[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_831 (Activation)      (None, 2, 2, 384)     0           batch_normalization_831[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_832 (Activation)      (None, 2, 2, 384)     0           batch_normalization_832[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_835 (Activation)      (None, 2, 2, 384)     0           batch_normalization_835[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_836 (Activation)      (None, 2, 2, 384)     0           batch_normalization_836[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_837 (BatchNo (None, 2, 2, 192)     576         conv2d_839[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_829 (Activation)      (None, 2, 2, 320)     0           batch_normalization_829[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)           (None, 2, 2, 768)     0           activation_831[0][0]             \n",
      "                                                                   activation_832[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)     (None, 2, 2, 768)     0           activation_835[0][0]             \n",
      "                                                                   activation_836[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_837 (Activation)      (None, 2, 2, 192)     0           batch_normalization_837[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)             (None, 2, 2, 2048)    0           activation_829[0][0]             \n",
      "                                                                   mixed9_0[0][0]                   \n",
      "                                                                   concatenate_17[0][0]             \n",
      "                                                                   activation_837[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_844 (Conv2D)              (None, 2, 2, 448)     917504      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_842 (BatchNo (None, 2, 2, 448)     1344        conv2d_844[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_842 (Activation)      (None, 2, 2, 448)     0           batch_normalization_842[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_841 (Conv2D)              (None, 2, 2, 384)     786432      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_845 (Conv2D)              (None, 2, 2, 384)     1548288     activation_842[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_839 (BatchNo (None, 2, 2, 384)     1152        conv2d_841[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_843 (BatchNo (None, 2, 2, 384)     1152        conv2d_845[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_839 (Activation)      (None, 2, 2, 384)     0           batch_normalization_839[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_843 (Activation)      (None, 2, 2, 384)     0           batch_normalization_843[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_842 (Conv2D)              (None, 2, 2, 384)     442368      activation_839[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_843 (Conv2D)              (None, 2, 2, 384)     442368      activation_839[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_846 (Conv2D)              (None, 2, 2, 384)     442368      activation_843[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_847 (Conv2D)              (None, 2, 2, 384)     442368      activation_843[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "average_pooling2d_81 (AveragePoo (None, 2, 2, 2048)    0           mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_840 (Conv2D)              (None, 2, 2, 320)     655360      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_840 (BatchNo (None, 2, 2, 384)     1152        conv2d_842[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_841 (BatchNo (None, 2, 2, 384)     1152        conv2d_843[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_844 (BatchNo (None, 2, 2, 384)     1152        conv2d_846[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_845 (BatchNo (None, 2, 2, 384)     1152        conv2d_847[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_848 (Conv2D)              (None, 2, 2, 192)     393216      average_pooling2d_81[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_838 (BatchNo (None, 2, 2, 320)     960         conv2d_840[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "activation_840 (Activation)      (None, 2, 2, 384)     0           batch_normalization_840[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_841 (Activation)      (None, 2, 2, 384)     0           batch_normalization_841[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_844 (Activation)      (None, 2, 2, 384)     0           batch_normalization_844[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "activation_845 (Activation)      (None, 2, 2, 384)     0           batch_normalization_845[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_846 (BatchNo (None, 2, 2, 192)     576         conv2d_848[0][0]                 \n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_838 (Activation)      (None, 2, 2, 320)     0           batch_normalization_838[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)           (None, 2, 2, 768)     0           activation_840[0][0]             \n",
      "                                                                   activation_841[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)     (None, 2, 2, 768)     0           activation_844[0][0]             \n",
      "                                                                   activation_845[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "activation_846 (Activation)      (None, 2, 2, 192)     0           batch_normalization_846[0][0]    \n",
      "____________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)            (None, 2, 2, 2048)    0           activation_838[0][0]             \n",
      "                                                                   mixed9_1[0][0]                   \n",
      "                                                                   concatenate_18[0][0]             \n",
      "                                                                   activation_846[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glob (None, 2048)          0           mixed10[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 1024)          2098176     global_average_pooling2d_5[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 1)             1025        dense_6[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 23,901,985\n",
      "Trainable params: 23,867,553\n",
      "Non-trainable params: 34,432\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# add a inception model here\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "# Build keras over a custom input tensor\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = Lambda(lambda x: x / 255) (inputs) #Normalization \n",
    "print(s.shape)\n",
    "base_model = InceptionV3(input_tensor = s, weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "#print(x.shape)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "print(x.shape)\n",
    "#Full connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "outputs = Dense(1, activation='sigmoid') (x)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "NormalizeInput (BatchNormali (None, 128, 128, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_856 (Conv2D)          (None, 128, 128, 8)       224       \n",
      "_________________________________________________________________\n",
      "conv2d_857 (Conv2D)          (None, 128, 128, 8)       584       \n",
      "_________________________________________________________________\n",
      "conv2d_858 (Conv2D)          (None, 128, 128, 16)      1168      \n",
      "_________________________________________________________________\n",
      "conv2d_859 (Conv2D)          (None, 128, 128, 16)      2320      \n",
      "_________________________________________________________________\n",
      "conv2d_860 (Conv2D)          (None, 128, 128, 32)      4640      \n",
      "_________________________________________________________________\n",
      "conv2d_861 (Conv2D)          (None, 128, 128, 16)      528       \n",
      "_________________________________________________________________\n",
      "conv2d_862 (Conv2D)          (None, 128, 128, 1)       17        \n",
      "=================================================================\n",
      "Total params: 9,493\n",
      "Trainable params: 9,487\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Changed to have upconversion with Inceptionv3\n",
    "# add a inception model here\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Conv2D, UpSampling2D, Lambda \n",
    "from keras import backend as K\n",
    "\n",
    "simple_cnn= Sequential()\n",
    "simple_cnn.add(BatchNormalization(input_shape = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), name='NormalizeInput'))\n",
    "simple_cnn.add(Conv2D(8, kernel_size=(3,3), padding='same'))\n",
    "simple_cnn.add(Conv2D(8, kernel_size=(3,3), padding='same'))\n",
    "\n",
    "simple_cnn.add(Conv2D(16, kernel_size=(3,3), dilation_rate=2, padding='same'))\n",
    "simple_cnn.add(Conv2D(16, kernel_size=(3,3), dilation_rate=2, padding='same'))\n",
    "simple_cnn.add(Conv2D(32, kernel_size=(3,3), dilation_rate=2, padding='same'))\n",
    "\n",
    "simple_cnn.add(Conv2D(16, kernel_size = (1,1), padding = 'same'))\n",
    "simple_cnn.add(Conv2D(1, kernel_size = (1,1), padding = 'same', activation = 'sigmoid'))\n",
    "simple_cnn.summary()\n",
    "\n",
    "\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = Lambda(lambda x: x / 255) (inputs) #Normalization \n",
    "encoded_images = simple_cnn(s)\n",
    "outputs = Dense(1, activation='sigmoid') (encoded_images)\n",
    "\n",
    "cnnmodel = Model(inputs=[inputs], outputs=[outputs])\n",
    "cnnmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 603 samples, validate on 67 samples\n",
      "Epoch 1/100\n",
      "592/603 [============================>.] - ETA: 165s - loss: 0.8046 - mean_iou: 0.0000e+ - ETA: 108s - loss: 0.8081 - mean_iou: 0.1849   - ETA: 88s - loss: 0.8022 - mean_iou: 0.2503 - ETA: 78s - loss: 0.7922 - mean_iou: 0.281 - ETA: 72s - loss: 0.7874 - mean_iou: 0.301 - ETA: 67s - loss: 0.7863 - mean_iou: 0.315 - ETA: 63s - loss: 0.7769 - mean_iou: 0.325 - ETA: 60s - loss: 0.7718 - mean_iou: 0.332 - ETA: 57s - loss: 0.7671 - mean_iou: 0.339 - ETA: 54s - loss: 0.7636 - mean_iou: 0.345 - ETA: 51s - loss: 0.7602 - mean_iou: 0.350 - ETA: 49s - loss: 0.7569 - mean_iou: 0.355 - ETA: 47s - loss: 0.7554 - mean_iou: 0.359 - ETA: 44s - loss: 0.7512 - mean_iou: 0.362 - ETA: 42s - loss: 0.7487 - mean_iou: 0.365 - ETA: 40s - loss: 0.7459 - mean_iou: 0.368 - ETA: 38s - loss: 0.7462 - mean_iou: 0.371 - ETA: 36s - loss: 0.7449 - mean_iou: 0.374 - ETA: 34s - loss: 0.7430 - mean_iou: 0.376 - ETA: 32s - loss: 0.7409 - mean_iou: 0.378 - ETA: 31s - loss: 0.7388 - mean_iou: 0.380 - ETA: 29s - loss: 0.7367 - mean_iou: 0.382 - ETA: 27s - loss: 0.7378 - mean_iou: 0.384 - ETA: 25s - loss: 0.7375 - mean_iou: 0.386 - ETA: 23s - loss: 0.7372 - mean_iou: 0.387 - ETA: 21s - loss: 0.7387 - mean_iou: 0.389 - ETA: 19s - loss: 0.7381 - mean_iou: 0.390 - ETA: 17s - loss: 0.7383 - mean_iou: 0.391 - ETA: 15s - loss: 0.7377 - mean_iou: 0.393 - ETA: 13s - loss: 0.7367 - mean_iou: 0.394 - ETA: 11s - loss: 0.7365 - mean_iou: 0.395 - ETA: 10s - loss: 0.7358 - mean_iou: 0.396 - ETA: 8s - loss: 0.7357 - mean_iou: 0.396 - ETA: 6s - loss: 0.7346 - mean_iou: 0.39 - ETA: 4s - loss: 0.7338 - mean_iou: 0.39 - ETA: 2s - loss: 0.7329 - mean_iou: 0.39 - ETA: 1s - loss: 0.7323 - mean_iou: 0.3999Epoch 00000: val_loss improved from inf to 0.69625, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 71s - loss: 0.7324 - mean_iou: 0.4004 - val_loss: 0.6963 - val_mean_iou: 0.4271\n",
      "Epoch 2/100\n",
      "592/603 [============================>.] - ETA: 59s - loss: 0.6936 - mean_iou: 0.429 - ETA: 58s - loss: 0.7021 - mean_iou: 0.429 - ETA: 57s - loss: 0.7093 - mean_iou: 0.429 - ETA: 56s - loss: 0.7189 - mean_iou: 0.429 - ETA: 54s - loss: 0.7102 - mean_iou: 0.429 - ETA: 52s - loss: 0.7210 - mean_iou: 0.429 - ETA: 50s - loss: 0.7203 - mean_iou: 0.429 - ETA: 48s - loss: 0.7154 - mean_iou: 0.429 - ETA: 46s - loss: 0.7142 - mean_iou: 0.429 - ETA: 45s - loss: 0.7156 - mean_iou: 0.429 - ETA: 43s - loss: 0.7142 - mean_iou: 0.429 - ETA: 41s - loss: 0.7129 - mean_iou: 0.429 - ETA: 39s - loss: 0.7127 - mean_iou: 0.429 - ETA: 38s - loss: 0.7122 - mean_iou: 0.429 - ETA: 36s - loss: 0.7125 - mean_iou: 0.429 - ETA: 34s - loss: 0.7128 - mean_iou: 0.429 - ETA: 33s - loss: 0.7123 - mean_iou: 0.430 - ETA: 31s - loss: 0.7132 - mean_iou: 0.430 - ETA: 30s - loss: 0.7117 - mean_iou: 0.430 - ETA: 28s - loss: 0.7118 - mean_iou: 0.430 - ETA: 26s - loss: 0.7114 - mean_iou: 0.430 - ETA: 25s - loss: 0.7124 - mean_iou: 0.430 - ETA: 23s - loss: 0.7110 - mean_iou: 0.430 - ETA: 21s - loss: 0.7110 - mean_iou: 0.430 - ETA: 20s - loss: 0.7108 - mean_iou: 0.430 - ETA: 18s - loss: 0.7110 - mean_iou: 0.430 - ETA: 17s - loss: 0.7109 - mean_iou: 0.430 - ETA: 15s - loss: 0.7100 - mean_iou: 0.430 - ETA: 13s - loss: 0.7101 - mean_iou: 0.430 - ETA: 12s - loss: 0.7102 - mean_iou: 0.430 - ETA: 10s - loss: 0.7087 - mean_iou: 0.430 - ETA: 9s - loss: 0.7072 - mean_iou: 0.430 - ETA: 7s - loss: 0.7066 - mean_iou: 0.43 - ETA: 5s - loss: 0.7062 - mean_iou: 0.43 - ETA: 4s - loss: 0.7053 - mean_iou: 0.43 - ETA: 2s - loss: 0.7042 - mean_iou: 0.43 - ETA: 1s - loss: 0.7040 - mean_iou: 0.4312Epoch 00001: val_loss improved from 0.69625 to 0.67965, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.7038 - mean_iou: 0.4313 - val_loss: 0.6796 - val_mean_iou: 0.4354\n",
      "Epoch 3/100\n",
      "592/603 [============================>.] - ETA: 58s - loss: 0.6715 - mean_iou: 0.436 - ETA: 57s - loss: 0.6776 - mean_iou: 0.436 - ETA: 55s - loss: 0.6962 - mean_iou: 0.436 - ETA: 54s - loss: 0.6951 - mean_iou: 0.436 - ETA: 53s - loss: 0.6916 - mean_iou: 0.436 - ETA: 51s - loss: 0.6840 - mean_iou: 0.436 - ETA: 50s - loss: 0.6930 - mean_iou: 0.436 - ETA: 48s - loss: 0.6959 - mean_iou: 0.436 - ETA: 46s - loss: 0.6950 - mean_iou: 0.436 - ETA: 45s - loss: 0.6905 - mean_iou: 0.436 - ETA: 43s - loss: 0.6885 - mean_iou: 0.436 - ETA: 41s - loss: 0.6871 - mean_iou: 0.436 - ETA: 40s - loss: 0.6875 - mean_iou: 0.437 - ETA: 38s - loss: 0.6889 - mean_iou: 0.437 - ETA: 37s - loss: 0.6899 - mean_iou: 0.437 - ETA: 35s - loss: 0.6896 - mean_iou: 0.437 - ETA: 33s - loss: 0.6906 - mean_iou: 0.437 - ETA: 32s - loss: 0.6899 - mean_iou: 0.437 - ETA: 30s - loss: 0.6894 - mean_iou: 0.437 - ETA: 28s - loss: 0.6885 - mean_iou: 0.437 - ETA: 27s - loss: 0.6879 - mean_iou: 0.437 - ETA: 25s - loss: 0.6895 - mean_iou: 0.437 - ETA: 24s - loss: 0.6894 - mean_iou: 0.437 - ETA: 22s - loss: 0.6886 - mean_iou: 0.437 - ETA: 20s - loss: 0.6889 - mean_iou: 0.437 - ETA: 19s - loss: 0.6894 - mean_iou: 0.437 - ETA: 17s - loss: 0.6897 - mean_iou: 0.437 - ETA: 15s - loss: 0.6901 - mean_iou: 0.437 - ETA: 14s - loss: 0.6892 - mean_iou: 0.437 - ETA: 12s - loss: 0.6888 - mean_iou: 0.437 - ETA: 11s - loss: 0.6895 - mean_iou: 0.437 - ETA: 9s - loss: 0.6884 - mean_iou: 0.437 - ETA: 7s - loss: 0.6883 - mean_iou: 0.43 - ETA: 6s - loss: 0.6880 - mean_iou: 0.43 - ETA: 4s - loss: 0.6868 - mean_iou: 0.43 - ETA: 2s - loss: 0.6858 - mean_iou: 0.43 - ETA: 1s - loss: 0.6848 - mean_iou: 0.4375Epoch 00002: val_loss improved from 0.67965 to 0.66123, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 65s - loss: 0.6855 - mean_iou: 0.4375 - val_loss: 0.6612 - val_mean_iou: 0.4395\n",
      "Epoch 4/100\n",
      "592/603 [============================>.] - ETA: 59s - loss: 0.6498 - mean_iou: 0.440 - ETA: 60s - loss: 0.6467 - mean_iou: 0.440 - ETA: 60s - loss: 0.6477 - mean_iou: 0.440 - ETA: 57s - loss: 0.6594 - mean_iou: 0.440 - ETA: 55s - loss: 0.6676 - mean_iou: 0.440 - ETA: 52s - loss: 0.6687 - mean_iou: 0.440 - ETA: 50s - loss: 0.6672 - mean_iou: 0.440 - ETA: 48s - loss: 0.6667 - mean_iou: 0.440 - ETA: 47s - loss: 0.6690 - mean_iou: 0.441 - ETA: 45s - loss: 0.6710 - mean_iou: 0.441 - ETA: 43s - loss: 0.6710 - mean_iou: 0.441 - ETA: 41s - loss: 0.6708 - mean_iou: 0.441 - ETA: 40s - loss: 0.6731 - mean_iou: 0.441 - ETA: 38s - loss: 0.6731 - mean_iou: 0.441 - ETA: 36s - loss: 0.6726 - mean_iou: 0.441 - ETA: 35s - loss: 0.6725 - mean_iou: 0.441 - ETA: 33s - loss: 0.6721 - mean_iou: 0.441 - ETA: 31s - loss: 0.6738 - mean_iou: 0.441 - ETA: 30s - loss: 0.6720 - mean_iou: 0.441 - ETA: 28s - loss: 0.6723 - mean_iou: 0.441 - ETA: 27s - loss: 0.6736 - mean_iou: 0.441 - ETA: 25s - loss: 0.6721 - mean_iou: 0.441 - ETA: 23s - loss: 0.6747 - mean_iou: 0.441 - ETA: 22s - loss: 0.6737 - mean_iou: 0.441 - ETA: 20s - loss: 0.6730 - mean_iou: 0.441 - ETA: 18s - loss: 0.6728 - mean_iou: 0.441 - ETA: 17s - loss: 0.6749 - mean_iou: 0.441 - ETA: 15s - loss: 0.6746 - mean_iou: 0.441 - ETA: 14s - loss: 0.6746 - mean_iou: 0.441 - ETA: 12s - loss: 0.6744 - mean_iou: 0.441 - ETA: 10s - loss: 0.6731 - mean_iou: 0.441 - ETA: 9s - loss: 0.6737 - mean_iou: 0.441 - ETA: 7s - loss: 0.6732 - mean_iou: 0.44 - ETA: 6s - loss: 0.6722 - mean_iou: 0.44 - ETA: 4s - loss: 0.6712 - mean_iou: 0.44 - ETA: 2s - loss: 0.6705 - mean_iou: 0.44 - ETA: 1s - loss: 0.6703 - mean_iou: 0.4412Epoch 00003: val_loss improved from 0.66123 to 0.64547, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.6703 - mean_iou: 0.4412 - val_loss: 0.6455 - val_mean_iou: 0.4416\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 59s - loss: 0.6545 - mean_iou: 0.442 - ETA: 58s - loss: 0.6448 - mean_iou: 0.442 - ETA: 56s - loss: 0.6498 - mean_iou: 0.442 - ETA: 55s - loss: 0.6448 - mean_iou: 0.442 - ETA: 53s - loss: 0.6423 - mean_iou: 0.442 - ETA: 51s - loss: 0.6433 - mean_iou: 0.442 - ETA: 49s - loss: 0.6417 - mean_iou: 0.442 - ETA: 48s - loss: 0.6450 - mean_iou: 0.442 - ETA: 46s - loss: 0.6466 - mean_iou: 0.442 - ETA: 45s - loss: 0.6488 - mean_iou: 0.442 - ETA: 43s - loss: 0.6495 - mean_iou: 0.442 - ETA: 42s - loss: 0.6530 - mean_iou: 0.442 - ETA: 40s - loss: 0.6555 - mean_iou: 0.442 - ETA: 38s - loss: 0.6533 - mean_iou: 0.442 - ETA: 36s - loss: 0.6547 - mean_iou: 0.442 - ETA: 35s - loss: 0.6553 - mean_iou: 0.442 - ETA: 33s - loss: 0.6545 - mean_iou: 0.442 - ETA: 31s - loss: 0.6546 - mean_iou: 0.442 - ETA: 30s - loss: 0.6545 - mean_iou: 0.442 - ETA: 28s - loss: 0.6547 - mean_iou: 0.442 - ETA: 27s - loss: 0.6569 - mean_iou: 0.442 - ETA: 25s - loss: 0.6565 - mean_iou: 0.442 - ETA: 23s - loss: 0.6561 - mean_iou: 0.442 - ETA: 22s - loss: 0.6551 - mean_iou: 0.442 - ETA: 20s - loss: 0.6541 - mean_iou: 0.442 - ETA: 18s - loss: 0.6533 - mean_iou: 0.443 - ETA: 17s - loss: 0.6526 - mean_iou: 0.443 - ETA: 15s - loss: 0.6521 - mean_iou: 0.443 - ETA: 14s - loss: 0.6514 - mean_iou: 0.443 - ETA: 12s - loss: 0.6506 - mean_iou: 0.443 - ETA: 10s - loss: 0.6499 - mean_iou: 0.443 - ETA: 9s - loss: 0.6493 - mean_iou: 0.443 - ETA: 7s - loss: 0.6487 - mean_iou: 0.44 - ETA: 5s - loss: 0.6482 - mean_iou: 0.44 - ETA: 4s - loss: 0.6480 - mean_iou: 0.44 - ETA: 2s - loss: 0.6474 - mean_iou: 0.44 - ETA: 1s - loss: 0.6468 - mean_iou: 0.4432Epoch 00004: val_loss improved from 0.64547 to 0.62456, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 63s - loss: 0.6462 - mean_iou: 0.4432 - val_loss: 0.6246 - val_mean_iou: 0.4442\n",
      "Epoch 6/100\n",
      "592/603 [============================>.] - ETA: 59s - loss: 0.6158 - mean_iou: 0.444 - ETA: 57s - loss: 0.6206 - mean_iou: 0.444 - ETA: 55s - loss: 0.6242 - mean_iou: 0.444 - ETA: 53s - loss: 0.6237 - mean_iou: 0.444 - ETA: 52s - loss: 0.6240 - mean_iou: 0.444 - ETA: 51s - loss: 0.6228 - mean_iou: 0.444 - ETA: 49s - loss: 0.6228 - mean_iou: 0.444 - ETA: 48s - loss: 0.6225 - mean_iou: 0.444 - ETA: 48s - loss: 0.6223 - mean_iou: 0.444 - ETA: 47s - loss: 0.6221 - mean_iou: 0.444 - ETA: 45s - loss: 0.6228 - mean_iou: 0.444 - ETA: 43s - loss: 0.6221 - mean_iou: 0.444 - ETA: 41s - loss: 0.6227 - mean_iou: 0.445 - ETA: 39s - loss: 0.6224 - mean_iou: 0.445 - ETA: 37s - loss: 0.6228 - mean_iou: 0.445 - ETA: 36s - loss: 0.6235 - mean_iou: 0.445 - ETA: 34s - loss: 0.6225 - mean_iou: 0.445 - ETA: 32s - loss: 0.6226 - mean_iou: 0.445 - ETA: 31s - loss: 0.6230 - mean_iou: 0.445 - ETA: 29s - loss: 0.6230 - mean_iou: 0.445 - ETA: 27s - loss: 0.6227 - mean_iou: 0.445 - ETA: 26s - loss: 0.6225 - mean_iou: 0.445 - ETA: 24s - loss: 0.6226 - mean_iou: 0.445 - ETA: 22s - loss: 0.6222 - mean_iou: 0.445 - ETA: 21s - loss: 0.6224 - mean_iou: 0.445 - ETA: 19s - loss: 0.6222 - mean_iou: 0.445 - ETA: 17s - loss: 0.6219 - mean_iou: 0.445 - ETA: 16s - loss: 0.6216 - mean_iou: 0.445 - ETA: 14s - loss: 0.6216 - mean_iou: 0.445 - ETA: 12s - loss: 0.6218 - mean_iou: 0.445 - ETA: 11s - loss: 0.6217 - mean_iou: 0.445 - ETA: 9s - loss: 0.6215 - mean_iou: 0.445 - ETA: 7s - loss: 0.6211 - mean_iou: 0.44 - ETA: 6s - loss: 0.6209 - mean_iou: 0.44 - ETA: 4s - loss: 0.6206 - mean_iou: 0.44 - ETA: 2s - loss: 0.6205 - mean_iou: 0.44 - ETA: 1s - loss: 0.6204 - mean_iou: 0.4455Epoch 00005: val_loss improved from 0.62456 to 0.61728, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 65s - loss: 0.6203 - mean_iou: 0.4455 - val_loss: 0.6173 - val_mean_iou: 0.4463\n",
      "Epoch 7/100\n",
      "592/603 [============================>.] - ETA: 58s - loss: 0.6236 - mean_iou: 0.446 - ETA: 58s - loss: 0.6264 - mean_iou: 0.446 - ETA: 57s - loss: 0.6285 - mean_iou: 0.446 - ETA: 56s - loss: 0.6306 - mean_iou: 0.446 - ETA: 54s - loss: 0.6251 - mean_iou: 0.446 - ETA: 53s - loss: 0.6229 - mean_iou: 0.446 - ETA: 50s - loss: 0.6211 - mean_iou: 0.446 - ETA: 49s - loss: 0.6210 - mean_iou: 0.446 - ETA: 47s - loss: 0.6189 - mean_iou: 0.446 - ETA: 45s - loss: 0.6233 - mean_iou: 0.446 - ETA: 43s - loss: 0.6212 - mean_iou: 0.446 - ETA: 41s - loss: 0.6205 - mean_iou: 0.446 - ETA: 40s - loss: 0.6204 - mean_iou: 0.446 - ETA: 38s - loss: 0.6199 - mean_iou: 0.446 - ETA: 36s - loss: 0.6185 - mean_iou: 0.446 - ETA: 35s - loss: 0.6196 - mean_iou: 0.446 - ETA: 33s - loss: 0.6191 - mean_iou: 0.446 - ETA: 31s - loss: 0.6187 - mean_iou: 0.446 - ETA: 30s - loss: 0.6186 - mean_iou: 0.446 - ETA: 28s - loss: 0.6187 - mean_iou: 0.446 - ETA: 27s - loss: 0.6183 - mean_iou: 0.446 - ETA: 25s - loss: 0.6179 - mean_iou: 0.446 - ETA: 23s - loss: 0.6177 - mean_iou: 0.446 - ETA: 22s - loss: 0.6175 - mean_iou: 0.446 - ETA: 20s - loss: 0.6169 - mean_iou: 0.446 - ETA: 18s - loss: 0.6167 - mean_iou: 0.446 - ETA: 17s - loss: 0.6162 - mean_iou: 0.446 - ETA: 15s - loss: 0.6159 - mean_iou: 0.446 - ETA: 14s - loss: 0.6160 - mean_iou: 0.446 - ETA: 12s - loss: 0.6155 - mean_iou: 0.446 - ETA: 10s - loss: 0.6153 - mean_iou: 0.446 - ETA: 9s - loss: 0.6148 - mean_iou: 0.446 - ETA: 7s - loss: 0.6145 - mean_iou: 0.44 - ETA: 5s - loss: 0.6142 - mean_iou: 0.44 - ETA: 4s - loss: 0.6139 - mean_iou: 0.44 - ETA: 2s - loss: 0.6138 - mean_iou: 0.44 - ETA: 1s - loss: 0.6138 - mean_iou: 0.4465Epoch 00006: val_loss improved from 0.61728 to 0.60526, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.6136 - mean_iou: 0.4465 - val_loss: 0.6053 - val_mean_iou: 0.4467\n",
      "Epoch 8/100\n",
      "592/603 [============================>.] - ETA: 59s - loss: 0.5967 - mean_iou: 0.446 - ETA: 58s - loss: 0.6077 - mean_iou: 0.446 - ETA: 56s - loss: 0.6030 - mean_iou: 0.446 - ETA: 54s - loss: 0.6041 - mean_iou: 0.446 - ETA: 53s - loss: 0.6022 - mean_iou: 0.446 - ETA: 52s - loss: 0.6025 - mean_iou: 0.446 - ETA: 50s - loss: 0.6043 - mean_iou: 0.446 - ETA: 48s - loss: 0.6031 - mean_iou: 0.446 - ETA: 46s - loss: 0.6029 - mean_iou: 0.446 - ETA: 45s - loss: 0.6029 - mean_iou: 0.446 - ETA: 43s - loss: 0.6019 - mean_iou: 0.446 - ETA: 41s - loss: 0.6031 - mean_iou: 0.446 - ETA: 40s - loss: 0.6033 - mean_iou: 0.446 - ETA: 38s - loss: 0.6025 - mean_iou: 0.447 - ETA: 36s - loss: 0.6021 - mean_iou: 0.447 - ETA: 35s - loss: 0.6018 - mean_iou: 0.447 - ETA: 33s - loss: 0.6013 - mean_iou: 0.447 - ETA: 32s - loss: 0.6017 - mean_iou: 0.447 - ETA: 30s - loss: 0.6015 - mean_iou: 0.447 - ETA: 28s - loss: 0.6015 - mean_iou: 0.447 - ETA: 27s - loss: 0.6012 - mean_iou: 0.447 - ETA: 25s - loss: 0.6013 - mean_iou: 0.447 - ETA: 24s - loss: 0.6016 - mean_iou: 0.447 - ETA: 22s - loss: 0.6016 - mean_iou: 0.447 - ETA: 20s - loss: 0.6016 - mean_iou: 0.447 - ETA: 19s - loss: 0.6014 - mean_iou: 0.447 - ETA: 17s - loss: 0.6014 - mean_iou: 0.447 - ETA: 16s - loss: 0.6012 - mean_iou: 0.447 - ETA: 14s - loss: 0.6008 - mean_iou: 0.447 - ETA: 12s - loss: 0.6007 - mean_iou: 0.447 - ETA: 11s - loss: 0.6006 - mean_iou: 0.447 - ETA: 9s - loss: 0.6006 - mean_iou: 0.447 - ETA: 7s - loss: 0.6001 - mean_iou: 0.44 - ETA: 6s - loss: 0.5998 - mean_iou: 0.44 - ETA: 4s - loss: 0.5993 - mean_iou: 0.44 - ETA: 2s - loss: 0.5994 - mean_iou: 0.44 - ETA: 1s - loss: 0.5996 - mean_iou: 0.4471Epoch 00007: val_loss improved from 0.60526 to 0.59141, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 66s - loss: 0.5995 - mean_iou: 0.4471 - val_loss: 0.5914 - val_mean_iou: 0.4473\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 58s - loss: 0.5775 - mean_iou: 0.447 - ETA: 56s - loss: 0.5841 - mean_iou: 0.447 - ETA: 55s - loss: 0.5887 - mean_iou: 0.447 - ETA: 53s - loss: 0.5895 - mean_iou: 0.447 - ETA: 52s - loss: 0.5905 - mean_iou: 0.447 - ETA: 51s - loss: 0.5891 - mean_iou: 0.447 - ETA: 49s - loss: 0.5929 - mean_iou: 0.447 - ETA: 48s - loss: 0.5924 - mean_iou: 0.447 - ETA: 46s - loss: 0.5924 - mean_iou: 0.447 - ETA: 45s - loss: 0.5931 - mean_iou: 0.447 - ETA: 43s - loss: 0.5919 - mean_iou: 0.447 - ETA: 41s - loss: 0.5924 - mean_iou: 0.447 - ETA: 39s - loss: 0.5926 - mean_iou: 0.447 - ETA: 38s - loss: 0.5934 - mean_iou: 0.447 - ETA: 37s - loss: 0.5931 - mean_iou: 0.447 - ETA: 35s - loss: 0.5930 - mean_iou: 0.447 - ETA: 34s - loss: 0.5923 - mean_iou: 0.447 - ETA: 32s - loss: 0.5916 - mean_iou: 0.447 - ETA: 30s - loss: 0.5912 - mean_iou: 0.447 - ETA: 29s - loss: 0.5914 - mean_iou: 0.447 - ETA: 27s - loss: 0.5913 - mean_iou: 0.447 - ETA: 25s - loss: 0.5911 - mean_iou: 0.447 - ETA: 24s - loss: 0.5909 - mean_iou: 0.447 - ETA: 22s - loss: 0.5903 - mean_iou: 0.447 - ETA: 20s - loss: 0.5899 - mean_iou: 0.447 - ETA: 19s - loss: 0.5898 - mean_iou: 0.447 - ETA: 17s - loss: 0.5896 - mean_iou: 0.447 - ETA: 15s - loss: 0.5892 - mean_iou: 0.447 - ETA: 14s - loss: 0.5890 - mean_iou: 0.447 - ETA: 12s - loss: 0.5893 - mean_iou: 0.447 - ETA: 10s - loss: 0.5888 - mean_iou: 0.447 - ETA: 9s - loss: 0.5887 - mean_iou: 0.447 - ETA: 7s - loss: 0.5889 - mean_iou: 0.44 - ETA: 6s - loss: 0.5888 - mean_iou: 0.44 - ETA: 4s - loss: 0.5886 - mean_iou: 0.44 - ETA: 2s - loss: 0.5881 - mean_iou: 0.44 - ETA: 1s - loss: 0.5880 - mean_iou: 0.4475Epoch 00008: val_loss improved from 0.59141 to 0.57946, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.5882 - mean_iou: 0.4476 - val_loss: 0.5795 - val_mean_iou: 0.4479\n",
      "Epoch 10/100\n",
      "592/603 [============================>.] - ETA: 58s - loss: 0.5877 - mean_iou: 0.448 - ETA: 56s - loss: 0.5820 - mean_iou: 0.448 - ETA: 56s - loss: 0.5832 - mean_iou: 0.448 - ETA: 54s - loss: 0.5821 - mean_iou: 0.448 - ETA: 53s - loss: 0.5838 - mean_iou: 0.448 - ETA: 51s - loss: 0.5846 - mean_iou: 0.448 - ETA: 50s - loss: 0.5835 - mean_iou: 0.448 - ETA: 48s - loss: 0.5830 - mean_iou: 0.448 - ETA: 47s - loss: 0.5835 - mean_iou: 0.448 - ETA: 45s - loss: 0.5833 - mean_iou: 0.448 - ETA: 44s - loss: 0.5825 - mean_iou: 0.448 - ETA: 42s - loss: 0.5830 - mean_iou: 0.448 - ETA: 41s - loss: 0.5831 - mean_iou: 0.448 - ETA: 39s - loss: 0.5827 - mean_iou: 0.448 - ETA: 37s - loss: 0.5824 - mean_iou: 0.448 - ETA: 35s - loss: 0.5818 - mean_iou: 0.448 - ETA: 34s - loss: 0.5819 - mean_iou: 0.448 - ETA: 32s - loss: 0.5808 - mean_iou: 0.448 - ETA: 30s - loss: 0.5807 - mean_iou: 0.448 - ETA: 28s - loss: 0.5805 - mean_iou: 0.448 - ETA: 27s - loss: 0.5802 - mean_iou: 0.448 - ETA: 25s - loss: 0.5807 - mean_iou: 0.448 - ETA: 23s - loss: 0.5805 - mean_iou: 0.448 - ETA: 22s - loss: 0.5802 - mean_iou: 0.448 - ETA: 20s - loss: 0.5802 - mean_iou: 0.448 - ETA: 19s - loss: 0.5800 - mean_iou: 0.448 - ETA: 17s - loss: 0.5791 - mean_iou: 0.448 - ETA: 15s - loss: 0.5787 - mean_iou: 0.448 - ETA: 14s - loss: 0.5788 - mean_iou: 0.448 - ETA: 12s - loss: 0.5785 - mean_iou: 0.448 - ETA: 10s - loss: 0.5781 - mean_iou: 0.448 - ETA: 9s - loss: 0.5779 - mean_iou: 0.448 - ETA: 7s - loss: 0.5780 - mean_iou: 0.44 - ETA: 6s - loss: 0.5786 - mean_iou: 0.44 - ETA: 4s - loss: 0.5779 - mean_iou: 0.44 - ETA: 2s - loss: 0.5777 - mean_iou: 0.44 - ETA: 1s - loss: 0.5780 - mean_iou: 0.4482Epoch 00009: val_loss improved from 0.57946 to 0.56871, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 65s - loss: 0.5779 - mean_iou: 0.4482 - val_loss: 0.5687 - val_mean_iou: 0.4485\n",
      "Epoch 11/100\n",
      "592/603 [============================>.] - ETA: 62s - loss: 0.5836 - mean_iou: 0.448 - ETA: 61s - loss: 0.5782 - mean_iou: 0.448 - ETA: 59s - loss: 0.5720 - mean_iou: 0.448 - ETA: 57s - loss: 0.5759 - mean_iou: 0.448 - ETA: 55s - loss: 0.5726 - mean_iou: 0.448 - ETA: 53s - loss: 0.5744 - mean_iou: 0.448 - ETA: 51s - loss: 0.5747 - mean_iou: 0.448 - ETA: 50s - loss: 0.5728 - mean_iou: 0.448 - ETA: 48s - loss: 0.5722 - mean_iou: 0.448 - ETA: 47s - loss: 0.5709 - mean_iou: 0.448 - ETA: 45s - loss: 0.5711 - mean_iou: 0.448 - ETA: 43s - loss: 0.5712 - mean_iou: 0.448 - ETA: 41s - loss: 0.5713 - mean_iou: 0.448 - ETA: 39s - loss: 0.5711 - mean_iou: 0.448 - ETA: 38s - loss: 0.5705 - mean_iou: 0.448 - ETA: 36s - loss: 0.5706 - mean_iou: 0.448 - ETA: 34s - loss: 0.5713 - mean_iou: 0.448 - ETA: 32s - loss: 0.5711 - mean_iou: 0.448 - ETA: 31s - loss: 0.5708 - mean_iou: 0.448 - ETA: 29s - loss: 0.5707 - mean_iou: 0.448 - ETA: 27s - loss: 0.5712 - mean_iou: 0.448 - ETA: 25s - loss: 0.5713 - mean_iou: 0.448 - ETA: 24s - loss: 0.5711 - mean_iou: 0.448 - ETA: 22s - loss: 0.5709 - mean_iou: 0.448 - ETA: 20s - loss: 0.5705 - mean_iou: 0.448 - ETA: 19s - loss: 0.5704 - mean_iou: 0.448 - ETA: 17s - loss: 0.5706 - mean_iou: 0.448 - ETA: 15s - loss: 0.5703 - mean_iou: 0.448 - ETA: 14s - loss: 0.5699 - mean_iou: 0.448 - ETA: 12s - loss: 0.5703 - mean_iou: 0.448 - ETA: 10s - loss: 0.5700 - mean_iou: 0.448 - ETA: 9s - loss: 0.5697 - mean_iou: 0.448 - ETA: 7s - loss: 0.5697 - mean_iou: 0.44 - ETA: 6s - loss: 0.5694 - mean_iou: 0.44 - ETA: 4s - loss: 0.5694 - mean_iou: 0.44 - ETA: 2s - loss: 0.5693 - mean_iou: 0.44 - ETA: 1s - loss: 0.5694 - mean_iou: 0.4487Epoch 00010: val_loss improved from 0.56871 to 0.55801, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 65s - loss: 0.5691 - mean_iou: 0.4487 - val_loss: 0.5580 - val_mean_iou: 0.4485\n",
      "Epoch 12/100\n",
      "592/603 [============================>.] - ETA: 61s - loss: 0.5603 - mean_iou: 0.448 - ETA: 59s - loss: 0.5609 - mean_iou: 0.448 - ETA: 57s - loss: 0.5598 - mean_iou: 0.448 - ETA: 54s - loss: 0.5594 - mean_iou: 0.448 - ETA: 53s - loss: 0.5595 - mean_iou: 0.448 - ETA: 51s - loss: 0.5586 - mean_iou: 0.448 - ETA: 50s - loss: 0.5586 - mean_iou: 0.448 - ETA: 49s - loss: 0.5599 - mean_iou: 0.448 - ETA: 47s - loss: 0.5587 - mean_iou: 0.448 - ETA: 45s - loss: 0.5577 - mean_iou: 0.448 - ETA: 43s - loss: 0.5595 - mean_iou: 0.448 - ETA: 42s - loss: 0.5605 - mean_iou: 0.448 - ETA: 40s - loss: 0.5598 - mean_iou: 0.448 - ETA: 38s - loss: 0.5606 - mean_iou: 0.448 - ETA: 37s - loss: 0.5602 - mean_iou: 0.448 - ETA: 35s - loss: 0.5616 - mean_iou: 0.448 - ETA: 33s - loss: 0.5614 - mean_iou: 0.448 - ETA: 32s - loss: 0.5613 - mean_iou: 0.448 - ETA: 30s - loss: 0.5607 - mean_iou: 0.448 - ETA: 28s - loss: 0.5608 - mean_iou: 0.448 - ETA: 27s - loss: 0.5606 - mean_iou: 0.448 - ETA: 25s - loss: 0.5603 - mean_iou: 0.448 - ETA: 24s - loss: 0.5613 - mean_iou: 0.448 - ETA: 22s - loss: 0.5614 - mean_iou: 0.448 - ETA: 20s - loss: 0.5615 - mean_iou: 0.448 - ETA: 19s - loss: 0.5615 - mean_iou: 0.448 - ETA: 17s - loss: 0.5618 - mean_iou: 0.448 - ETA: 15s - loss: 0.5615 - mean_iou: 0.448 - ETA: 14s - loss: 0.5617 - mean_iou: 0.448 - ETA: 12s - loss: 0.5616 - mean_iou: 0.448 - ETA: 10s - loss: 0.5620 - mean_iou: 0.448 - ETA: 9s - loss: 0.5619 - mean_iou: 0.448 - ETA: 7s - loss: 0.5620 - mean_iou: 0.44 - ETA: 6s - loss: 0.5618 - mean_iou: 0.44 - ETA: 4s - loss: 0.5616 - mean_iou: 0.44 - ETA: 2s - loss: 0.5616 - mean_iou: 0.44 - ETA: 1s - loss: 0.5614 - mean_iou: 0.4484Epoch 00011: val_loss improved from 0.55801 to 0.55190, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.5614 - mean_iou: 0.4484 - val_loss: 0.5519 - val_mean_iou: 0.4480\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 58s - loss: 0.5557 - mean_iou: 0.448 - ETA: 57s - loss: 0.5561 - mean_iou: 0.448 - ETA: 55s - loss: 0.5614 - mean_iou: 0.448 - ETA: 53s - loss: 0.5611 - mean_iou: 0.448 - ETA: 52s - loss: 0.5615 - mean_iou: 0.448 - ETA: 52s - loss: 0.5621 - mean_iou: 0.448 - ETA: 51s - loss: 0.5591 - mean_iou: 0.447 - ETA: 49s - loss: 0.5581 - mean_iou: 0.447 - ETA: 47s - loss: 0.5585 - mean_iou: 0.447 - ETA: 46s - loss: 0.5574 - mean_iou: 0.447 - ETA: 44s - loss: 0.5552 - mean_iou: 0.447 - ETA: 42s - loss: 0.5543 - mean_iou: 0.447 - ETA: 40s - loss: 0.5557 - mean_iou: 0.447 - ETA: 39s - loss: 0.5547 - mean_iou: 0.447 - ETA: 38s - loss: 0.5552 - mean_iou: 0.447 - ETA: 36s - loss: 0.5551 - mean_iou: 0.447 - ETA: 34s - loss: 0.5548 - mean_iou: 0.447 - ETA: 33s - loss: 0.5539 - mean_iou: 0.447 - ETA: 31s - loss: 0.5532 - mean_iou: 0.447 - ETA: 29s - loss: 0.5529 - mean_iou: 0.447 - ETA: 28s - loss: 0.5524 - mean_iou: 0.447 - ETA: 26s - loss: 0.5525 - mean_iou: 0.447 - ETA: 24s - loss: 0.5521 - mean_iou: 0.447 - ETA: 22s - loss: 0.5518 - mean_iou: 0.447 - ETA: 21s - loss: 0.5516 - mean_iou: 0.447 - ETA: 19s - loss: 0.5517 - mean_iou: 0.447 - ETA: 17s - loss: 0.5512 - mean_iou: 0.447 - ETA: 16s - loss: 0.5511 - mean_iou: 0.447 - ETA: 14s - loss: 0.5510 - mean_iou: 0.447 - ETA: 12s - loss: 0.5506 - mean_iou: 0.447 - ETA: 11s - loss: 0.5507 - mean_iou: 0.447 - ETA: 9s - loss: 0.5502 - mean_iou: 0.447 - ETA: 7s - loss: 0.5505 - mean_iou: 0.44 - ETA: 6s - loss: 0.5501 - mean_iou: 0.44 - ETA: 4s - loss: 0.5501 - mean_iou: 0.44 - ETA: 2s - loss: 0.5500 - mean_iou: 0.44 - ETA: 1s - loss: 0.5498 - mean_iou: 0.4478Epoch 00012: val_loss improved from 0.55190 to 0.53856, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 65s - loss: 0.5494 - mean_iou: 0.4478 - val_loss: 0.5386 - val_mean_iou: 0.4477\n",
      "Epoch 14/100\n",
      "592/603 [============================>.] - ETA: 63s - loss: 0.5409 - mean_iou: 0.447 - ETA: 67s - loss: 0.5439 - mean_iou: 0.447 - ETA: 65s - loss: 0.5460 - mean_iou: 0.447 - ETA: 61s - loss: 0.5422 - mean_iou: 0.447 - ETA: 58s - loss: 0.5422 - mean_iou: 0.447 - ETA: 55s - loss: 0.5441 - mean_iou: 0.447 - ETA: 53s - loss: 0.5441 - mean_iou: 0.447 - ETA: 51s - loss: 0.5442 - mean_iou: 0.447 - ETA: 49s - loss: 0.5437 - mean_iou: 0.447 - ETA: 47s - loss: 0.5440 - mean_iou: 0.447 - ETA: 45s - loss: 0.5441 - mean_iou: 0.447 - ETA: 44s - loss: 0.5428 - mean_iou: 0.447 - ETA: 42s - loss: 0.5442 - mean_iou: 0.447 - ETA: 40s - loss: 0.5447 - mean_iou: 0.447 - ETA: 38s - loss: 0.5453 - mean_iou: 0.447 - ETA: 36s - loss: 0.5456 - mean_iou: 0.447 - ETA: 35s - loss: 0.5446 - mean_iou: 0.447 - ETA: 33s - loss: 0.5435 - mean_iou: 0.447 - ETA: 31s - loss: 0.5427 - mean_iou: 0.447 - ETA: 29s - loss: 0.5418 - mean_iou: 0.447 - ETA: 28s - loss: 0.5425 - mean_iou: 0.447 - ETA: 26s - loss: 0.5421 - mean_iou: 0.447 - ETA: 24s - loss: 0.5422 - mean_iou: 0.447 - ETA: 23s - loss: 0.5426 - mean_iou: 0.447 - ETA: 21s - loss: 0.5420 - mean_iou: 0.447 - ETA: 19s - loss: 0.5417 - mean_iou: 0.447 - ETA: 17s - loss: 0.5427 - mean_iou: 0.447 - ETA: 16s - loss: 0.5417 - mean_iou: 0.447 - ETA: 14s - loss: 0.5422 - mean_iou: 0.447 - ETA: 12s - loss: 0.5419 - mean_iou: 0.447 - ETA: 11s - loss: 0.5430 - mean_iou: 0.447 - ETA: 9s - loss: 0.5429 - mean_iou: 0.447 - ETA: 7s - loss: 0.5425 - mean_iou: 0.44 - ETA: 6s - loss: 0.5425 - mean_iou: 0.44 - ETA: 4s - loss: 0.5420 - mean_iou: 0.44 - ETA: 2s - loss: 0.5417 - mean_iou: 0.44 - ETA: 1s - loss: 0.5416 - mean_iou: 0.4475Epoch 00013: val_loss improved from 0.53856 to 0.53456, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 65s - loss: 0.5418 - mean_iou: 0.4475 - val_loss: 0.5346 - val_mean_iou: 0.4473\n",
      "Epoch 15/100\n",
      "592/603 [============================>.] - ETA: 72s - loss: 0.5402 - mean_iou: 0.447 - ETA: 67s - loss: 0.5407 - mean_iou: 0.447 - ETA: 62s - loss: 0.5456 - mean_iou: 0.447 - ETA: 59s - loss: 0.5477 - mean_iou: 0.447 - ETA: 56s - loss: 0.5487 - mean_iou: 0.447 - ETA: 54s - loss: 0.5458 - mean_iou: 0.447 - ETA: 52s - loss: 0.5455 - mean_iou: 0.447 - ETA: 50s - loss: 0.5467 - mean_iou: 0.447 - ETA: 48s - loss: 0.5448 - mean_iou: 0.447 - ETA: 46s - loss: 0.5448 - mean_iou: 0.447 - ETA: 44s - loss: 0.5448 - mean_iou: 0.447 - ETA: 42s - loss: 0.5443 - mean_iou: 0.447 - ETA: 41s - loss: 0.5420 - mean_iou: 0.447 - ETA: 39s - loss: 0.5421 - mean_iou: 0.447 - ETA: 37s - loss: 0.5415 - mean_iou: 0.447 - ETA: 35s - loss: 0.5416 - mean_iou: 0.447 - ETA: 34s - loss: 0.5416 - mean_iou: 0.447 - ETA: 32s - loss: 0.5420 - mean_iou: 0.447 - ETA: 30s - loss: 0.5407 - mean_iou: 0.447 - ETA: 29s - loss: 0.5407 - mean_iou: 0.447 - ETA: 27s - loss: 0.5397 - mean_iou: 0.447 - ETA: 25s - loss: 0.5386 - mean_iou: 0.447 - ETA: 24s - loss: 0.5386 - mean_iou: 0.447 - ETA: 22s - loss: 0.5382 - mean_iou: 0.447 - ETA: 20s - loss: 0.5372 - mean_iou: 0.447 - ETA: 19s - loss: 0.5364 - mean_iou: 0.447 - ETA: 17s - loss: 0.5359 - mean_iou: 0.447 - ETA: 15s - loss: 0.5361 - mean_iou: 0.447 - ETA: 14s - loss: 0.5363 - mean_iou: 0.447 - ETA: 12s - loss: 0.5357 - mean_iou: 0.447 - ETA: 10s - loss: 0.5356 - mean_iou: 0.447 - ETA: 9s - loss: 0.5353 - mean_iou: 0.447 - ETA: 7s - loss: 0.5347 - mean_iou: 0.44 - ETA: 6s - loss: 0.5341 - mean_iou: 0.44 - ETA: 4s - loss: 0.5343 - mean_iou: 0.44 - ETA: 2s - loss: 0.5338 - mean_iou: 0.44 - ETA: 1s - loss: 0.5339 - mean_iou: 0.4471Epoch 00014: val_loss improved from 0.53456 to 0.52020, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 66s - loss: 0.5337 - mean_iou: 0.4471 - val_loss: 0.5202 - val_mean_iou: 0.4470\n",
      "Epoch 16/100\n",
      "592/603 [============================>.] - ETA: 64s - loss: 0.5267 - mean_iou: 0.447 - ETA: 62s - loss: 0.5272 - mean_iou: 0.447 - ETA: 61s - loss: 0.5247 - mean_iou: 0.447 - ETA: 60s - loss: 0.5237 - mean_iou: 0.447 - ETA: 58s - loss: 0.5269 - mean_iou: 0.447 - ETA: 56s - loss: 0.5250 - mean_iou: 0.447 - ETA: 54s - loss: 0.5231 - mean_iou: 0.447 - ETA: 53s - loss: 0.5222 - mean_iou: 0.447 - ETA: 51s - loss: 0.5228 - mean_iou: 0.447 - ETA: 49s - loss: 0.5211 - mean_iou: 0.447 - ETA: 47s - loss: 0.5216 - mean_iou: 0.447 - ETA: 45s - loss: 0.5202 - mean_iou: 0.447 - ETA: 43s - loss: 0.5211 - mean_iou: 0.447 - ETA: 41s - loss: 0.5214 - mean_iou: 0.447 - ETA: 39s - loss: 0.5212 - mean_iou: 0.447 - ETA: 37s - loss: 0.5212 - mean_iou: 0.447 - ETA: 35s - loss: 0.5217 - mean_iou: 0.447 - ETA: 33s - loss: 0.5227 - mean_iou: 0.447 - ETA: 31s - loss: 0.5224 - mean_iou: 0.447 - ETA: 30s - loss: 0.5226 - mean_iou: 0.447 - ETA: 28s - loss: 0.5227 - mean_iou: 0.447 - ETA: 26s - loss: 0.5228 - mean_iou: 0.447 - ETA: 24s - loss: 0.5228 - mean_iou: 0.447 - ETA: 23s - loss: 0.5226 - mean_iou: 0.447 - ETA: 21s - loss: 0.5224 - mean_iou: 0.447 - ETA: 19s - loss: 0.5222 - mean_iou: 0.447 - ETA: 17s - loss: 0.5226 - mean_iou: 0.447 - ETA: 16s - loss: 0.5222 - mean_iou: 0.447 - ETA: 14s - loss: 0.5218 - mean_iou: 0.447 - ETA: 12s - loss: 0.5219 - mean_iou: 0.447 - ETA: 11s - loss: 0.5224 - mean_iou: 0.447 - ETA: 9s - loss: 0.5226 - mean_iou: 0.447 - ETA: 7s - loss: 0.5225 - mean_iou: 0.44 - ETA: 6s - loss: 0.5222 - mean_iou: 0.44 - ETA: 4s - loss: 0.5222 - mean_iou: 0.44 - ETA: 2s - loss: 0.5219 - mean_iou: 0.44 - ETA: 1s - loss: 0.5217 - mean_iou: 0.4469Epoch 00015: val_loss improved from 0.52020 to 0.51010, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 66s - loss: 0.5214 - mean_iou: 0.4469 - val_loss: 0.5101 - val_mean_iou: 0.4468\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 60s - loss: 0.5049 - mean_iou: 0.446 - ETA: 57s - loss: 0.5113 - mean_iou: 0.446 - ETA: 55s - loss: 0.5096 - mean_iou: 0.446 - ETA: 54s - loss: 0.5068 - mean_iou: 0.446 - ETA: 53s - loss: 0.5089 - mean_iou: 0.446 - ETA: 51s - loss: 0.5118 - mean_iou: 0.446 - ETA: 50s - loss: 0.5135 - mean_iou: 0.446 - ETA: 48s - loss: 0.5128 - mean_iou: 0.446 - ETA: 46s - loss: 0.5118 - mean_iou: 0.446 - ETA: 45s - loss: 0.5111 - mean_iou: 0.446 - ETA: 43s - loss: 0.5099 - mean_iou: 0.446 - ETA: 42s - loss: 0.5102 - mean_iou: 0.446 - ETA: 40s - loss: 0.5106 - mean_iou: 0.446 - ETA: 38s - loss: 0.5116 - mean_iou: 0.446 - ETA: 37s - loss: 0.5114 - mean_iou: 0.446 - ETA: 35s - loss: 0.5114 - mean_iou: 0.446 - ETA: 33s - loss: 0.5117 - mean_iou: 0.446 - ETA: 32s - loss: 0.5123 - mean_iou: 0.446 - ETA: 30s - loss: 0.5124 - mean_iou: 0.446 - ETA: 28s - loss: 0.5117 - mean_iou: 0.446 - ETA: 27s - loss: 0.5115 - mean_iou: 0.446 - ETA: 25s - loss: 0.5112 - mean_iou: 0.446 - ETA: 23s - loss: 0.5115 - mean_iou: 0.446 - ETA: 22s - loss: 0.5123 - mean_iou: 0.446 - ETA: 20s - loss: 0.5133 - mean_iou: 0.446 - ETA: 18s - loss: 0.5134 - mean_iou: 0.446 - ETA: 17s - loss: 0.5130 - mean_iou: 0.446 - ETA: 15s - loss: 0.5131 - mean_iou: 0.446 - ETA: 14s - loss: 0.5127 - mean_iou: 0.446 - ETA: 12s - loss: 0.5126 - mean_iou: 0.446 - ETA: 10s - loss: 0.5125 - mean_iou: 0.446 - ETA: 9s - loss: 0.5129 - mean_iou: 0.446 - ETA: 7s - loss: 0.5124 - mean_iou: 0.44 - ETA: 6s - loss: 0.5125 - mean_iou: 0.44 - ETA: 4s - loss: 0.5121 - mean_iou: 0.44 - ETA: 2s - loss: 0.5121 - mean_iou: 0.44 - ETA: 1s - loss: 0.5118 - mean_iou: 0.4468Epoch 00016: val_loss improved from 0.51010 to 0.50134, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.5119 - mean_iou: 0.4468 - val_loss: 0.5013 - val_mean_iou: 0.4466\n",
      "Epoch 18/100\n",
      "592/603 [============================>.] - ETA: 59s - loss: 0.5023 - mean_iou: 0.446 - ETA: 58s - loss: 0.5124 - mean_iou: 0.446 - ETA: 57s - loss: 0.5139 - mean_iou: 0.446 - ETA: 55s - loss: 0.5118 - mean_iou: 0.446 - ETA: 54s - loss: 0.5090 - mean_iou: 0.446 - ETA: 52s - loss: 0.5060 - mean_iou: 0.446 - ETA: 52s - loss: 0.5050 - mean_iou: 0.446 - ETA: 50s - loss: 0.5064 - mean_iou: 0.446 - ETA: 47s - loss: 0.5047 - mean_iou: 0.446 - ETA: 46s - loss: 0.5039 - mean_iou: 0.446 - ETA: 44s - loss: 0.5053 - mean_iou: 0.446 - ETA: 42s - loss: 0.5067 - mean_iou: 0.446 - ETA: 40s - loss: 0.5065 - mean_iou: 0.446 - ETA: 39s - loss: 0.5055 - mean_iou: 0.446 - ETA: 37s - loss: 0.5053 - mean_iou: 0.446 - ETA: 35s - loss: 0.5055 - mean_iou: 0.446 - ETA: 33s - loss: 0.5059 - mean_iou: 0.446 - ETA: 32s - loss: 0.5061 - mean_iou: 0.446 - ETA: 30s - loss: 0.5059 - mean_iou: 0.446 - ETA: 28s - loss: 0.5053 - mean_iou: 0.446 - ETA: 27s - loss: 0.5053 - mean_iou: 0.446 - ETA: 25s - loss: 0.5052 - mean_iou: 0.446 - ETA: 23s - loss: 0.5051 - mean_iou: 0.446 - ETA: 22s - loss: 0.5049 - mean_iou: 0.446 - ETA: 20s - loss: 0.5046 - mean_iou: 0.446 - ETA: 19s - loss: 0.5046 - mean_iou: 0.446 - ETA: 17s - loss: 0.5043 - mean_iou: 0.446 - ETA: 15s - loss: 0.5043 - mean_iou: 0.446 - ETA: 14s - loss: 0.5046 - mean_iou: 0.446 - ETA: 12s - loss: 0.5039 - mean_iou: 0.446 - ETA: 11s - loss: 0.5040 - mean_iou: 0.446 - ETA: 9s - loss: 0.5039 - mean_iou: 0.446 - ETA: 7s - loss: 0.5036 - mean_iou: 0.44 - ETA: 6s - loss: 0.5037 - mean_iou: 0.44 - ETA: 4s - loss: 0.5031 - mean_iou: 0.44 - ETA: 2s - loss: 0.5028 - mean_iou: 0.44 - ETA: 1s - loss: 0.5027 - mean_iou: 0.4466Epoch 00017: val_loss improved from 0.50134 to 0.49214, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 65s - loss: 0.5032 - mean_iou: 0.4466 - val_loss: 0.4921 - val_mean_iou: 0.4465\n",
      "Epoch 19/100\n",
      "592/603 [============================>.] - ETA: 58s - loss: 0.4920 - mean_iou: 0.446 - ETA: 56s - loss: 0.4864 - mean_iou: 0.446 - ETA: 55s - loss: 0.4957 - mean_iou: 0.446 - ETA: 54s - loss: 0.5015 - mean_iou: 0.446 - ETA: 54s - loss: 0.5001 - mean_iou: 0.446 - ETA: 52s - loss: 0.4993 - mean_iou: 0.446 - ETA: 50s - loss: 0.4973 - mean_iou: 0.446 - ETA: 49s - loss: 0.4957 - mean_iou: 0.446 - ETA: 47s - loss: 0.4944 - mean_iou: 0.446 - ETA: 46s - loss: 0.4952 - mean_iou: 0.446 - ETA: 44s - loss: 0.4958 - mean_iou: 0.446 - ETA: 42s - loss: 0.4966 - mean_iou: 0.446 - ETA: 40s - loss: 0.4965 - mean_iou: 0.446 - ETA: 38s - loss: 0.4970 - mean_iou: 0.446 - ETA: 37s - loss: 0.4979 - mean_iou: 0.446 - ETA: 35s - loss: 0.4991 - mean_iou: 0.446 - ETA: 33s - loss: 0.4984 - mean_iou: 0.446 - ETA: 32s - loss: 0.4982 - mean_iou: 0.446 - ETA: 30s - loss: 0.4976 - mean_iou: 0.446 - ETA: 28s - loss: 0.4975 - mean_iou: 0.446 - ETA: 27s - loss: 0.4972 - mean_iou: 0.446 - ETA: 25s - loss: 0.4966 - mean_iou: 0.446 - ETA: 23s - loss: 0.4968 - mean_iou: 0.446 - ETA: 22s - loss: 0.4965 - mean_iou: 0.446 - ETA: 20s - loss: 0.4961 - mean_iou: 0.446 - ETA: 18s - loss: 0.4959 - mean_iou: 0.446 - ETA: 17s - loss: 0.4963 - mean_iou: 0.446 - ETA: 15s - loss: 0.4966 - mean_iou: 0.446 - ETA: 14s - loss: 0.4972 - mean_iou: 0.446 - ETA: 12s - loss: 0.4965 - mean_iou: 0.446 - ETA: 10s - loss: 0.4963 - mean_iou: 0.446 - ETA: 9s - loss: 0.4964 - mean_iou: 0.446 - ETA: 7s - loss: 0.4959 - mean_iou: 0.44 - ETA: 5s - loss: 0.4956 - mean_iou: 0.44 - ETA: 4s - loss: 0.4957 - mean_iou: 0.44 - ETA: 2s - loss: 0.4951 - mean_iou: 0.44 - ETA: 1s - loss: 0.4947 - mean_iou: 0.4465Epoch 00018: val_loss improved from 0.49214 to 0.48410, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.4949 - mean_iou: 0.4465 - val_loss: 0.4841 - val_mean_iou: 0.4464\n",
      "Epoch 20/100\n",
      "592/603 [============================>.] - ETA: 61s - loss: 0.4878 - mean_iou: 0.446 - ETA: 58s - loss: 0.4892 - mean_iou: 0.446 - ETA: 56s - loss: 0.4895 - mean_iou: 0.446 - ETA: 54s - loss: 0.4917 - mean_iou: 0.446 - ETA: 53s - loss: 0.4936 - mean_iou: 0.446 - ETA: 52s - loss: 0.4940 - mean_iou: 0.446 - ETA: 51s - loss: 0.4916 - mean_iou: 0.446 - ETA: 48s - loss: 0.4913 - mean_iou: 0.446 - ETA: 47s - loss: 0.4934 - mean_iou: 0.446 - ETA: 45s - loss: 0.4945 - mean_iou: 0.446 - ETA: 43s - loss: 0.4953 - mean_iou: 0.446 - ETA: 42s - loss: 0.4955 - mean_iou: 0.446 - ETA: 40s - loss: 0.4945 - mean_iou: 0.446 - ETA: 38s - loss: 0.4927 - mean_iou: 0.446 - ETA: 36s - loss: 0.4911 - mean_iou: 0.446 - ETA: 35s - loss: 0.4907 - mean_iou: 0.446 - ETA: 33s - loss: 0.4897 - mean_iou: 0.446 - ETA: 31s - loss: 0.4900 - mean_iou: 0.446 - ETA: 30s - loss: 0.4890 - mean_iou: 0.446 - ETA: 28s - loss: 0.4893 - mean_iou: 0.446 - ETA: 26s - loss: 0.4893 - mean_iou: 0.446 - ETA: 25s - loss: 0.4896 - mean_iou: 0.446 - ETA: 23s - loss: 0.4892 - mean_iou: 0.446 - ETA: 22s - loss: 0.4888 - mean_iou: 0.446 - ETA: 20s - loss: 0.4889 - mean_iou: 0.446 - ETA: 18s - loss: 0.4885 - mean_iou: 0.446 - ETA: 17s - loss: 0.4887 - mean_iou: 0.446 - ETA: 15s - loss: 0.4888 - mean_iou: 0.446 - ETA: 14s - loss: 0.4886 - mean_iou: 0.446 - ETA: 12s - loss: 0.4891 - mean_iou: 0.446 - ETA: 10s - loss: 0.4893 - mean_iou: 0.446 - ETA: 9s - loss: 0.4896 - mean_iou: 0.446 - ETA: 7s - loss: 0.4890 - mean_iou: 0.44 - ETA: 5s - loss: 0.4885 - mean_iou: 0.44 - ETA: 4s - loss: 0.4883 - mean_iou: 0.44 - ETA: 2s - loss: 0.4879 - mean_iou: 0.44 - ETA: 1s - loss: 0.4875 - mean_iou: 0.4464Epoch 00019: val_loss improved from 0.48410 to 0.47572, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.4878 - mean_iou: 0.4464 - val_loss: 0.4757 - val_mean_iou: 0.4463\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 58s - loss: 0.5006 - mean_iou: 0.446 - ETA: 56s - loss: 0.4949 - mean_iou: 0.446 - ETA: 55s - loss: 0.4950 - mean_iou: 0.446 - ETA: 54s - loss: 0.4895 - mean_iou: 0.446 - ETA: 52s - loss: 0.4868 - mean_iou: 0.446 - ETA: 51s - loss: 0.4821 - mean_iou: 0.446 - ETA: 49s - loss: 0.4808 - mean_iou: 0.446 - ETA: 48s - loss: 0.4808 - mean_iou: 0.446 - ETA: 46s - loss: 0.4806 - mean_iou: 0.446 - ETA: 44s - loss: 0.4795 - mean_iou: 0.446 - ETA: 43s - loss: 0.4812 - mean_iou: 0.446 - ETA: 41s - loss: 0.4821 - mean_iou: 0.446 - ETA: 39s - loss: 0.4811 - mean_iou: 0.446 - ETA: 38s - loss: 0.4801 - mean_iou: 0.446 - ETA: 36s - loss: 0.4805 - mean_iou: 0.446 - ETA: 34s - loss: 0.4813 - mean_iou: 0.446 - ETA: 33s - loss: 0.4807 - mean_iou: 0.446 - ETA: 31s - loss: 0.4809 - mean_iou: 0.446 - ETA: 29s - loss: 0.4807 - mean_iou: 0.446 - ETA: 28s - loss: 0.4801 - mean_iou: 0.446 - ETA: 26s - loss: 0.4797 - mean_iou: 0.446 - ETA: 25s - loss: 0.4789 - mean_iou: 0.446 - ETA: 23s - loss: 0.4789 - mean_iou: 0.446 - ETA: 22s - loss: 0.4788 - mean_iou: 0.446 - ETA: 20s - loss: 0.4797 - mean_iou: 0.446 - ETA: 18s - loss: 0.4794 - mean_iou: 0.446 - ETA: 17s - loss: 0.4798 - mean_iou: 0.446 - ETA: 15s - loss: 0.4800 - mean_iou: 0.446 - ETA: 14s - loss: 0.4801 - mean_iou: 0.446 - ETA: 12s - loss: 0.4797 - mean_iou: 0.446 - ETA: 10s - loss: 0.4793 - mean_iou: 0.446 - ETA: 9s - loss: 0.4790 - mean_iou: 0.446 - ETA: 7s - loss: 0.4782 - mean_iou: 0.44 - ETA: 5s - loss: 0.4781 - mean_iou: 0.44 - ETA: 4s - loss: 0.4772 - mean_iou: 0.44 - ETA: 2s - loss: 0.4773 - mean_iou: 0.44 - ETA: 1s - loss: 0.4776 - mean_iou: 0.4463Epoch 00020: val_loss improved from 0.47572 to 0.46729, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.4781 - mean_iou: 0.4463 - val_loss: 0.4673 - val_mean_iou: 0.4462\n",
      "Epoch 22/100\n",
      "592/603 [============================>.] - ETA: 57s - loss: 0.4839 - mean_iou: 0.446 - ETA: 56s - loss: 0.4859 - mean_iou: 0.446 - ETA: 55s - loss: 0.4874 - mean_iou: 0.446 - ETA: 53s - loss: 0.4862 - mean_iou: 0.446 - ETA: 52s - loss: 0.4882 - mean_iou: 0.446 - ETA: 51s - loss: 0.4881 - mean_iou: 0.446 - ETA: 50s - loss: 0.4843 - mean_iou: 0.446 - ETA: 48s - loss: 0.4829 - mean_iou: 0.446 - ETA: 47s - loss: 0.4789 - mean_iou: 0.446 - ETA: 45s - loss: 0.4765 - mean_iou: 0.446 - ETA: 43s - loss: 0.4782 - mean_iou: 0.446 - ETA: 41s - loss: 0.4769 - mean_iou: 0.446 - ETA: 40s - loss: 0.4764 - mean_iou: 0.446 - ETA: 38s - loss: 0.4750 - mean_iou: 0.446 - ETA: 36s - loss: 0.4750 - mean_iou: 0.446 - ETA: 35s - loss: 0.4762 - mean_iou: 0.446 - ETA: 33s - loss: 0.4770 - mean_iou: 0.446 - ETA: 32s - loss: 0.4768 - mean_iou: 0.446 - ETA: 30s - loss: 0.4755 - mean_iou: 0.446 - ETA: 28s - loss: 0.4748 - mean_iou: 0.446 - ETA: 27s - loss: 0.4744 - mean_iou: 0.446 - ETA: 25s - loss: 0.4752 - mean_iou: 0.446 - ETA: 23s - loss: 0.4758 - mean_iou: 0.446 - ETA: 22s - loss: 0.4752 - mean_iou: 0.446 - ETA: 20s - loss: 0.4749 - mean_iou: 0.446 - ETA: 19s - loss: 0.4748 - mean_iou: 0.446 - ETA: 17s - loss: 0.4742 - mean_iou: 0.446 - ETA: 15s - loss: 0.4736 - mean_iou: 0.446 - ETA: 14s - loss: 0.4738 - mean_iou: 0.446 - ETA: 12s - loss: 0.4737 - mean_iou: 0.446 - ETA: 10s - loss: 0.4737 - mean_iou: 0.446 - ETA: 9s - loss: 0.4732 - mean_iou: 0.446 - ETA: 7s - loss: 0.4730 - mean_iou: 0.44 - ETA: 6s - loss: 0.4727 - mean_iou: 0.44 - ETA: 4s - loss: 0.4724 - mean_iou: 0.44 - ETA: 2s - loss: 0.4721 - mean_iou: 0.44 - ETA: 1s - loss: 0.4723 - mean_iou: 0.4462Epoch 00021: val_loss improved from 0.46729 to 0.46225, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.4726 - mean_iou: 0.4462 - val_loss: 0.4623 - val_mean_iou: 0.4462\n",
      "Epoch 23/100\n",
      "592/603 [============================>.] - ETA: 62s - loss: 0.4583 - mean_iou: 0.446 - ETA: 58s - loss: 0.4656 - mean_iou: 0.446 - ETA: 56s - loss: 0.4784 - mean_iou: 0.446 - ETA: 54s - loss: 0.4793 - mean_iou: 0.446 - ETA: 52s - loss: 0.4762 - mean_iou: 0.446 - ETA: 51s - loss: 0.4781 - mean_iou: 0.446 - ETA: 49s - loss: 0.4773 - mean_iou: 0.446 - ETA: 47s - loss: 0.4791 - mean_iou: 0.446 - ETA: 46s - loss: 0.4799 - mean_iou: 0.446 - ETA: 45s - loss: 0.4788 - mean_iou: 0.446 - ETA: 44s - loss: 0.4782 - mean_iou: 0.446 - ETA: 42s - loss: 0.4761 - mean_iou: 0.446 - ETA: 41s - loss: 0.4743 - mean_iou: 0.446 - ETA: 39s - loss: 0.4729 - mean_iou: 0.446 - ETA: 37s - loss: 0.4731 - mean_iou: 0.446 - ETA: 35s - loss: 0.4725 - mean_iou: 0.446 - ETA: 34s - loss: 0.4717 - mean_iou: 0.446 - ETA: 32s - loss: 0.4727 - mean_iou: 0.446 - ETA: 31s - loss: 0.4713 - mean_iou: 0.446 - ETA: 29s - loss: 0.4714 - mean_iou: 0.446 - ETA: 27s - loss: 0.4700 - mean_iou: 0.446 - ETA: 26s - loss: 0.4713 - mean_iou: 0.446 - ETA: 24s - loss: 0.4701 - mean_iou: 0.446 - ETA: 22s - loss: 0.4701 - mean_iou: 0.446 - ETA: 21s - loss: 0.4711 - mean_iou: 0.446 - ETA: 19s - loss: 0.4697 - mean_iou: 0.446 - ETA: 17s - loss: 0.4691 - mean_iou: 0.446 - ETA: 16s - loss: 0.4696 - mean_iou: 0.446 - ETA: 14s - loss: 0.4700 - mean_iou: 0.446 - ETA: 12s - loss: 0.4695 - mean_iou: 0.446 - ETA: 11s - loss: 0.4697 - mean_iou: 0.446 - ETA: 9s - loss: 0.4686 - mean_iou: 0.446 - ETA: 7s - loss: 0.4680 - mean_iou: 0.44 - ETA: 6s - loss: 0.4682 - mean_iou: 0.44 - ETA: 4s - loss: 0.4681 - mean_iou: 0.44 - ETA: 2s - loss: 0.4680 - mean_iou: 0.44 - ETA: 1s - loss: 0.4681 - mean_iou: 0.4461Epoch 00022: val_loss improved from 0.46225 to 0.45513, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 65s - loss: 0.4681 - mean_iou: 0.4461 - val_loss: 0.4551 - val_mean_iou: 0.4461\n",
      "Epoch 24/100\n",
      "592/603 [============================>.] - ETA: 60s - loss: 0.4912 - mean_iou: 0.446 - ETA: 58s - loss: 0.4803 - mean_iou: 0.446 - ETA: 57s - loss: 0.4716 - mean_iou: 0.446 - ETA: 55s - loss: 0.4695 - mean_iou: 0.446 - ETA: 53s - loss: 0.4625 - mean_iou: 0.446 - ETA: 51s - loss: 0.4630 - mean_iou: 0.446 - ETA: 49s - loss: 0.4630 - mean_iou: 0.446 - ETA: 47s - loss: 0.4635 - mean_iou: 0.446 - ETA: 46s - loss: 0.4627 - mean_iou: 0.446 - ETA: 44s - loss: 0.4616 - mean_iou: 0.446 - ETA: 43s - loss: 0.4622 - mean_iou: 0.446 - ETA: 41s - loss: 0.4609 - mean_iou: 0.446 - ETA: 39s - loss: 0.4609 - mean_iou: 0.446 - ETA: 38s - loss: 0.4600 - mean_iou: 0.446 - ETA: 36s - loss: 0.4602 - mean_iou: 0.446 - ETA: 34s - loss: 0.4584 - mean_iou: 0.446 - ETA: 33s - loss: 0.4573 - mean_iou: 0.446 - ETA: 31s - loss: 0.4597 - mean_iou: 0.446 - ETA: 30s - loss: 0.4588 - mean_iou: 0.446 - ETA: 28s - loss: 0.4587 - mean_iou: 0.446 - ETA: 27s - loss: 0.4586 - mean_iou: 0.446 - ETA: 25s - loss: 0.4586 - mean_iou: 0.446 - ETA: 23s - loss: 0.4592 - mean_iou: 0.446 - ETA: 22s - loss: 0.4595 - mean_iou: 0.446 - ETA: 20s - loss: 0.4586 - mean_iou: 0.446 - ETA: 18s - loss: 0.4599 - mean_iou: 0.446 - ETA: 17s - loss: 0.4599 - mean_iou: 0.446 - ETA: 15s - loss: 0.4602 - mean_iou: 0.446 - ETA: 14s - loss: 0.4597 - mean_iou: 0.446 - ETA: 12s - loss: 0.4588 - mean_iou: 0.446 - ETA: 10s - loss: 0.4588 - mean_iou: 0.446 - ETA: 9s - loss: 0.4589 - mean_iou: 0.446 - ETA: 7s - loss: 0.4587 - mean_iou: 0.44 - ETA: 5s - loss: 0.4584 - mean_iou: 0.44 - ETA: 4s - loss: 0.4577 - mean_iou: 0.44 - ETA: 2s - loss: 0.4579 - mean_iou: 0.44 - ETA: 1s - loss: 0.4574 - mean_iou: 0.4460Epoch 00023: val_loss improved from 0.45513 to 0.44777, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.4579 - mean_iou: 0.4460 - val_loss: 0.4478 - val_mean_iou: 0.4460\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 59s - loss: 0.4323 - mean_iou: 0.446 - ETA: 56s - loss: 0.4364 - mean_iou: 0.446 - ETA: 55s - loss: 0.4413 - mean_iou: 0.446 - ETA: 54s - loss: 0.4451 - mean_iou: 0.446 - ETA: 53s - loss: 0.4461 - mean_iou: 0.446 - ETA: 51s - loss: 0.4466 - mean_iou: 0.446 - ETA: 50s - loss: 0.4475 - mean_iou: 0.446 - ETA: 48s - loss: 0.4502 - mean_iou: 0.446 - ETA: 46s - loss: 0.4519 - mean_iou: 0.446 - ETA: 45s - loss: 0.4509 - mean_iou: 0.446 - ETA: 43s - loss: 0.4501 - mean_iou: 0.446 - ETA: 41s - loss: 0.4507 - mean_iou: 0.446 - ETA: 40s - loss: 0.4525 - mean_iou: 0.446 - ETA: 38s - loss: 0.4525 - mean_iou: 0.446 - ETA: 37s - loss: 0.4506 - mean_iou: 0.446 - ETA: 35s - loss: 0.4490 - mean_iou: 0.446 - ETA: 33s - loss: 0.4494 - mean_iou: 0.446 - ETA: 32s - loss: 0.4489 - mean_iou: 0.446 - ETA: 30s - loss: 0.4489 - mean_iou: 0.446 - ETA: 29s - loss: 0.4483 - mean_iou: 0.446 - ETA: 27s - loss: 0.4475 - mean_iou: 0.446 - ETA: 25s - loss: 0.4470 - mean_iou: 0.446 - ETA: 23s - loss: 0.4474 - mean_iou: 0.446 - ETA: 22s - loss: 0.4474 - mean_iou: 0.446 - ETA: 20s - loss: 0.4475 - mean_iou: 0.446 - ETA: 19s - loss: 0.4479 - mean_iou: 0.446 - ETA: 17s - loss: 0.4483 - mean_iou: 0.446 - ETA: 15s - loss: 0.4492 - mean_iou: 0.446 - ETA: 14s - loss: 0.4488 - mean_iou: 0.446 - ETA: 12s - loss: 0.4484 - mean_iou: 0.446 - ETA: 10s - loss: 0.4479 - mean_iou: 0.446 - ETA: 9s - loss: 0.4480 - mean_iou: 0.446 - ETA: 7s - loss: 0.4472 - mean_iou: 0.44 - ETA: 5s - loss: 0.4478 - mean_iou: 0.44 - ETA: 4s - loss: 0.4485 - mean_iou: 0.44 - ETA: 2s - loss: 0.4484 - mean_iou: 0.44 - ETA: 1s - loss: 0.4481 - mean_iou: 0.4460Epoch 00024: val_loss improved from 0.44777 to 0.43761, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.4483 - mean_iou: 0.4460 - val_loss: 0.4376 - val_mean_iou: 0.4460\n",
      "Epoch 26/100\n",
      "592/603 [============================>.] - ETA: 60s - loss: 0.4496 - mean_iou: 0.446 - ETA: 59s - loss: 0.4619 - mean_iou: 0.446 - ETA: 56s - loss: 0.4538 - mean_iou: 0.446 - ETA: 54s - loss: 0.4515 - mean_iou: 0.446 - ETA: 53s - loss: 0.4534 - mean_iou: 0.446 - ETA: 51s - loss: 0.4560 - mean_iou: 0.446 - ETA: 49s - loss: 0.4525 - mean_iou: 0.445 - ETA: 48s - loss: 0.4491 - mean_iou: 0.445 - ETA: 46s - loss: 0.4484 - mean_iou: 0.445 - ETA: 45s - loss: 0.4460 - mean_iou: 0.445 - ETA: 43s - loss: 0.4470 - mean_iou: 0.445 - ETA: 42s - loss: 0.4458 - mean_iou: 0.445 - ETA: 40s - loss: 0.4467 - mean_iou: 0.446 - ETA: 39s - loss: 0.4471 - mean_iou: 0.446 - ETA: 37s - loss: 0.4457 - mean_iou: 0.446 - ETA: 36s - loss: 0.4457 - mean_iou: 0.446 - ETA: 34s - loss: 0.4448 - mean_iou: 0.446 - ETA: 32s - loss: 0.4448 - mean_iou: 0.446 - ETA: 30s - loss: 0.4455 - mean_iou: 0.446 - ETA: 29s - loss: 0.4450 - mean_iou: 0.446 - ETA: 27s - loss: 0.4448 - mean_iou: 0.446 - ETA: 25s - loss: 0.4445 - mean_iou: 0.446 - ETA: 24s - loss: 0.4442 - mean_iou: 0.446 - ETA: 22s - loss: 0.4443 - mean_iou: 0.446 - ETA: 20s - loss: 0.4442 - mean_iou: 0.446 - ETA: 19s - loss: 0.4435 - mean_iou: 0.446 - ETA: 17s - loss: 0.4439 - mean_iou: 0.446 - ETA: 15s - loss: 0.4440 - mean_iou: 0.446 - ETA: 14s - loss: 0.4445 - mean_iou: 0.446 - ETA: 12s - loss: 0.4451 - mean_iou: 0.445 - ETA: 10s - loss: 0.4441 - mean_iou: 0.445 - ETA: 9s - loss: 0.4442 - mean_iou: 0.445 - ETA: 7s - loss: 0.4437 - mean_iou: 0.44 - ETA: 6s - loss: 0.4432 - mean_iou: 0.44 - ETA: 4s - loss: 0.4429 - mean_iou: 0.44 - ETA: 2s - loss: 0.4421 - mean_iou: 0.44 - ETA: 1s - loss: 0.4419 - mean_iou: 0.4459Epoch 00025: val_loss improved from 0.43761 to 0.43020, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.4419 - mean_iou: 0.4459 - val_loss: 0.4302 - val_mean_iou: 0.4459\n",
      "Epoch 27/100\n",
      "592/603 [============================>.] - ETA: 59s - loss: 0.4841 - mean_iou: 0.446 - ETA: 57s - loss: 0.4584 - mean_iou: 0.445 - ETA: 55s - loss: 0.4500 - mean_iou: 0.445 - ETA: 54s - loss: 0.4471 - mean_iou: 0.445 - ETA: 53s - loss: 0.4448 - mean_iou: 0.445 - ETA: 51s - loss: 0.4469 - mean_iou: 0.445 - ETA: 50s - loss: 0.4450 - mean_iou: 0.445 - ETA: 49s - loss: 0.4447 - mean_iou: 0.445 - ETA: 47s - loss: 0.4406 - mean_iou: 0.445 - ETA: 45s - loss: 0.4397 - mean_iou: 0.445 - ETA: 44s - loss: 0.4399 - mean_iou: 0.445 - ETA: 43s - loss: 0.4389 - mean_iou: 0.445 - ETA: 41s - loss: 0.4380 - mean_iou: 0.445 - ETA: 39s - loss: 0.4410 - mean_iou: 0.445 - ETA: 37s - loss: 0.4401 - mean_iou: 0.445 - ETA: 36s - loss: 0.4403 - mean_iou: 0.445 - ETA: 34s - loss: 0.4410 - mean_iou: 0.445 - ETA: 32s - loss: 0.4400 - mean_iou: 0.445 - ETA: 30s - loss: 0.4390 - mean_iou: 0.445 - ETA: 29s - loss: 0.4395 - mean_iou: 0.445 - ETA: 27s - loss: 0.4391 - mean_iou: 0.445 - ETA: 25s - loss: 0.4385 - mean_iou: 0.445 - ETA: 24s - loss: 0.4375 - mean_iou: 0.445 - ETA: 22s - loss: 0.4377 - mean_iou: 0.445 - ETA: 20s - loss: 0.4384 - mean_iou: 0.445 - ETA: 19s - loss: 0.4375 - mean_iou: 0.445 - ETA: 17s - loss: 0.4365 - mean_iou: 0.445 - ETA: 15s - loss: 0.4355 - mean_iou: 0.445 - ETA: 14s - loss: 0.4349 - mean_iou: 0.445 - ETA: 12s - loss: 0.4350 - mean_iou: 0.445 - ETA: 10s - loss: 0.4345 - mean_iou: 0.445 - ETA: 9s - loss: 0.4340 - mean_iou: 0.445 - ETA: 7s - loss: 0.4340 - mean_iou: 0.44 - ETA: 6s - loss: 0.4338 - mean_iou: 0.44 - ETA: 4s - loss: 0.4335 - mean_iou: 0.44 - ETA: 2s - loss: 0.4339 - mean_iou: 0.44 - ETA: 1s - loss: 0.4341 - mean_iou: 0.4459Epoch 00026: val_loss did not improve\n",
      "603/603 [==============================] - 65s - loss: 0.4347 - mean_iou: 0.4459 - val_loss: 0.4312 - val_mean_iou: 0.4459\n",
      "Epoch 28/100\n",
      "592/603 [============================>.] - ETA: 59s - loss: 0.4534 - mean_iou: 0.445 - ETA: 57s - loss: 0.4446 - mean_iou: 0.445 - ETA: 55s - loss: 0.4429 - mean_iou: 0.445 - ETA: 54s - loss: 0.4400 - mean_iou: 0.445 - ETA: 52s - loss: 0.4346 - mean_iou: 0.445 - ETA: 50s - loss: 0.4345 - mean_iou: 0.445 - ETA: 49s - loss: 0.4365 - mean_iou: 0.445 - ETA: 47s - loss: 0.4347 - mean_iou: 0.445 - ETA: 46s - loss: 0.4377 - mean_iou: 0.445 - ETA: 45s - loss: 0.4386 - mean_iou: 0.445 - ETA: 43s - loss: 0.4384 - mean_iou: 0.445 - ETA: 41s - loss: 0.4390 - mean_iou: 0.445 - ETA: 39s - loss: 0.4390 - mean_iou: 0.445 - ETA: 38s - loss: 0.4386 - mean_iou: 0.445 - ETA: 36s - loss: 0.4371 - mean_iou: 0.445 - ETA: 35s - loss: 0.4357 - mean_iou: 0.445 - ETA: 33s - loss: 0.4335 - mean_iou: 0.445 - ETA: 32s - loss: 0.4329 - mean_iou: 0.445 - ETA: 30s - loss: 0.4338 - mean_iou: 0.445 - ETA: 29s - loss: 0.4328 - mean_iou: 0.445 - ETA: 27s - loss: 0.4331 - mean_iou: 0.445 - ETA: 25s - loss: 0.4333 - mean_iou: 0.445 - ETA: 24s - loss: 0.4347 - mean_iou: 0.445 - ETA: 22s - loss: 0.4341 - mean_iou: 0.445 - ETA: 20s - loss: 0.4334 - mean_iou: 0.445 - ETA: 19s - loss: 0.4329 - mean_iou: 0.445 - ETA: 17s - loss: 0.4323 - mean_iou: 0.445 - ETA: 15s - loss: 0.4318 - mean_iou: 0.445 - ETA: 14s - loss: 0.4316 - mean_iou: 0.445 - ETA: 12s - loss: 0.4317 - mean_iou: 0.445 - ETA: 10s - loss: 0.4313 - mean_iou: 0.445 - ETA: 9s - loss: 0.4303 - mean_iou: 0.445 - ETA: 7s - loss: 0.4310 - mean_iou: 0.44 - ETA: 5s - loss: 0.4309 - mean_iou: 0.44 - ETA: 4s - loss: 0.4314 - mean_iou: 0.44 - ETA: 2s - loss: 0.4320 - mean_iou: 0.44 - ETA: 1s - loss: 0.4320 - mean_iou: 0.4459Epoch 00027: val_loss did not improve\n",
      "603/603 [==============================] - 65s - loss: 0.4318 - mean_iou: 0.4459 - val_loss: 0.4309 - val_mean_iou: 0.4459\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 67s - loss: 0.4324 - mean_iou: 0.445 - ETA: 65s - loss: 0.4295 - mean_iou: 0.445 - ETA: 61s - loss: 0.4282 - mean_iou: 0.445 - ETA: 59s - loss: 0.4365 - mean_iou: 0.445 - ETA: 58s - loss: 0.4330 - mean_iou: 0.445 - ETA: 56s - loss: 0.4364 - mean_iou: 0.445 - ETA: 54s - loss: 0.4370 - mean_iou: 0.445 - ETA: 53s - loss: 0.4475 - mean_iou: 0.445 - ETA: 52s - loss: 0.4572 - mean_iou: 0.445 - ETA: 50s - loss: 0.4629 - mean_iou: 0.445 - ETA: 48s - loss: 0.4618 - mean_iou: 0.445 - ETA: 47s - loss: 0.4697 - mean_iou: 0.445 - ETA: 45s - loss: 0.4701 - mean_iou: 0.445 - ETA: 43s - loss: 0.4744 - mean_iou: 0.445 - ETA: 41s - loss: 0.4733 - mean_iou: 0.445 - ETA: 39s - loss: 0.4742 - mean_iou: 0.445 - ETA: 37s - loss: 0.4739 - mean_iou: 0.445 - ETA: 35s - loss: 0.4715 - mean_iou: 0.445 - ETA: 33s - loss: 0.4685 - mean_iou: 0.445 - ETA: 31s - loss: 0.4715 - mean_iou: 0.445 - ETA: 29s - loss: 0.4691 - mean_iou: 0.445 - ETA: 27s - loss: 0.4687 - mean_iou: 0.445 - ETA: 25s - loss: 0.4673 - mean_iou: 0.445 - ETA: 23s - loss: 0.4655 - mean_iou: 0.445 - ETA: 22s - loss: 0.4632 - mean_iou: 0.445 - ETA: 20s - loss: 0.4636 - mean_iou: 0.445 - ETA: 18s - loss: 0.4629 - mean_iou: 0.445 - ETA: 16s - loss: 0.4626 - mean_iou: 0.445 - ETA: 14s - loss: 0.4610 - mean_iou: 0.445 - ETA: 13s - loss: 0.4611 - mean_iou: 0.445 - ETA: 11s - loss: 0.4604 - mean_iou: 0.445 - ETA: 9s - loss: 0.4585 - mean_iou: 0.445 - ETA: 8s - loss: 0.4574 - mean_iou: 0.44 - ETA: 6s - loss: 0.4569 - mean_iou: 0.44 - ETA: 4s - loss: 0.4569 - mean_iou: 0.44 - ETA: 2s - loss: 0.4564 - mean_iou: 0.44 - ETA: 1s - loss: 0.4555 - mean_iou: 0.4457Epoch 00028: val_loss improved from 0.43020 to 0.41861, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 70s - loss: 0.4556 - mean_iou: 0.4457 - val_loss: 0.4186 - val_mean_iou: 0.4456\n",
      "Epoch 30/100\n",
      "592/603 [============================>.] - ETA: 61s - loss: 0.4361 - mean_iou: 0.445 - ETA: 58s - loss: 0.4310 - mean_iou: 0.445 - ETA: 57s - loss: 0.4279 - mean_iou: 0.445 - ETA: 55s - loss: 0.4277 - mean_iou: 0.445 - ETA: 56s - loss: 0.4311 - mean_iou: 0.445 - ETA: 55s - loss: 0.4336 - mean_iou: 0.445 - ETA: 53s - loss: 0.4303 - mean_iou: 0.445 - ETA: 50s - loss: 0.4294 - mean_iou: 0.445 - ETA: 48s - loss: 0.4254 - mean_iou: 0.445 - ETA: 46s - loss: 0.4295 - mean_iou: 0.445 - ETA: 44s - loss: 0.4300 - mean_iou: 0.445 - ETA: 43s - loss: 0.4297 - mean_iou: 0.445 - ETA: 41s - loss: 0.4277 - mean_iou: 0.445 - ETA: 39s - loss: 0.4279 - mean_iou: 0.445 - ETA: 37s - loss: 0.4295 - mean_iou: 0.445 - ETA: 36s - loss: 0.4284 - mean_iou: 0.445 - ETA: 34s - loss: 0.4301 - mean_iou: 0.445 - ETA: 32s - loss: 0.4287 - mean_iou: 0.445 - ETA: 31s - loss: 0.4290 - mean_iou: 0.445 - ETA: 29s - loss: 0.4284 - mean_iou: 0.445 - ETA: 27s - loss: 0.4292 - mean_iou: 0.445 - ETA: 26s - loss: 0.4296 - mean_iou: 0.445 - ETA: 24s - loss: 0.4287 - mean_iou: 0.445 - ETA: 23s - loss: 0.4301 - mean_iou: 0.445 - ETA: 21s - loss: 0.4296 - mean_iou: 0.445 - ETA: 19s - loss: 0.4293 - mean_iou: 0.445 - ETA: 18s - loss: 0.4299 - mean_iou: 0.445 - ETA: 16s - loss: 0.4303 - mean_iou: 0.445 - ETA: 14s - loss: 0.4307 - mean_iou: 0.445 - ETA: 13s - loss: 0.4299 - mean_iou: 0.445 - ETA: 11s - loss: 0.4289 - mean_iou: 0.445 - ETA: 9s - loss: 0.4284 - mean_iou: 0.445 - ETA: 8s - loss: 0.4283 - mean_iou: 0.44 - ETA: 6s - loss: 0.4275 - mean_iou: 0.44 - ETA: 4s - loss: 0.4267 - mean_iou: 0.44 - ETA: 2s - loss: 0.4264 - mean_iou: 0.44 - ETA: 1s - loss: 0.4270 - mean_iou: 0.4456Epoch 00029: val_loss improved from 0.41861 to 0.41131, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 69s - loss: 0.4277 - mean_iou: 0.4456 - val_loss: 0.4113 - val_mean_iou: 0.4455\n",
      "Epoch 31/100\n",
      "592/603 [============================>.] - ETA: 61s - loss: 0.4369 - mean_iou: 0.445 - ETA: 73s - loss: 0.4265 - mean_iou: 0.445 - ETA: 74s - loss: 0.4292 - mean_iou: 0.445 - ETA: 72s - loss: 0.4266 - mean_iou: 0.445 - ETA: 75s - loss: 0.4249 - mean_iou: 0.445 - ETA: 75s - loss: 0.4236 - mean_iou: 0.445 - ETA: 74s - loss: 0.4228 - mean_iou: 0.445 - ETA: 72s - loss: 0.4172 - mean_iou: 0.445 - ETA: 69s - loss: 0.4174 - mean_iou: 0.445 - ETA: 64s - loss: 0.4156 - mean_iou: 0.445 - ETA: 61s - loss: 0.4155 - mean_iou: 0.445 - ETA: 58s - loss: 0.4174 - mean_iou: 0.445 - ETA: 57s - loss: 0.4173 - mean_iou: 0.445 - ETA: 54s - loss: 0.4208 - mean_iou: 0.445 - ETA: 51s - loss: 0.4192 - mean_iou: 0.445 - ETA: 48s - loss: 0.4204 - mean_iou: 0.445 - ETA: 45s - loss: 0.4211 - mean_iou: 0.445 - ETA: 43s - loss: 0.4207 - mean_iou: 0.445 - ETA: 40s - loss: 0.4202 - mean_iou: 0.445 - ETA: 38s - loss: 0.4197 - mean_iou: 0.445 - ETA: 35s - loss: 0.4194 - mean_iou: 0.445 - ETA: 33s - loss: 0.4201 - mean_iou: 0.445 - ETA: 30s - loss: 0.4198 - mean_iou: 0.445 - ETA: 28s - loss: 0.4216 - mean_iou: 0.445 - ETA: 26s - loss: 0.4200 - mean_iou: 0.445 - ETA: 24s - loss: 0.4203 - mean_iou: 0.445 - ETA: 22s - loss: 0.4200 - mean_iou: 0.445 - ETA: 20s - loss: 0.4194 - mean_iou: 0.445 - ETA: 18s - loss: 0.4207 - mean_iou: 0.445 - ETA: 16s - loss: 0.4199 - mean_iou: 0.445 - ETA: 13s - loss: 0.4199 - mean_iou: 0.445 - ETA: 11s - loss: 0.4207 - mean_iou: 0.445 - ETA: 9s - loss: 0.4210 - mean_iou: 0.445 - ETA: 7s - loss: 0.4211 - mean_iou: 0.44 - ETA: 5s - loss: 0.4211 - mean_iou: 0.44 - ETA: 3s - loss: 0.4206 - mean_iou: 0.44 - ETA: 1s - loss: 0.4201 - mean_iou: 0.4455Epoch 00030: val_loss improved from 0.41131 to 0.40658, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 79s - loss: 0.4193 - mean_iou: 0.4455 - val_loss: 0.4066 - val_mean_iou: 0.4454\n",
      "Epoch 32/100\n",
      "592/603 [============================>.] - ETA: 59s - loss: 0.3972 - mean_iou: 0.445 - ETA: 57s - loss: 0.4085 - mean_iou: 0.445 - ETA: 61s - loss: 0.4279 - mean_iou: 0.445 - ETA: 59s - loss: 0.4243 - mean_iou: 0.445 - ETA: 57s - loss: 0.4287 - mean_iou: 0.445 - ETA: 55s - loss: 0.4215 - mean_iou: 0.445 - ETA: 53s - loss: 0.4179 - mean_iou: 0.445 - ETA: 51s - loss: 0.4154 - mean_iou: 0.445 - ETA: 49s - loss: 0.4157 - mean_iou: 0.445 - ETA: 47s - loss: 0.4165 - mean_iou: 0.445 - ETA: 45s - loss: 0.4177 - mean_iou: 0.445 - ETA: 43s - loss: 0.4185 - mean_iou: 0.445 - ETA: 42s - loss: 0.4173 - mean_iou: 0.445 - ETA: 40s - loss: 0.4185 - mean_iou: 0.445 - ETA: 38s - loss: 0.4182 - mean_iou: 0.445 - ETA: 37s - loss: 0.4178 - mean_iou: 0.445 - ETA: 35s - loss: 0.4171 - mean_iou: 0.445 - ETA: 33s - loss: 0.4166 - mean_iou: 0.445 - ETA: 32s - loss: 0.4153 - mean_iou: 0.445 - ETA: 30s - loss: 0.4146 - mean_iou: 0.445 - ETA: 29s - loss: 0.4130 - mean_iou: 0.445 - ETA: 27s - loss: 0.4111 - mean_iou: 0.445 - ETA: 25s - loss: 0.4116 - mean_iou: 0.445 - ETA: 23s - loss: 0.4121 - mean_iou: 0.445 - ETA: 22s - loss: 0.4121 - mean_iou: 0.445 - ETA: 20s - loss: 0.4123 - mean_iou: 0.445 - ETA: 18s - loss: 0.4120 - mean_iou: 0.445 - ETA: 16s - loss: 0.4132 - mean_iou: 0.445 - ETA: 15s - loss: 0.4134 - mean_iou: 0.445 - ETA: 13s - loss: 0.4128 - mean_iou: 0.445 - ETA: 11s - loss: 0.4129 - mean_iou: 0.445 - ETA: 9s - loss: 0.4125 - mean_iou: 0.445 - ETA: 8s - loss: 0.4123 - mean_iou: 0.44 - ETA: 6s - loss: 0.4120 - mean_iou: 0.44 - ETA: 4s - loss: 0.4114 - mean_iou: 0.44 - ETA: 2s - loss: 0.4106 - mean_iou: 0.44 - ETA: 1s - loss: 0.4098 - mean_iou: 0.4454Epoch 00031: val_loss improved from 0.40658 to 0.39539, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 67s - loss: 0.4094 - mean_iou: 0.4454 - val_loss: 0.3954 - val_mean_iou: 0.4454\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 61s - loss: 0.3957 - mean_iou: 0.445 - ETA: 58s - loss: 0.4028 - mean_iou: 0.445 - ETA: 56s - loss: 0.4024 - mean_iou: 0.445 - ETA: 54s - loss: 0.4065 - mean_iou: 0.445 - ETA: 53s - loss: 0.4117 - mean_iou: 0.445 - ETA: 52s - loss: 0.4140 - mean_iou: 0.445 - ETA: 50s - loss: 0.4149 - mean_iou: 0.445 - ETA: 48s - loss: 0.4097 - mean_iou: 0.445 - ETA: 47s - loss: 0.4140 - mean_iou: 0.445 - ETA: 46s - loss: 0.4152 - mean_iou: 0.445 - ETA: 45s - loss: 0.4141 - mean_iou: 0.445 - ETA: 43s - loss: 0.4130 - mean_iou: 0.445 - ETA: 43s - loss: 0.4126 - mean_iou: 0.445 - ETA: 43s - loss: 0.4141 - mean_iou: 0.445 - ETA: 42s - loss: 0.4124 - mean_iou: 0.445 - ETA: 42s - loss: 0.4113 - mean_iou: 0.445 - ETA: 42s - loss: 0.4105 - mean_iou: 0.445 - ETA: 41s - loss: 0.4104 - mean_iou: 0.445 - ETA: 39s - loss: 0.4111 - mean_iou: 0.445 - ETA: 37s - loss: 0.4119 - mean_iou: 0.445 - ETA: 36s - loss: 0.4127 - mean_iou: 0.445 - ETA: 34s - loss: 0.4123 - mean_iou: 0.445 - ETA: 31s - loss: 0.4106 - mean_iou: 0.445 - ETA: 29s - loss: 0.4107 - mean_iou: 0.445 - ETA: 27s - loss: 0.4105 - mean_iou: 0.445 - ETA: 25s - loss: 0.4099 - mean_iou: 0.445 - ETA: 23s - loss: 0.4095 - mean_iou: 0.445 - ETA: 21s - loss: 0.4089 - mean_iou: 0.445 - ETA: 19s - loss: 0.4075 - mean_iou: 0.445 - ETA: 17s - loss: 0.4076 - mean_iou: 0.445 - ETA: 14s - loss: 0.4071 - mean_iou: 0.445 - ETA: 12s - loss: 0.4075 - mean_iou: 0.445 - ETA: 10s - loss: 0.4069 - mean_iou: 0.445 - ETA: 8s - loss: 0.4060 - mean_iou: 0.445 - ETA: 5s - loss: 0.4060 - mean_iou: 0.44 - ETA: 3s - loss: 0.4063 - mean_iou: 0.44 - ETA: 1s - loss: 0.4055 - mean_iou: 0.4454Epoch 00032: val_loss improved from 0.39539 to 0.38999, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 85s - loss: 0.4046 - mean_iou: 0.4454 - val_loss: 0.3900 - val_mean_iou: 0.4454\n",
      "Epoch 34/100\n",
      "592/603 [============================>.] - ETA: 66s - loss: 0.4030 - mean_iou: 0.445 - ETA: 63s - loss: 0.3895 - mean_iou: 0.445 - ETA: 60s - loss: 0.3910 - mean_iou: 0.445 - ETA: 61s - loss: 0.3919 - mean_iou: 0.445 - ETA: 59s - loss: 0.3937 - mean_iou: 0.445 - ETA: 57s - loss: 0.3931 - mean_iou: 0.445 - ETA: 55s - loss: 0.3934 - mean_iou: 0.445 - ETA: 52s - loss: 0.3918 - mean_iou: 0.445 - ETA: 51s - loss: 0.3887 - mean_iou: 0.445 - ETA: 49s - loss: 0.3863 - mean_iou: 0.445 - ETA: 47s - loss: 0.3879 - mean_iou: 0.445 - ETA: 45s - loss: 0.3896 - mean_iou: 0.445 - ETA: 43s - loss: 0.3903 - mean_iou: 0.445 - ETA: 41s - loss: 0.3938 - mean_iou: 0.445 - ETA: 39s - loss: 0.3947 - mean_iou: 0.445 - ETA: 37s - loss: 0.3950 - mean_iou: 0.445 - ETA: 36s - loss: 0.3964 - mean_iou: 0.445 - ETA: 34s - loss: 0.3967 - mean_iou: 0.445 - ETA: 32s - loss: 0.3973 - mean_iou: 0.445 - ETA: 30s - loss: 0.3985 - mean_iou: 0.445 - ETA: 28s - loss: 0.3980 - mean_iou: 0.445 - ETA: 27s - loss: 0.3974 - mean_iou: 0.445 - ETA: 25s - loss: 0.3988 - mean_iou: 0.445 - ETA: 23s - loss: 0.3989 - mean_iou: 0.445 - ETA: 21s - loss: 0.3992 - mean_iou: 0.445 - ETA: 19s - loss: 0.3994 - mean_iou: 0.445 - ETA: 18s - loss: 0.3994 - mean_iou: 0.445 - ETA: 16s - loss: 0.3991 - mean_iou: 0.445 - ETA: 14s - loss: 0.3994 - mean_iou: 0.445 - ETA: 13s - loss: 0.4000 - mean_iou: 0.445 - ETA: 11s - loss: 0.4007 - mean_iou: 0.445 - ETA: 9s - loss: 0.4008 - mean_iou: 0.445 - ETA: 8s - loss: 0.4016 - mean_iou: 0.44 - ETA: 6s - loss: 0.4007 - mean_iou: 0.44 - ETA: 4s - loss: 0.4009 - mean_iou: 0.44 - ETA: 2s - loss: 0.4009 - mean_iou: 0.44 - ETA: 1s - loss: 0.4003 - mean_iou: 0.4454Epoch 00033: val_loss improved from 0.38999 to 0.38713, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 68s - loss: 0.4004 - mean_iou: 0.4454 - val_loss: 0.3871 - val_mean_iou: 0.4453\n",
      "Epoch 35/100\n",
      "592/603 [============================>.] - ETA: 67s - loss: 0.4065 - mean_iou: 0.445 - ETA: 62s - loss: 0.3950 - mean_iou: 0.445 - ETA: 59s - loss: 0.3993 - mean_iou: 0.445 - ETA: 56s - loss: 0.4009 - mean_iou: 0.445 - ETA: 54s - loss: 0.3994 - mean_iou: 0.445 - ETA: 54s - loss: 0.4020 - mean_iou: 0.445 - ETA: 52s - loss: 0.4042 - mean_iou: 0.445 - ETA: 50s - loss: 0.4016 - mean_iou: 0.445 - ETA: 48s - loss: 0.3991 - mean_iou: 0.445 - ETA: 46s - loss: 0.3956 - mean_iou: 0.445 - ETA: 44s - loss: 0.3982 - mean_iou: 0.445 - ETA: 42s - loss: 0.3963 - mean_iou: 0.445 - ETA: 41s - loss: 0.3976 - mean_iou: 0.445 - ETA: 39s - loss: 0.3960 - mean_iou: 0.445 - ETA: 37s - loss: 0.3957 - mean_iou: 0.445 - ETA: 35s - loss: 0.3956 - mean_iou: 0.445 - ETA: 34s - loss: 0.3957 - mean_iou: 0.445 - ETA: 32s - loss: 0.3943 - mean_iou: 0.445 - ETA: 30s - loss: 0.3929 - mean_iou: 0.445 - ETA: 29s - loss: 0.3917 - mean_iou: 0.445 - ETA: 27s - loss: 0.3909 - mean_iou: 0.445 - ETA: 26s - loss: 0.3923 - mean_iou: 0.445 - ETA: 24s - loss: 0.3920 - mean_iou: 0.445 - ETA: 22s - loss: 0.3927 - mean_iou: 0.445 - ETA: 21s - loss: 0.3934 - mean_iou: 0.445 - ETA: 19s - loss: 0.3932 - mean_iou: 0.445 - ETA: 17s - loss: 0.3937 - mean_iou: 0.445 - ETA: 16s - loss: 0.3944 - mean_iou: 0.445 - ETA: 14s - loss: 0.3941 - mean_iou: 0.445 - ETA: 12s - loss: 0.3934 - mean_iou: 0.445 - ETA: 11s - loss: 0.3925 - mean_iou: 0.445 - ETA: 9s - loss: 0.3941 - mean_iou: 0.445 - ETA: 8s - loss: 0.3944 - mean_iou: 0.44 - ETA: 6s - loss: 0.3937 - mean_iou: 0.44 - ETA: 4s - loss: 0.3941 - mean_iou: 0.44 - ETA: 2s - loss: 0.3949 - mean_iou: 0.44 - ETA: 1s - loss: 0.3944 - mean_iou: 0.4453Epoch 00034: val_loss improved from 0.38713 to 0.38150, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 70s - loss: 0.3939 - mean_iou: 0.4453 - val_loss: 0.3815 - val_mean_iou: 0.4453\n",
      "Epoch 36/100\n",
      "592/603 [============================>.] - ETA: 72s - loss: 0.3633 - mean_iou: 0.445 - ETA: 69s - loss: 0.3685 - mean_iou: 0.445 - ETA: 68s - loss: 0.3719 - mean_iou: 0.445 - ETA: 64s - loss: 0.3740 - mean_iou: 0.445 - ETA: 63s - loss: 0.3805 - mean_iou: 0.445 - ETA: 61s - loss: 0.3787 - mean_iou: 0.445 - ETA: 60s - loss: 0.3787 - mean_iou: 0.445 - ETA: 59s - loss: 0.3833 - mean_iou: 0.445 - ETA: 56s - loss: 0.3843 - mean_iou: 0.445 - ETA: 54s - loss: 0.3832 - mean_iou: 0.445 - ETA: 52s - loss: 0.3826 - mean_iou: 0.445 - ETA: 50s - loss: 0.3814 - mean_iou: 0.445 - ETA: 47s - loss: 0.3807 - mean_iou: 0.445 - ETA: 45s - loss: 0.3809 - mean_iou: 0.445 - ETA: 43s - loss: 0.3804 - mean_iou: 0.445 - ETA: 41s - loss: 0.3827 - mean_iou: 0.445 - ETA: 39s - loss: 0.3809 - mean_iou: 0.445 - ETA: 37s - loss: 0.3820 - mean_iou: 0.445 - ETA: 35s - loss: 0.3821 - mean_iou: 0.445 - ETA: 33s - loss: 0.3823 - mean_iou: 0.445 - ETA: 31s - loss: 0.3825 - mean_iou: 0.445 - ETA: 29s - loss: 0.3824 - mean_iou: 0.445 - ETA: 27s - loss: 0.3816 - mean_iou: 0.445 - ETA: 26s - loss: 0.3818 - mean_iou: 0.445 - ETA: 24s - loss: 0.3831 - mean_iou: 0.445 - ETA: 22s - loss: 0.3834 - mean_iou: 0.445 - ETA: 20s - loss: 0.3846 - mean_iou: 0.445 - ETA: 18s - loss: 0.3851 - mean_iou: 0.445 - ETA: 16s - loss: 0.3852 - mean_iou: 0.445 - ETA: 14s - loss: 0.3851 - mean_iou: 0.445 - ETA: 12s - loss: 0.3855 - mean_iou: 0.445 - ETA: 10s - loss: 0.3852 - mean_iou: 0.445 - ETA: 8s - loss: 0.3854 - mean_iou: 0.445 - ETA: 7s - loss: 0.3853 - mean_iou: 0.44 - ETA: 5s - loss: 0.3852 - mean_iou: 0.44 - ETA: 3s - loss: 0.3853 - mean_iou: 0.44 - ETA: 1s - loss: 0.3854 - mean_iou: 0.4454Epoch 00035: val_loss improved from 0.38150 to 0.37313, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 75s - loss: 0.3852 - mean_iou: 0.4454 - val_loss: 0.3731 - val_mean_iou: 0.4456\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 59s - loss: 0.3566 - mean_iou: 0.445 - ETA: 58s - loss: 0.3701 - mean_iou: 0.445 - ETA: 56s - loss: 0.3708 - mean_iou: 0.445 - ETA: 54s - loss: 0.3724 - mean_iou: 0.445 - ETA: 53s - loss: 0.3763 - mean_iou: 0.445 - ETA: 52s - loss: 0.3771 - mean_iou: 0.445 - ETA: 50s - loss: 0.3770 - mean_iou: 0.445 - ETA: 49s - loss: 0.3781 - mean_iou: 0.445 - ETA: 48s - loss: 0.3770 - mean_iou: 0.445 - ETA: 46s - loss: 0.3793 - mean_iou: 0.445 - ETA: 44s - loss: 0.3780 - mean_iou: 0.445 - ETA: 43s - loss: 0.3779 - mean_iou: 0.445 - ETA: 41s - loss: 0.3810 - mean_iou: 0.445 - ETA: 39s - loss: 0.3808 - mean_iou: 0.445 - ETA: 38s - loss: 0.3809 - mean_iou: 0.445 - ETA: 36s - loss: 0.3809 - mean_iou: 0.445 - ETA: 34s - loss: 0.3802 - mean_iou: 0.445 - ETA: 32s - loss: 0.3805 - mean_iou: 0.445 - ETA: 31s - loss: 0.3798 - mean_iou: 0.445 - ETA: 29s - loss: 0.3799 - mean_iou: 0.445 - ETA: 28s - loss: 0.3815 - mean_iou: 0.445 - ETA: 26s - loss: 0.3821 - mean_iou: 0.445 - ETA: 24s - loss: 0.3811 - mean_iou: 0.445 - ETA: 23s - loss: 0.3806 - mean_iou: 0.445 - ETA: 21s - loss: 0.3805 - mean_iou: 0.445 - ETA: 19s - loss: 0.3792 - mean_iou: 0.445 - ETA: 18s - loss: 0.3791 - mean_iou: 0.445 - ETA: 16s - loss: 0.3792 - mean_iou: 0.445 - ETA: 14s - loss: 0.3793 - mean_iou: 0.445 - ETA: 13s - loss: 0.3800 - mean_iou: 0.445 - ETA: 11s - loss: 0.3799 - mean_iou: 0.445 - ETA: 9s - loss: 0.3799 - mean_iou: 0.445 - ETA: 8s - loss: 0.3803 - mean_iou: 0.44 - ETA: 6s - loss: 0.3796 - mean_iou: 0.44 - ETA: 4s - loss: 0.3790 - mean_iou: 0.44 - ETA: 2s - loss: 0.3792 - mean_iou: 0.44 - ETA: 1s - loss: 0.3784 - mean_iou: 0.4459Epoch 00036: val_loss improved from 0.37313 to 0.36728, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 68s - loss: 0.3782 - mean_iou: 0.4459 - val_loss: 0.3673 - val_mean_iou: 0.4462\n",
      "Epoch 38/100\n",
      "592/603 [============================>.] - ETA: 62s - loss: 0.3663 - mean_iou: 0.446 - ETA: 59s - loss: 0.3632 - mean_iou: 0.446 - ETA: 57s - loss: 0.3796 - mean_iou: 0.446 - ETA: 54s - loss: 0.3804 - mean_iou: 0.446 - ETA: 53s - loss: 0.3788 - mean_iou: 0.446 - ETA: 52s - loss: 0.3753 - mean_iou: 0.446 - ETA: 51s - loss: 0.3725 - mean_iou: 0.446 - ETA: 50s - loss: 0.3731 - mean_iou: 0.446 - ETA: 49s - loss: 0.3753 - mean_iou: 0.446 - ETA: 49s - loss: 0.3780 - mean_iou: 0.446 - ETA: 47s - loss: 0.3776 - mean_iou: 0.446 - ETA: 45s - loss: 0.3770 - mean_iou: 0.446 - ETA: 43s - loss: 0.3749 - mean_iou: 0.446 - ETA: 41s - loss: 0.3720 - mean_iou: 0.446 - ETA: 40s - loss: 0.3727 - mean_iou: 0.446 - ETA: 39s - loss: 0.3743 - mean_iou: 0.446 - ETA: 37s - loss: 0.3740 - mean_iou: 0.446 - ETA: 36s - loss: 0.3732 - mean_iou: 0.446 - ETA: 34s - loss: 0.3731 - mean_iou: 0.446 - ETA: 32s - loss: 0.3733 - mean_iou: 0.446 - ETA: 31s - loss: 0.3743 - mean_iou: 0.446 - ETA: 29s - loss: 0.3741 - mean_iou: 0.446 - ETA: 27s - loss: 0.3734 - mean_iou: 0.446 - ETA: 25s - loss: 0.3717 - mean_iou: 0.446 - ETA: 23s - loss: 0.3724 - mean_iou: 0.446 - ETA: 22s - loss: 0.3720 - mean_iou: 0.446 - ETA: 20s - loss: 0.3723 - mean_iou: 0.446 - ETA: 18s - loss: 0.3729 - mean_iou: 0.446 - ETA: 16s - loss: 0.3735 - mean_iou: 0.446 - ETA: 14s - loss: 0.3737 - mean_iou: 0.446 - ETA: 12s - loss: 0.3731 - mean_iou: 0.446 - ETA: 11s - loss: 0.3725 - mean_iou: 0.446 - ETA: 9s - loss: 0.3730 - mean_iou: 0.446 - ETA: 7s - loss: 0.3729 - mean_iou: 0.44 - ETA: 5s - loss: 0.3723 - mean_iou: 0.44 - ETA: 3s - loss: 0.3729 - mean_iou: 0.44 - ETA: 1s - loss: 0.3730 - mean_iou: 0.4465Epoch 00037: val_loss improved from 0.36728 to 0.36282, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 78s - loss: 0.3732 - mean_iou: 0.4465 - val_loss: 0.3628 - val_mean_iou: 0.4467\n",
      "Epoch 39/100\n",
      "592/603 [============================>.] - ETA: 62s - loss: 0.3484 - mean_iou: 0.446 - ETA: 62s - loss: 0.3540 - mean_iou: 0.446 - ETA: 60s - loss: 0.3615 - mean_iou: 0.446 - ETA: 60s - loss: 0.3669 - mean_iou: 0.446 - ETA: 58s - loss: 0.3643 - mean_iou: 0.446 - ETA: 56s - loss: 0.3651 - mean_iou: 0.446 - ETA: 54s - loss: 0.3654 - mean_iou: 0.446 - ETA: 53s - loss: 0.3658 - mean_iou: 0.446 - ETA: 52s - loss: 0.3639 - mean_iou: 0.446 - ETA: 50s - loss: 0.3648 - mean_iou: 0.446 - ETA: 48s - loss: 0.3706 - mean_iou: 0.446 - ETA: 46s - loss: 0.3723 - mean_iou: 0.446 - ETA: 44s - loss: 0.3704 - mean_iou: 0.446 - ETA: 42s - loss: 0.3735 - mean_iou: 0.446 - ETA: 40s - loss: 0.3727 - mean_iou: 0.446 - ETA: 39s - loss: 0.3726 - mean_iou: 0.446 - ETA: 37s - loss: 0.3729 - mean_iou: 0.446 - ETA: 35s - loss: 0.3728 - mean_iou: 0.446 - ETA: 34s - loss: 0.3725 - mean_iou: 0.446 - ETA: 32s - loss: 0.3723 - mean_iou: 0.446 - ETA: 30s - loss: 0.3711 - mean_iou: 0.446 - ETA: 28s - loss: 0.3719 - mean_iou: 0.446 - ETA: 26s - loss: 0.3719 - mean_iou: 0.446 - ETA: 25s - loss: 0.3712 - mean_iou: 0.446 - ETA: 23s - loss: 0.3710 - mean_iou: 0.446 - ETA: 21s - loss: 0.3701 - mean_iou: 0.446 - ETA: 19s - loss: 0.3705 - mean_iou: 0.446 - ETA: 17s - loss: 0.3697 - mean_iou: 0.446 - ETA: 15s - loss: 0.3693 - mean_iou: 0.446 - ETA: 13s - loss: 0.3693 - mean_iou: 0.446 - ETA: 12s - loss: 0.3690 - mean_iou: 0.446 - ETA: 10s - loss: 0.3704 - mean_iou: 0.447 - ETA: 8s - loss: 0.3710 - mean_iou: 0.447 - ETA: 6s - loss: 0.3705 - mean_iou: 0.44 - ETA: 4s - loss: 0.3705 - mean_iou: 0.44 - ETA: 3s - loss: 0.3695 - mean_iou: 0.44 - ETA: 1s - loss: 0.3689 - mean_iou: 0.4470Epoch 00038: val_loss improved from 0.36282 to 0.35761, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 71s - loss: 0.3690 - mean_iou: 0.4470 - val_loss: 0.3576 - val_mean_iou: 0.4472\n",
      "Epoch 40/100\n",
      "592/603 [============================>.] - ETA: 64s - loss: 0.3267 - mean_iou: 0.447 - ETA: 64s - loss: 0.3582 - mean_iou: 0.447 - ETA: 63s - loss: 0.3700 - mean_iou: 0.447 - ETA: 62s - loss: 0.3601 - mean_iou: 0.447 - ETA: 60s - loss: 0.3578 - mean_iou: 0.447 - ETA: 58s - loss: 0.3654 - mean_iou: 0.447 - ETA: 56s - loss: 0.3640 - mean_iou: 0.447 - ETA: 53s - loss: 0.3661 - mean_iou: 0.447 - ETA: 51s - loss: 0.3645 - mean_iou: 0.447 - ETA: 49s - loss: 0.3654 - mean_iou: 0.447 - ETA: 47s - loss: 0.3658 - mean_iou: 0.447 - ETA: 45s - loss: 0.3652 - mean_iou: 0.447 - ETA: 43s - loss: 0.3681 - mean_iou: 0.447 - ETA: 41s - loss: 0.3698 - mean_iou: 0.447 - ETA: 39s - loss: 0.3682 - mean_iou: 0.447 - ETA: 37s - loss: 0.3689 - mean_iou: 0.447 - ETA: 35s - loss: 0.3690 - mean_iou: 0.447 - ETA: 33s - loss: 0.3684 - mean_iou: 0.447 - ETA: 31s - loss: 0.3685 - mean_iou: 0.447 - ETA: 30s - loss: 0.3702 - mean_iou: 0.447 - ETA: 28s - loss: 0.3700 - mean_iou: 0.447 - ETA: 26s - loss: 0.3701 - mean_iou: 0.447 - ETA: 24s - loss: 0.3690 - mean_iou: 0.447 - ETA: 23s - loss: 0.3690 - mean_iou: 0.447 - ETA: 21s - loss: 0.3680 - mean_iou: 0.447 - ETA: 19s - loss: 0.3678 - mean_iou: 0.447 - ETA: 18s - loss: 0.3677 - mean_iou: 0.447 - ETA: 16s - loss: 0.3672 - mean_iou: 0.447 - ETA: 14s - loss: 0.3663 - mean_iou: 0.447 - ETA: 13s - loss: 0.3653 - mean_iou: 0.447 - ETA: 11s - loss: 0.3654 - mean_iou: 0.447 - ETA: 9s - loss: 0.3651 - mean_iou: 0.447 - ETA: 7s - loss: 0.3651 - mean_iou: 0.44 - ETA: 6s - loss: 0.3642 - mean_iou: 0.44 - ETA: 4s - loss: 0.3645 - mean_iou: 0.44 - ETA: 2s - loss: 0.3637 - mean_iou: 0.44 - ETA: 1s - loss: 0.3643 - mean_iou: 0.4475Epoch 00039: val_loss improved from 0.35761 to 0.35260, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 66s - loss: 0.3642 - mean_iou: 0.4475 - val_loss: 0.3526 - val_mean_iou: 0.4477\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 60s - loss: 0.3816 - mean_iou: 0.447 - ETA: 58s - loss: 0.3764 - mean_iou: 0.447 - ETA: 55s - loss: 0.3635 - mean_iou: 0.447 - ETA: 54s - loss: 0.3590 - mean_iou: 0.447 - ETA: 52s - loss: 0.3535 - mean_iou: 0.447 - ETA: 50s - loss: 0.3525 - mean_iou: 0.447 - ETA: 49s - loss: 0.3547 - mean_iou: 0.447 - ETA: 49s - loss: 0.3606 - mean_iou: 0.447 - ETA: 47s - loss: 0.3626 - mean_iou: 0.447 - ETA: 45s - loss: 0.3622 - mean_iou: 0.447 - ETA: 43s - loss: 0.3625 - mean_iou: 0.447 - ETA: 42s - loss: 0.3620 - mean_iou: 0.447 - ETA: 40s - loss: 0.3619 - mean_iou: 0.447 - ETA: 38s - loss: 0.3612 - mean_iou: 0.447 - ETA: 36s - loss: 0.3635 - mean_iou: 0.447 - ETA: 35s - loss: 0.3642 - mean_iou: 0.447 - ETA: 33s - loss: 0.3631 - mean_iou: 0.447 - ETA: 31s - loss: 0.3638 - mean_iou: 0.447 - ETA: 30s - loss: 0.3630 - mean_iou: 0.447 - ETA: 28s - loss: 0.3632 - mean_iou: 0.447 - ETA: 27s - loss: 0.3628 - mean_iou: 0.447 - ETA: 25s - loss: 0.3624 - mean_iou: 0.447 - ETA: 23s - loss: 0.3619 - mean_iou: 0.447 - ETA: 22s - loss: 0.3615 - mean_iou: 0.447 - ETA: 20s - loss: 0.3613 - mean_iou: 0.447 - ETA: 18s - loss: 0.3616 - mean_iou: 0.447 - ETA: 17s - loss: 0.3618 - mean_iou: 0.447 - ETA: 15s - loss: 0.3606 - mean_iou: 0.447 - ETA: 14s - loss: 0.3608 - mean_iou: 0.447 - ETA: 12s - loss: 0.3604 - mean_iou: 0.447 - ETA: 10s - loss: 0.3611 - mean_iou: 0.447 - ETA: 9s - loss: 0.3605 - mean_iou: 0.447 - ETA: 7s - loss: 0.3605 - mean_iou: 0.44 - ETA: 5s - loss: 0.3614 - mean_iou: 0.44 - ETA: 4s - loss: 0.3619 - mean_iou: 0.44 - ETA: 2s - loss: 0.3619 - mean_iou: 0.44 - ETA: 1s - loss: 0.3615 - mean_iou: 0.4480Epoch 00040: val_loss improved from 0.35260 to 0.34911, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.3616 - mean_iou: 0.4480 - val_loss: 0.3491 - val_mean_iou: 0.4482\n",
      "Epoch 42/100\n",
      "592/603 [============================>.] - ETA: 61s - loss: 0.3469 - mean_iou: 0.448 - ETA: 58s - loss: 0.3588 - mean_iou: 0.448 - ETA: 56s - loss: 0.3493 - mean_iou: 0.448 - ETA: 54s - loss: 0.3469 - mean_iou: 0.448 - ETA: 52s - loss: 0.3544 - mean_iou: 0.448 - ETA: 50s - loss: 0.3562 - mean_iou: 0.448 - ETA: 49s - loss: 0.3542 - mean_iou: 0.448 - ETA: 48s - loss: 0.3534 - mean_iou: 0.448 - ETA: 46s - loss: 0.3529 - mean_iou: 0.448 - ETA: 44s - loss: 0.3545 - mean_iou: 0.448 - ETA: 43s - loss: 0.3537 - mean_iou: 0.448 - ETA: 41s - loss: 0.3523 - mean_iou: 0.448 - ETA: 40s - loss: 0.3545 - mean_iou: 0.448 - ETA: 38s - loss: 0.3543 - mean_iou: 0.448 - ETA: 36s - loss: 0.3535 - mean_iou: 0.448 - ETA: 35s - loss: 0.3580 - mean_iou: 0.448 - ETA: 33s - loss: 0.3575 - mean_iou: 0.448 - ETA: 31s - loss: 0.3560 - mean_iou: 0.448 - ETA: 30s - loss: 0.3552 - mean_iou: 0.448 - ETA: 28s - loss: 0.3546 - mean_iou: 0.448 - ETA: 27s - loss: 0.3552 - mean_iou: 0.448 - ETA: 25s - loss: 0.3553 - mean_iou: 0.448 - ETA: 23s - loss: 0.3533 - mean_iou: 0.448 - ETA: 22s - loss: 0.3541 - mean_iou: 0.448 - ETA: 20s - loss: 0.3547 - mean_iou: 0.448 - ETA: 18s - loss: 0.3550 - mean_iou: 0.448 - ETA: 17s - loss: 0.3550 - mean_iou: 0.448 - ETA: 15s - loss: 0.3560 - mean_iou: 0.448 - ETA: 14s - loss: 0.3552 - mean_iou: 0.448 - ETA: 12s - loss: 0.3556 - mean_iou: 0.448 - ETA: 10s - loss: 0.3567 - mean_iou: 0.448 - ETA: 9s - loss: 0.3575 - mean_iou: 0.448 - ETA: 7s - loss: 0.3575 - mean_iou: 0.44 - ETA: 5s - loss: 0.3574 - mean_iou: 0.44 - ETA: 4s - loss: 0.3567 - mean_iou: 0.44 - ETA: 2s - loss: 0.3562 - mean_iou: 0.44 - ETA: 1s - loss: 0.3568 - mean_iou: 0.4484Epoch 00041: val_loss improved from 0.34911 to 0.34697, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.3566 - mean_iou: 0.4484 - val_loss: 0.3470 - val_mean_iou: 0.4486\n",
      "Epoch 43/100\n",
      "592/603 [============================>.] - ETA: 62s - loss: 0.3358 - mean_iou: 0.448 - ETA: 66s - loss: 0.3610 - mean_iou: 0.448 - ETA: 61s - loss: 0.3746 - mean_iou: 0.448 - ETA: 58s - loss: 0.3678 - mean_iou: 0.448 - ETA: 56s - loss: 0.3720 - mean_iou: 0.448 - ETA: 53s - loss: 0.3694 - mean_iou: 0.448 - ETA: 52s - loss: 0.3651 - mean_iou: 0.448 - ETA: 50s - loss: 0.3669 - mean_iou: 0.448 - ETA: 48s - loss: 0.3619 - mean_iou: 0.448 - ETA: 46s - loss: 0.3603 - mean_iou: 0.448 - ETA: 44s - loss: 0.3602 - mean_iou: 0.448 - ETA: 42s - loss: 0.3562 - mean_iou: 0.448 - ETA: 40s - loss: 0.3561 - mean_iou: 0.448 - ETA: 38s - loss: 0.3546 - mean_iou: 0.448 - ETA: 37s - loss: 0.3533 - mean_iou: 0.448 - ETA: 35s - loss: 0.3544 - mean_iou: 0.448 - ETA: 33s - loss: 0.3566 - mean_iou: 0.448 - ETA: 32s - loss: 0.3599 - mean_iou: 0.448 - ETA: 30s - loss: 0.3580 - mean_iou: 0.448 - ETA: 28s - loss: 0.3555 - mean_iou: 0.448 - ETA: 27s - loss: 0.3567 - mean_iou: 0.448 - ETA: 25s - loss: 0.3560 - mean_iou: 0.448 - ETA: 24s - loss: 0.3563 - mean_iou: 0.448 - ETA: 22s - loss: 0.3575 - mean_iou: 0.448 - ETA: 21s - loss: 0.3576 - mean_iou: 0.448 - ETA: 19s - loss: 0.3561 - mean_iou: 0.448 - ETA: 17s - loss: 0.3547 - mean_iou: 0.448 - ETA: 16s - loss: 0.3546 - mean_iou: 0.448 - ETA: 14s - loss: 0.3542 - mean_iou: 0.448 - ETA: 12s - loss: 0.3546 - mean_iou: 0.448 - ETA: 11s - loss: 0.3554 - mean_iou: 0.448 - ETA: 9s - loss: 0.3549 - mean_iou: 0.448 - ETA: 7s - loss: 0.3541 - mean_iou: 0.44 - ETA: 6s - loss: 0.3540 - mean_iou: 0.44 - ETA: 4s - loss: 0.3541 - mean_iou: 0.44 - ETA: 2s - loss: 0.3547 - mean_iou: 0.44 - ETA: 1s - loss: 0.3537 - mean_iou: 0.4488Epoch 00042: val_loss improved from 0.34697 to 0.34138, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 68s - loss: 0.3533 - mean_iou: 0.4488 - val_loss: 0.3414 - val_mean_iou: 0.4490\n",
      "Epoch 44/100\n",
      "592/603 [============================>.] - ETA: 70s - loss: 0.3653 - mean_iou: 0.449 - ETA: 67s - loss: 0.3711 - mean_iou: 0.449 - ETA: 65s - loss: 0.3712 - mean_iou: 0.449 - ETA: 62s - loss: 0.3646 - mean_iou: 0.449 - ETA: 62s - loss: 0.3625 - mean_iou: 0.449 - ETA: 62s - loss: 0.3618 - mean_iou: 0.449 - ETA: 61s - loss: 0.3560 - mean_iou: 0.449 - ETA: 59s - loss: 0.3554 - mean_iou: 0.449 - ETA: 57s - loss: 0.3538 - mean_iou: 0.449 - ETA: 55s - loss: 0.3510 - mean_iou: 0.449 - ETA: 53s - loss: 0.3513 - mean_iou: 0.449 - ETA: 50s - loss: 0.3519 - mean_iou: 0.449 - ETA: 48s - loss: 0.3506 - mean_iou: 0.449 - ETA: 46s - loss: 0.3486 - mean_iou: 0.449 - ETA: 44s - loss: 0.3503 - mean_iou: 0.449 - ETA: 42s - loss: 0.3505 - mean_iou: 0.449 - ETA: 39s - loss: 0.3520 - mean_iou: 0.449 - ETA: 37s - loss: 0.3497 - mean_iou: 0.449 - ETA: 35s - loss: 0.3494 - mean_iou: 0.449 - ETA: 33s - loss: 0.3497 - mean_iou: 0.449 - ETA: 31s - loss: 0.3489 - mean_iou: 0.449 - ETA: 29s - loss: 0.3490 - mean_iou: 0.449 - ETA: 27s - loss: 0.3479 - mean_iou: 0.449 - ETA: 25s - loss: 0.3477 - mean_iou: 0.449 - ETA: 23s - loss: 0.3476 - mean_iou: 0.449 - ETA: 21s - loss: 0.3453 - mean_iou: 0.449 - ETA: 19s - loss: 0.3456 - mean_iou: 0.449 - ETA: 18s - loss: 0.3458 - mean_iou: 0.449 - ETA: 16s - loss: 0.3465 - mean_iou: 0.449 - ETA: 14s - loss: 0.3466 - mean_iou: 0.449 - ETA: 12s - loss: 0.3464 - mean_iou: 0.449 - ETA: 10s - loss: 0.3463 - mean_iou: 0.449 - ETA: 8s - loss: 0.3465 - mean_iou: 0.449 - ETA: 6s - loss: 0.3463 - mean_iou: 0.44 - ETA: 4s - loss: 0.3465 - mean_iou: 0.44 - ETA: 3s - loss: 0.3469 - mean_iou: 0.44 - ETA: 1s - loss: 0.3466 - mean_iou: 0.4492Epoch 00043: val_loss improved from 0.34138 to 0.33539, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 73s - loss: 0.3463 - mean_iou: 0.4492 - val_loss: 0.3354 - val_mean_iou: 0.4494\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 65s - loss: 0.3526 - mean_iou: 0.449 - ETA: 62s - loss: 0.3375 - mean_iou: 0.449 - ETA: 60s - loss: 0.3426 - mean_iou: 0.449 - ETA: 58s - loss: 0.3462 - mean_iou: 0.449 - ETA: 56s - loss: 0.3420 - mean_iou: 0.449 - ETA: 55s - loss: 0.3332 - mean_iou: 0.449 - ETA: 53s - loss: 0.3350 - mean_iou: 0.449 - ETA: 51s - loss: 0.3406 - mean_iou: 0.449 - ETA: 50s - loss: 0.3398 - mean_iou: 0.449 - ETA: 48s - loss: 0.3401 - mean_iou: 0.449 - ETA: 46s - loss: 0.3397 - mean_iou: 0.449 - ETA: 45s - loss: 0.3424 - mean_iou: 0.449 - ETA: 43s - loss: 0.3401 - mean_iou: 0.449 - ETA: 41s - loss: 0.3402 - mean_iou: 0.449 - ETA: 40s - loss: 0.3424 - mean_iou: 0.449 - ETA: 38s - loss: 0.3418 - mean_iou: 0.449 - ETA: 36s - loss: 0.3409 - mean_iou: 0.449 - ETA: 34s - loss: 0.3416 - mean_iou: 0.449 - ETA: 33s - loss: 0.3414 - mean_iou: 0.449 - ETA: 31s - loss: 0.3411 - mean_iou: 0.449 - ETA: 29s - loss: 0.3410 - mean_iou: 0.449 - ETA: 28s - loss: 0.3434 - mean_iou: 0.449 - ETA: 26s - loss: 0.3431 - mean_iou: 0.449 - ETA: 24s - loss: 0.3423 - mean_iou: 0.449 - ETA: 22s - loss: 0.3431 - mean_iou: 0.449 - ETA: 21s - loss: 0.3439 - mean_iou: 0.449 - ETA: 19s - loss: 0.3433 - mean_iou: 0.449 - ETA: 17s - loss: 0.3432 - mean_iou: 0.449 - ETA: 15s - loss: 0.3421 - mean_iou: 0.449 - ETA: 13s - loss: 0.3418 - mean_iou: 0.449 - ETA: 12s - loss: 0.3421 - mean_iou: 0.449 - ETA: 10s - loss: 0.3416 - mean_iou: 0.449 - ETA: 8s - loss: 0.3419 - mean_iou: 0.449 - ETA: 6s - loss: 0.3418 - mean_iou: 0.44 - ETA: 4s - loss: 0.3416 - mean_iou: 0.44 - ETA: 3s - loss: 0.3418 - mean_iou: 0.44 - ETA: 1s - loss: 0.3415 - mean_iou: 0.4497Epoch 00044: val_loss improved from 0.33539 to 0.33084, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 70s - loss: 0.3411 - mean_iou: 0.4497 - val_loss: 0.3308 - val_mean_iou: 0.4500\n",
      "Epoch 46/100\n",
      "592/603 [============================>.] - ETA: 68s - loss: 0.3289 - mean_iou: 0.450 - ETA: 65s - loss: 0.3315 - mean_iou: 0.450 - ETA: 64s - loss: 0.3308 - mean_iou: 0.450 - ETA: 62s - loss: 0.3281 - mean_iou: 0.450 - ETA: 64s - loss: 0.3320 - mean_iou: 0.450 - ETA: 62s - loss: 0.3328 - mean_iou: 0.450 - ETA: 59s - loss: 0.3312 - mean_iou: 0.450 - ETA: 56s - loss: 0.3329 - mean_iou: 0.450 - ETA: 54s - loss: 0.3347 - mean_iou: 0.450 - ETA: 53s - loss: 0.3338 - mean_iou: 0.450 - ETA: 51s - loss: 0.3352 - mean_iou: 0.450 - ETA: 48s - loss: 0.3354 - mean_iou: 0.450 - ETA: 47s - loss: 0.3358 - mean_iou: 0.450 - ETA: 44s - loss: 0.3346 - mean_iou: 0.450 - ETA: 42s - loss: 0.3342 - mean_iou: 0.450 - ETA: 40s - loss: 0.3338 - mean_iou: 0.450 - ETA: 38s - loss: 0.3337 - mean_iou: 0.450 - ETA: 36s - loss: 0.3337 - mean_iou: 0.450 - ETA: 34s - loss: 0.3336 - mean_iou: 0.450 - ETA: 32s - loss: 0.3334 - mean_iou: 0.450 - ETA: 30s - loss: 0.3332 - mean_iou: 0.450 - ETA: 28s - loss: 0.3323 - mean_iou: 0.450 - ETA: 26s - loss: 0.3324 - mean_iou: 0.450 - ETA: 24s - loss: 0.3319 - mean_iou: 0.450 - ETA: 22s - loss: 0.3334 - mean_iou: 0.450 - ETA: 21s - loss: 0.3348 - mean_iou: 0.450 - ETA: 19s - loss: 0.3346 - mean_iou: 0.450 - ETA: 17s - loss: 0.3353 - mean_iou: 0.450 - ETA: 15s - loss: 0.3362 - mean_iou: 0.450 - ETA: 13s - loss: 0.3358 - mean_iou: 0.450 - ETA: 11s - loss: 0.3363 - mean_iou: 0.450 - ETA: 10s - loss: 0.3362 - mean_iou: 0.450 - ETA: 8s - loss: 0.3360 - mean_iou: 0.450 - ETA: 6s - loss: 0.3358 - mean_iou: 0.45 - ETA: 4s - loss: 0.3372 - mean_iou: 0.45 - ETA: 2s - loss: 0.3374 - mean_iou: 0.45 - ETA: 1s - loss: 0.3389 - mean_iou: 0.4504Epoch 00045: val_loss improved from 0.33084 to 0.32976, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 69s - loss: 0.3391 - mean_iou: 0.4504 - val_loss: 0.3298 - val_mean_iou: 0.4508\n",
      "Epoch 47/100\n",
      "592/603 [============================>.] - ETA: 59s - loss: 0.3600 - mean_iou: 0.450 - ETA: 58s - loss: 0.3375 - mean_iou: 0.450 - ETA: 56s - loss: 0.3400 - mean_iou: 0.450 - ETA: 55s - loss: 0.3402 - mean_iou: 0.450 - ETA: 53s - loss: 0.3431 - mean_iou: 0.450 - ETA: 51s - loss: 0.3439 - mean_iou: 0.450 - ETA: 50s - loss: 0.3445 - mean_iou: 0.450 - ETA: 48s - loss: 0.3404 - mean_iou: 0.450 - ETA: 46s - loss: 0.3438 - mean_iou: 0.450 - ETA: 45s - loss: 0.3416 - mean_iou: 0.451 - ETA: 43s - loss: 0.3403 - mean_iou: 0.451 - ETA: 42s - loss: 0.3406 - mean_iou: 0.451 - ETA: 40s - loss: 0.3408 - mean_iou: 0.451 - ETA: 38s - loss: 0.3412 - mean_iou: 0.451 - ETA: 37s - loss: 0.3410 - mean_iou: 0.451 - ETA: 35s - loss: 0.3399 - mean_iou: 0.451 - ETA: 34s - loss: 0.3405 - mean_iou: 0.451 - ETA: 32s - loss: 0.3401 - mean_iou: 0.451 - ETA: 31s - loss: 0.3390 - mean_iou: 0.451 - ETA: 29s - loss: 0.3370 - mean_iou: 0.451 - ETA: 28s - loss: 0.3375 - mean_iou: 0.451 - ETA: 26s - loss: 0.3373 - mean_iou: 0.451 - ETA: 24s - loss: 0.3370 - mean_iou: 0.451 - ETA: 23s - loss: 0.3378 - mean_iou: 0.451 - ETA: 21s - loss: 0.3376 - mean_iou: 0.451 - ETA: 19s - loss: 0.3375 - mean_iou: 0.451 - ETA: 17s - loss: 0.3375 - mean_iou: 0.451 - ETA: 16s - loss: 0.3361 - mean_iou: 0.451 - ETA: 14s - loss: 0.3361 - mean_iou: 0.451 - ETA: 12s - loss: 0.3353 - mean_iou: 0.451 - ETA: 11s - loss: 0.3347 - mean_iou: 0.451 - ETA: 9s - loss: 0.3342 - mean_iou: 0.451 - ETA: 7s - loss: 0.3348 - mean_iou: 0.45 - ETA: 6s - loss: 0.3343 - mean_iou: 0.45 - ETA: 4s - loss: 0.3340 - mean_iou: 0.45 - ETA: 2s - loss: 0.3341 - mean_iou: 0.45 - ETA: 1s - loss: 0.3339 - mean_iou: 0.4512Epoch 00046: val_loss improved from 0.32976 to 0.32282, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 65s - loss: 0.3341 - mean_iou: 0.4512 - val_loss: 0.3228 - val_mean_iou: 0.4517\n",
      "Epoch 48/100\n",
      "592/603 [============================>.] - ETA: 60s - loss: 0.3288 - mean_iou: 0.451 - ETA: 57s - loss: 0.3246 - mean_iou: 0.451 - ETA: 55s - loss: 0.3269 - mean_iou: 0.451 - ETA: 54s - loss: 0.3312 - mean_iou: 0.451 - ETA: 53s - loss: 0.3327 - mean_iou: 0.451 - ETA: 52s - loss: 0.3354 - mean_iou: 0.451 - ETA: 51s - loss: 0.3367 - mean_iou: 0.451 - ETA: 50s - loss: 0.3347 - mean_iou: 0.451 - ETA: 49s - loss: 0.3381 - mean_iou: 0.451 - ETA: 47s - loss: 0.3402 - mean_iou: 0.451 - ETA: 45s - loss: 0.3404 - mean_iou: 0.451 - ETA: 43s - loss: 0.3406 - mean_iou: 0.451 - ETA: 42s - loss: 0.3377 - mean_iou: 0.451 - ETA: 40s - loss: 0.3377 - mean_iou: 0.451 - ETA: 38s - loss: 0.3356 - mean_iou: 0.451 - ETA: 36s - loss: 0.3344 - mean_iou: 0.451 - ETA: 34s - loss: 0.3345 - mean_iou: 0.451 - ETA: 33s - loss: 0.3346 - mean_iou: 0.451 - ETA: 31s - loss: 0.3356 - mean_iou: 0.451 - ETA: 29s - loss: 0.3343 - mean_iou: 0.451 - ETA: 27s - loss: 0.3318 - mean_iou: 0.451 - ETA: 26s - loss: 0.3325 - mean_iou: 0.451 - ETA: 24s - loss: 0.3323 - mean_iou: 0.451 - ETA: 22s - loss: 0.3339 - mean_iou: 0.451 - ETA: 20s - loss: 0.3323 - mean_iou: 0.451 - ETA: 19s - loss: 0.3323 - mean_iou: 0.451 - ETA: 17s - loss: 0.3313 - mean_iou: 0.452 - ETA: 15s - loss: 0.3334 - mean_iou: 0.452 - ETA: 14s - loss: 0.3326 - mean_iou: 0.452 - ETA: 12s - loss: 0.3340 - mean_iou: 0.452 - ETA: 10s - loss: 0.3345 - mean_iou: 0.452 - ETA: 9s - loss: 0.3343 - mean_iou: 0.452 - ETA: 7s - loss: 0.3346 - mean_iou: 0.45 - ETA: 6s - loss: 0.3336 - mean_iou: 0.45 - ETA: 4s - loss: 0.3340 - mean_iou: 0.45 - ETA: 2s - loss: 0.3338 - mean_iou: 0.45 - ETA: 1s - loss: 0.3332 - mean_iou: 0.4520Epoch 00047: val_loss improved from 0.32282 to 0.32030, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.3336 - mean_iou: 0.4520 - val_loss: 0.3203 - val_mean_iou: 0.4524\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 57s - loss: 0.3788 - mean_iou: 0.452 - ETA: 56s - loss: 0.3354 - mean_iou: 0.452 - ETA: 54s - loss: 0.3376 - mean_iou: 0.452 - ETA: 52s - loss: 0.3381 - mean_iou: 0.452 - ETA: 51s - loss: 0.3369 - mean_iou: 0.452 - ETA: 51s - loss: 0.3405 - mean_iou: 0.452 - ETA: 50s - loss: 0.3399 - mean_iou: 0.452 - ETA: 48s - loss: 0.3400 - mean_iou: 0.452 - ETA: 46s - loss: 0.3393 - mean_iou: 0.452 - ETA: 45s - loss: 0.3389 - mean_iou: 0.452 - ETA: 43s - loss: 0.3337 - mean_iou: 0.452 - ETA: 41s - loss: 0.3313 - mean_iou: 0.452 - ETA: 39s - loss: 0.3283 - mean_iou: 0.452 - ETA: 38s - loss: 0.3303 - mean_iou: 0.452 - ETA: 36s - loss: 0.3306 - mean_iou: 0.452 - ETA: 35s - loss: 0.3312 - mean_iou: 0.452 - ETA: 33s - loss: 0.3311 - mean_iou: 0.452 - ETA: 31s - loss: 0.3318 - mean_iou: 0.452 - ETA: 30s - loss: 0.3313 - mean_iou: 0.452 - ETA: 28s - loss: 0.3323 - mean_iou: 0.452 - ETA: 26s - loss: 0.3316 - mean_iou: 0.452 - ETA: 25s - loss: 0.3310 - mean_iou: 0.452 - ETA: 23s - loss: 0.3290 - mean_iou: 0.452 - ETA: 21s - loss: 0.3285 - mean_iou: 0.452 - ETA: 20s - loss: 0.3270 - mean_iou: 0.452 - ETA: 18s - loss: 0.3274 - mean_iou: 0.452 - ETA: 17s - loss: 0.3282 - mean_iou: 0.452 - ETA: 15s - loss: 0.3272 - mean_iou: 0.452 - ETA: 13s - loss: 0.3285 - mean_iou: 0.452 - ETA: 12s - loss: 0.3273 - mean_iou: 0.452 - ETA: 10s - loss: 0.3262 - mean_iou: 0.452 - ETA: 9s - loss: 0.3270 - mean_iou: 0.452 - ETA: 7s - loss: 0.3262 - mean_iou: 0.45 - ETA: 5s - loss: 0.3259 - mean_iou: 0.45 - ETA: 4s - loss: 0.3254 - mean_iou: 0.45 - ETA: 2s - loss: 0.3259 - mean_iou: 0.45 - ETA: 1s - loss: 0.3264 - mean_iou: 0.4528Epoch 00048: val_loss improved from 0.32030 to 0.31526, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 62s - loss: 0.3261 - mean_iou: 0.4528 - val_loss: 0.3153 - val_mean_iou: 0.4532\n",
      "Epoch 50/100\n",
      "592/603 [============================>.] - ETA: 59s - loss: 0.3277 - mean_iou: 0.453 - ETA: 56s - loss: 0.3355 - mean_iou: 0.453 - ETA: 54s - loss: 0.3358 - mean_iou: 0.453 - ETA: 53s - loss: 0.3366 - mean_iou: 0.453 - ETA: 52s - loss: 0.3295 - mean_iou: 0.453 - ETA: 51s - loss: 0.3309 - mean_iou: 0.453 - ETA: 49s - loss: 0.3326 - mean_iou: 0.453 - ETA: 47s - loss: 0.3304 - mean_iou: 0.453 - ETA: 45s - loss: 0.3314 - mean_iou: 0.453 - ETA: 43s - loss: 0.3300 - mean_iou: 0.453 - ETA: 42s - loss: 0.3311 - mean_iou: 0.453 - ETA: 40s - loss: 0.3335 - mean_iou: 0.453 - ETA: 38s - loss: 0.3307 - mean_iou: 0.453 - ETA: 37s - loss: 0.3297 - mean_iou: 0.453 - ETA: 35s - loss: 0.3279 - mean_iou: 0.453 - ETA: 34s - loss: 0.3284 - mean_iou: 0.453 - ETA: 32s - loss: 0.3282 - mean_iou: 0.453 - ETA: 30s - loss: 0.3282 - mean_iou: 0.453 - ETA: 29s - loss: 0.3284 - mean_iou: 0.453 - ETA: 27s - loss: 0.3270 - mean_iou: 0.453 - ETA: 26s - loss: 0.3280 - mean_iou: 0.453 - ETA: 24s - loss: 0.3285 - mean_iou: 0.453 - ETA: 22s - loss: 0.3281 - mean_iou: 0.453 - ETA: 21s - loss: 0.3284 - mean_iou: 0.453 - ETA: 19s - loss: 0.3285 - mean_iou: 0.453 - ETA: 18s - loss: 0.3270 - mean_iou: 0.453 - ETA: 16s - loss: 0.3264 - mean_iou: 0.453 - ETA: 15s - loss: 0.3260 - mean_iou: 0.453 - ETA: 14s - loss: 0.3253 - mean_iou: 0.453 - ETA: 12s - loss: 0.3252 - mean_iou: 0.453 - ETA: 11s - loss: 0.3252 - mean_iou: 0.453 - ETA: 9s - loss: 0.3241 - mean_iou: 0.453 - ETA: 8s - loss: 0.3231 - mean_iou: 0.45 - ETA: 6s - loss: 0.3223 - mean_iou: 0.45 - ETA: 4s - loss: 0.3222 - mean_iou: 0.45 - ETA: 3s - loss: 0.3215 - mean_iou: 0.45 - ETA: 1s - loss: 0.3211 - mean_iou: 0.4536Epoch 00049: val_loss improved from 0.31526 to 0.31297, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 78s - loss: 0.3225 - mean_iou: 0.4536 - val_loss: 0.3130 - val_mean_iou: 0.4540\n",
      "Epoch 51/100\n",
      "592/603 [============================>.] - ETA: 69s - loss: 0.3609 - mean_iou: 0.454 - ETA: 82s - loss: 0.3392 - mean_iou: 0.454 - ETA: 81s - loss: 0.3354 - mean_iou: 0.454 - ETA: 77s - loss: 0.3255 - mean_iou: 0.454 - ETA: 76s - loss: 0.3283 - mean_iou: 0.454 - ETA: 75s - loss: 0.3288 - mean_iou: 0.454 - ETA: 73s - loss: 0.3244 - mean_iou: 0.454 - ETA: 70s - loss: 0.3232 - mean_iou: 0.454 - ETA: 66s - loss: 0.3200 - mean_iou: 0.454 - ETA: 63s - loss: 0.3205 - mean_iou: 0.454 - ETA: 60s - loss: 0.3214 - mean_iou: 0.454 - ETA: 57s - loss: 0.3206 - mean_iou: 0.454 - ETA: 54s - loss: 0.3207 - mean_iou: 0.454 - ETA: 51s - loss: 0.3187 - mean_iou: 0.454 - ETA: 49s - loss: 0.3185 - mean_iou: 0.454 - ETA: 46s - loss: 0.3187 - mean_iou: 0.454 - ETA: 43s - loss: 0.3175 - mean_iou: 0.454 - ETA: 41s - loss: 0.3189 - mean_iou: 0.454 - ETA: 38s - loss: 0.3188 - mean_iou: 0.454 - ETA: 36s - loss: 0.3187 - mean_iou: 0.454 - ETA: 34s - loss: 0.3198 - mean_iou: 0.454 - ETA: 32s - loss: 0.3192 - mean_iou: 0.454 - ETA: 29s - loss: 0.3184 - mean_iou: 0.454 - ETA: 27s - loss: 0.3182 - mean_iou: 0.454 - ETA: 25s - loss: 0.3180 - mean_iou: 0.454 - ETA: 23s - loss: 0.3162 - mean_iou: 0.454 - ETA: 21s - loss: 0.3164 - mean_iou: 0.454 - ETA: 19s - loss: 0.3169 - mean_iou: 0.454 - ETA: 17s - loss: 0.3174 - mean_iou: 0.454 - ETA: 15s - loss: 0.3187 - mean_iou: 0.454 - ETA: 13s - loss: 0.3194 - mean_iou: 0.454 - ETA: 11s - loss: 0.3190 - mean_iou: 0.454 - ETA: 9s - loss: 0.3185 - mean_iou: 0.454 - ETA: 7s - loss: 0.3187 - mean_iou: 0.45 - ETA: 5s - loss: 0.3184 - mean_iou: 0.45 - ETA: 3s - loss: 0.3186 - mean_iou: 0.45 - ETA: 1s - loss: 0.3177 - mean_iou: 0.4543Epoch 00050: val_loss improved from 0.31297 to 0.30741, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 76s - loss: 0.3179 - mean_iou: 0.4543 - val_loss: 0.3074 - val_mean_iou: 0.4547\n",
      "Epoch 52/100\n",
      "592/603 [============================>.] - ETA: 66s - loss: 0.2986 - mean_iou: 0.454 - ETA: 64s - loss: 0.2973 - mean_iou: 0.454 - ETA: 60s - loss: 0.3104 - mean_iou: 0.454 - ETA: 58s - loss: 0.3107 - mean_iou: 0.454 - ETA: 56s - loss: 0.3141 - mean_iou: 0.454 - ETA: 54s - loss: 0.3104 - mean_iou: 0.454 - ETA: 52s - loss: 0.3120 - mean_iou: 0.454 - ETA: 50s - loss: 0.3117 - mean_iou: 0.454 - ETA: 48s - loss: 0.3116 - mean_iou: 0.454 - ETA: 46s - loss: 0.3138 - mean_iou: 0.454 - ETA: 45s - loss: 0.3123 - mean_iou: 0.454 - ETA: 43s - loss: 0.3127 - mean_iou: 0.454 - ETA: 41s - loss: 0.3131 - mean_iou: 0.454 - ETA: 40s - loss: 0.3156 - mean_iou: 0.454 - ETA: 38s - loss: 0.3152 - mean_iou: 0.454 - ETA: 36s - loss: 0.3132 - mean_iou: 0.454 - ETA: 34s - loss: 0.3142 - mean_iou: 0.454 - ETA: 33s - loss: 0.3150 - mean_iou: 0.454 - ETA: 31s - loss: 0.3138 - mean_iou: 0.454 - ETA: 29s - loss: 0.3138 - mean_iou: 0.454 - ETA: 28s - loss: 0.3126 - mean_iou: 0.454 - ETA: 26s - loss: 0.3119 - mean_iou: 0.454 - ETA: 24s - loss: 0.3120 - mean_iou: 0.454 - ETA: 23s - loss: 0.3127 - mean_iou: 0.454 - ETA: 21s - loss: 0.3127 - mean_iou: 0.454 - ETA: 19s - loss: 0.3123 - mean_iou: 0.455 - ETA: 17s - loss: 0.3118 - mean_iou: 0.455 - ETA: 16s - loss: 0.3137 - mean_iou: 0.455 - ETA: 14s - loss: 0.3132 - mean_iou: 0.455 - ETA: 12s - loss: 0.3134 - mean_iou: 0.455 - ETA: 11s - loss: 0.3139 - mean_iou: 0.455 - ETA: 9s - loss: 0.3139 - mean_iou: 0.455 - ETA: 7s - loss: 0.3138 - mean_iou: 0.45 - ETA: 6s - loss: 0.3152 - mean_iou: 0.45 - ETA: 4s - loss: 0.3154 - mean_iou: 0.45 - ETA: 2s - loss: 0.3158 - mean_iou: 0.45 - ETA: 1s - loss: 0.3165 - mean_iou: 0.4550Epoch 00051: val_loss improved from 0.30741 to 0.30477, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 68s - loss: 0.3163 - mean_iou: 0.4551 - val_loss: 0.3048 - val_mean_iou: 0.4554\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 67s - loss: 0.3195 - mean_iou: 0.455 - ETA: 64s - loss: 0.3073 - mean_iou: 0.455 - ETA: 61s - loss: 0.3015 - mean_iou: 0.455 - ETA: 59s - loss: 0.3056 - mean_iou: 0.455 - ETA: 56s - loss: 0.3083 - mean_iou: 0.455 - ETA: 55s - loss: 0.3061 - mean_iou: 0.455 - ETA: 54s - loss: 0.3072 - mean_iou: 0.455 - ETA: 52s - loss: 0.3085 - mean_iou: 0.455 - ETA: 50s - loss: 0.3115 - mean_iou: 0.455 - ETA: 48s - loss: 0.3124 - mean_iou: 0.455 - ETA: 47s - loss: 0.3125 - mean_iou: 0.455 - ETA: 45s - loss: 0.3141 - mean_iou: 0.455 - ETA: 44s - loss: 0.3157 - mean_iou: 0.455 - ETA: 42s - loss: 0.3137 - mean_iou: 0.455 - ETA: 41s - loss: 0.3131 - mean_iou: 0.455 - ETA: 39s - loss: 0.3116 - mean_iou: 0.455 - ETA: 37s - loss: 0.3114 - mean_iou: 0.455 - ETA: 36s - loss: 0.3111 - mean_iou: 0.455 - ETA: 34s - loss: 0.3118 - mean_iou: 0.455 - ETA: 32s - loss: 0.3110 - mean_iou: 0.455 - ETA: 30s - loss: 0.3104 - mean_iou: 0.455 - ETA: 28s - loss: 0.3105 - mean_iou: 0.455 - ETA: 26s - loss: 0.3109 - mean_iou: 0.455 - ETA: 24s - loss: 0.3121 - mean_iou: 0.455 - ETA: 22s - loss: 0.3129 - mean_iou: 0.455 - ETA: 20s - loss: 0.3133 - mean_iou: 0.455 - ETA: 18s - loss: 0.3126 - mean_iou: 0.455 - ETA: 17s - loss: 0.3137 - mean_iou: 0.455 - ETA: 15s - loss: 0.3145 - mean_iou: 0.455 - ETA: 13s - loss: 0.3143 - mean_iou: 0.455 - ETA: 11s - loss: 0.3135 - mean_iou: 0.455 - ETA: 9s - loss: 0.3140 - mean_iou: 0.455 - ETA: 8s - loss: 0.3139 - mean_iou: 0.45 - ETA: 6s - loss: 0.3130 - mean_iou: 0.45 - ETA: 4s - loss: 0.3125 - mean_iou: 0.45 - ETA: 2s - loss: 0.3113 - mean_iou: 0.45 - ETA: 1s - loss: 0.3110 - mean_iou: 0.4557Epoch 00052: val_loss improved from 0.30477 to 0.30038, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 68s - loss: 0.3110 - mean_iou: 0.4557 - val_loss: 0.3004 - val_mean_iou: 0.4561\n",
      "Epoch 54/100\n",
      "592/603 [============================>.] - ETA: 62s - loss: 0.2666 - mean_iou: 0.456 - ETA: 59s - loss: 0.3059 - mean_iou: 0.456 - ETA: 57s - loss: 0.3094 - mean_iou: 0.456 - ETA: 56s - loss: 0.3046 - mean_iou: 0.456 - ETA: 56s - loss: 0.3075 - mean_iou: 0.456 - ETA: 54s - loss: 0.3148 - mean_iou: 0.456 - ETA: 53s - loss: 0.3120 - mean_iou: 0.456 - ETA: 52s - loss: 0.3126 - mean_iou: 0.456 - ETA: 50s - loss: 0.3124 - mean_iou: 0.456 - ETA: 47s - loss: 0.3108 - mean_iou: 0.456 - ETA: 45s - loss: 0.3090 - mean_iou: 0.456 - ETA: 43s - loss: 0.3094 - mean_iou: 0.456 - ETA: 41s - loss: 0.3106 - mean_iou: 0.456 - ETA: 40s - loss: 0.3096 - mean_iou: 0.456 - ETA: 38s - loss: 0.3108 - mean_iou: 0.456 - ETA: 37s - loss: 0.3098 - mean_iou: 0.456 - ETA: 35s - loss: 0.3090 - mean_iou: 0.456 - ETA: 33s - loss: 0.3084 - mean_iou: 0.456 - ETA: 32s - loss: 0.3091 - mean_iou: 0.456 - ETA: 30s - loss: 0.3090 - mean_iou: 0.456 - ETA: 28s - loss: 0.3090 - mean_iou: 0.456 - ETA: 27s - loss: 0.3084 - mean_iou: 0.456 - ETA: 25s - loss: 0.3087 - mean_iou: 0.456 - ETA: 23s - loss: 0.3083 - mean_iou: 0.456 - ETA: 21s - loss: 0.3067 - mean_iou: 0.456 - ETA: 19s - loss: 0.3069 - mean_iou: 0.456 - ETA: 18s - loss: 0.3080 - mean_iou: 0.456 - ETA: 16s - loss: 0.3080 - mean_iou: 0.456 - ETA: 14s - loss: 0.3069 - mean_iou: 0.456 - ETA: 12s - loss: 0.3065 - mean_iou: 0.456 - ETA: 11s - loss: 0.3067 - mean_iou: 0.456 - ETA: 9s - loss: 0.3064 - mean_iou: 0.456 - ETA: 7s - loss: 0.3059 - mean_iou: 0.45 - ETA: 6s - loss: 0.3060 - mean_iou: 0.45 - ETA: 4s - loss: 0.3060 - mean_iou: 0.45 - ETA: 2s - loss: 0.3064 - mean_iou: 0.45 - ETA: 1s - loss: 0.3059 - mean_iou: 0.4564Epoch 00053: val_loss improved from 0.30038 to 0.29810, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 66s - loss: 0.3064 - mean_iou: 0.4564 - val_loss: 0.2981 - val_mean_iou: 0.4567\n",
      "Epoch 55/100\n",
      "592/603 [============================>.] - ETA: 57s - loss: 0.2976 - mean_iou: 0.456 - ETA: 57s - loss: 0.3026 - mean_iou: 0.456 - ETA: 55s - loss: 0.3027 - mean_iou: 0.456 - ETA: 53s - loss: 0.3072 - mean_iou: 0.456 - ETA: 51s - loss: 0.2970 - mean_iou: 0.456 - ETA: 49s - loss: 0.3015 - mean_iou: 0.456 - ETA: 48s - loss: 0.2984 - mean_iou: 0.456 - ETA: 47s - loss: 0.3004 - mean_iou: 0.456 - ETA: 45s - loss: 0.2992 - mean_iou: 0.456 - ETA: 44s - loss: 0.3006 - mean_iou: 0.456 - ETA: 42s - loss: 0.3001 - mean_iou: 0.456 - ETA: 41s - loss: 0.2987 - mean_iou: 0.456 - ETA: 39s - loss: 0.2998 - mean_iou: 0.456 - ETA: 37s - loss: 0.3003 - mean_iou: 0.456 - ETA: 36s - loss: 0.2987 - mean_iou: 0.456 - ETA: 34s - loss: 0.2999 - mean_iou: 0.456 - ETA: 32s - loss: 0.2999 - mean_iou: 0.456 - ETA: 31s - loss: 0.3001 - mean_iou: 0.456 - ETA: 29s - loss: 0.2997 - mean_iou: 0.456 - ETA: 28s - loss: 0.3010 - mean_iou: 0.457 - ETA: 26s - loss: 0.3007 - mean_iou: 0.457 - ETA: 24s - loss: 0.3015 - mean_iou: 0.457 - ETA: 23s - loss: 0.3013 - mean_iou: 0.457 - ETA: 21s - loss: 0.3014 - mean_iou: 0.457 - ETA: 20s - loss: 0.3021 - mean_iou: 0.457 - ETA: 18s - loss: 0.3031 - mean_iou: 0.457 - ETA: 16s - loss: 0.3027 - mean_iou: 0.457 - ETA: 15s - loss: 0.3029 - mean_iou: 0.457 - ETA: 13s - loss: 0.3042 - mean_iou: 0.457 - ETA: 12s - loss: 0.3042 - mean_iou: 0.457 - ETA: 10s - loss: 0.3042 - mean_iou: 0.457 - ETA: 9s - loss: 0.3039 - mean_iou: 0.457 - ETA: 7s - loss: 0.3043 - mean_iou: 0.45 - ETA: 5s - loss: 0.3059 - mean_iou: 0.45 - ETA: 4s - loss: 0.3060 - mean_iou: 0.45 - ETA: 2s - loss: 0.3051 - mean_iou: 0.45 - ETA: 1s - loss: 0.3047 - mean_iou: 0.4572Epoch 00054: val_loss improved from 0.29810 to 0.29645, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 62s - loss: 0.3047 - mean_iou: 0.4572 - val_loss: 0.2964 - val_mean_iou: 0.4577\n",
      "Epoch 56/100\n",
      "592/603 [============================>.] - ETA: 58s - loss: 0.2966 - mean_iou: 0.457 - ETA: 56s - loss: 0.3162 - mean_iou: 0.457 - ETA: 54s - loss: 0.3106 - mean_iou: 0.457 - ETA: 54s - loss: 0.3052 - mean_iou: 0.457 - ETA: 54s - loss: 0.3048 - mean_iou: 0.457 - ETA: 53s - loss: 0.3040 - mean_iou: 0.457 - ETA: 52s - loss: 0.3034 - mean_iou: 0.457 - ETA: 50s - loss: 0.3042 - mean_iou: 0.457 - ETA: 48s - loss: 0.3055 - mean_iou: 0.457 - ETA: 47s - loss: 0.3063 - mean_iou: 0.457 - ETA: 45s - loss: 0.3070 - mean_iou: 0.457 - ETA: 43s - loss: 0.3040 - mean_iou: 0.457 - ETA: 41s - loss: 0.3023 - mean_iou: 0.457 - ETA: 39s - loss: 0.3027 - mean_iou: 0.457 - ETA: 37s - loss: 0.3014 - mean_iou: 0.457 - ETA: 36s - loss: 0.3002 - mean_iou: 0.457 - ETA: 34s - loss: 0.3021 - mean_iou: 0.458 - ETA: 32s - loss: 0.3032 - mean_iou: 0.458 - ETA: 30s - loss: 0.3031 - mean_iou: 0.458 - ETA: 29s - loss: 0.3041 - mean_iou: 0.458 - ETA: 27s - loss: 0.3047 - mean_iou: 0.458 - ETA: 25s - loss: 0.3031 - mean_iou: 0.458 - ETA: 24s - loss: 0.3014 - mean_iou: 0.458 - ETA: 22s - loss: 0.3025 - mean_iou: 0.458 - ETA: 20s - loss: 0.3012 - mean_iou: 0.458 - ETA: 19s - loss: 0.3021 - mean_iou: 0.458 - ETA: 17s - loss: 0.3024 - mean_iou: 0.458 - ETA: 15s - loss: 0.3037 - mean_iou: 0.458 - ETA: 14s - loss: 0.3035 - mean_iou: 0.458 - ETA: 12s - loss: 0.3045 - mean_iou: 0.458 - ETA: 10s - loss: 0.3039 - mean_iou: 0.458 - ETA: 9s - loss: 0.3036 - mean_iou: 0.458 - ETA: 7s - loss: 0.3034 - mean_iou: 0.45 - ETA: 5s - loss: 0.3025 - mean_iou: 0.45 - ETA: 4s - loss: 0.3018 - mean_iou: 0.45 - ETA: 2s - loss: 0.3020 - mean_iou: 0.45 - ETA: 1s - loss: 0.3014 - mean_iou: 0.4582Epoch 00055: val_loss improved from 0.29645 to 0.29133, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.3014 - mean_iou: 0.4582 - val_loss: 0.2913 - val_mean_iou: 0.4587\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 59s - loss: 0.3048 - mean_iou: 0.458 - ETA: 58s - loss: 0.2949 - mean_iou: 0.458 - ETA: 55s - loss: 0.2900 - mean_iou: 0.458 - ETA: 53s - loss: 0.2958 - mean_iou: 0.458 - ETA: 52s - loss: 0.3013 - mean_iou: 0.458 - ETA: 51s - loss: 0.3003 - mean_iou: 0.458 - ETA: 49s - loss: 0.3025 - mean_iou: 0.458 - ETA: 48s - loss: 0.2962 - mean_iou: 0.458 - ETA: 46s - loss: 0.2943 - mean_iou: 0.458 - ETA: 44s - loss: 0.2972 - mean_iou: 0.458 - ETA: 43s - loss: 0.2986 - mean_iou: 0.458 - ETA: 41s - loss: 0.3008 - mean_iou: 0.458 - ETA: 39s - loss: 0.2990 - mean_iou: 0.458 - ETA: 37s - loss: 0.2991 - mean_iou: 0.458 - ETA: 36s - loss: 0.2993 - mean_iou: 0.459 - ETA: 34s - loss: 0.2996 - mean_iou: 0.459 - ETA: 32s - loss: 0.2995 - mean_iou: 0.459 - ETA: 31s - loss: 0.3001 - mean_iou: 0.459 - ETA: 29s - loss: 0.2991 - mean_iou: 0.459 - ETA: 28s - loss: 0.2994 - mean_iou: 0.459 - ETA: 26s - loss: 0.2984 - mean_iou: 0.459 - ETA: 24s - loss: 0.2993 - mean_iou: 0.459 - ETA: 23s - loss: 0.2994 - mean_iou: 0.459 - ETA: 21s - loss: 0.2986 - mean_iou: 0.459 - ETA: 20s - loss: 0.2972 - mean_iou: 0.459 - ETA: 18s - loss: 0.2971 - mean_iou: 0.459 - ETA: 16s - loss: 0.2968 - mean_iou: 0.459 - ETA: 15s - loss: 0.2985 - mean_iou: 0.459 - ETA: 13s - loss: 0.2981 - mean_iou: 0.459 - ETA: 12s - loss: 0.2981 - mean_iou: 0.459 - ETA: 10s - loss: 0.2979 - mean_iou: 0.459 - ETA: 8s - loss: 0.2986 - mean_iou: 0.459 - ETA: 7s - loss: 0.2991 - mean_iou: 0.45 - ETA: 5s - loss: 0.2989 - mean_iou: 0.45 - ETA: 4s - loss: 0.2989 - mean_iou: 0.45 - ETA: 2s - loss: 0.2987 - mean_iou: 0.45 - ETA: 1s - loss: 0.2987 - mean_iou: 0.4592Epoch 00056: val_loss improved from 0.29133 to 0.28796, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.2987 - mean_iou: 0.4592 - val_loss: 0.2880 - val_mean_iou: 0.4597\n",
      "Epoch 58/100\n",
      "592/603 [============================>.] - ETA: 64s - loss: 0.2964 - mean_iou: 0.459 - ETA: 63s - loss: 0.2933 - mean_iou: 0.459 - ETA: 61s - loss: 0.2975 - mean_iou: 0.459 - ETA: 58s - loss: 0.3016 - mean_iou: 0.459 - ETA: 57s - loss: 0.2994 - mean_iou: 0.459 - ETA: 56s - loss: 0.2999 - mean_iou: 0.459 - ETA: 54s - loss: 0.2971 - mean_iou: 0.459 - ETA: 52s - loss: 0.2977 - mean_iou: 0.459 - ETA: 50s - loss: 0.2983 - mean_iou: 0.459 - ETA: 48s - loss: 0.2988 - mean_iou: 0.459 - ETA: 46s - loss: 0.2993 - mean_iou: 0.459 - ETA: 44s - loss: 0.2978 - mean_iou: 0.459 - ETA: 42s - loss: 0.2964 - mean_iou: 0.459 - ETA: 40s - loss: 0.2973 - mean_iou: 0.459 - ETA: 38s - loss: 0.2968 - mean_iou: 0.459 - ETA: 37s - loss: 0.2975 - mean_iou: 0.460 - ETA: 35s - loss: 0.2975 - mean_iou: 0.460 - ETA: 33s - loss: 0.2959 - mean_iou: 0.460 - ETA: 31s - loss: 0.2949 - mean_iou: 0.460 - ETA: 29s - loss: 0.2936 - mean_iou: 0.460 - ETA: 27s - loss: 0.2950 - mean_iou: 0.460 - ETA: 26s - loss: 0.2960 - mean_iou: 0.460 - ETA: 24s - loss: 0.2961 - mean_iou: 0.460 - ETA: 22s - loss: 0.2955 - mean_iou: 0.460 - ETA: 20s - loss: 0.2952 - mean_iou: 0.460 - ETA: 19s - loss: 0.2950 - mean_iou: 0.460 - ETA: 17s - loss: 0.2962 - mean_iou: 0.460 - ETA: 15s - loss: 0.2965 - mean_iou: 0.460 - ETA: 14s - loss: 0.2978 - mean_iou: 0.460 - ETA: 12s - loss: 0.2972 - mean_iou: 0.460 - ETA: 10s - loss: 0.2971 - mean_iou: 0.460 - ETA: 9s - loss: 0.2969 - mean_iou: 0.460 - ETA: 7s - loss: 0.2972 - mean_iou: 0.46 - ETA: 6s - loss: 0.2965 - mean_iou: 0.46 - ETA: 4s - loss: 0.2964 - mean_iou: 0.46 - ETA: 2s - loss: 0.2963 - mean_iou: 0.46 - ETA: 1s - loss: 0.2972 - mean_iou: 0.4602Epoch 00057: val_loss did not improve\n",
      "603/603 [==============================] - 64s - loss: 0.2969 - mean_iou: 0.4602 - val_loss: 0.2881 - val_mean_iou: 0.4607\n",
      "Epoch 59/100\n",
      "592/603 [============================>.] - ETA: 57s - loss: 0.2908 - mean_iou: 0.460 - ETA: 55s - loss: 0.3064 - mean_iou: 0.460 - ETA: 54s - loss: 0.3022 - mean_iou: 0.460 - ETA: 52s - loss: 0.2987 - mean_iou: 0.460 - ETA: 51s - loss: 0.2917 - mean_iou: 0.460 - ETA: 50s - loss: 0.2903 - mean_iou: 0.460 - ETA: 48s - loss: 0.2898 - mean_iou: 0.460 - ETA: 47s - loss: 0.2880 - mean_iou: 0.460 - ETA: 45s - loss: 0.2893 - mean_iou: 0.460 - ETA: 43s - loss: 0.2916 - mean_iou: 0.460 - ETA: 41s - loss: 0.2913 - mean_iou: 0.460 - ETA: 40s - loss: 0.2914 - mean_iou: 0.460 - ETA: 38s - loss: 0.2927 - mean_iou: 0.460 - ETA: 37s - loss: 0.2917 - mean_iou: 0.460 - ETA: 36s - loss: 0.2911 - mean_iou: 0.460 - ETA: 36s - loss: 0.2897 - mean_iou: 0.460 - ETA: 35s - loss: 0.2902 - mean_iou: 0.460 - ETA: 34s - loss: 0.2905 - mean_iou: 0.460 - ETA: 32s - loss: 0.2888 - mean_iou: 0.460 - ETA: 31s - loss: 0.2881 - mean_iou: 0.461 - ETA: 30s - loss: 0.2893 - mean_iou: 0.461 - ETA: 28s - loss: 0.2910 - mean_iou: 0.461 - ETA: 27s - loss: 0.2914 - mean_iou: 0.461 - ETA: 25s - loss: 0.2919 - mean_iou: 0.461 - ETA: 23s - loss: 0.2936 - mean_iou: 0.461 - ETA: 22s - loss: 0.2937 - mean_iou: 0.461 - ETA: 20s - loss: 0.2934 - mean_iou: 0.461 - ETA: 18s - loss: 0.2943 - mean_iou: 0.461 - ETA: 16s - loss: 0.2934 - mean_iou: 0.461 - ETA: 14s - loss: 0.2926 - mean_iou: 0.461 - ETA: 12s - loss: 0.2926 - mean_iou: 0.461 - ETA: 10s - loss: 0.2923 - mean_iou: 0.461 - ETA: 9s - loss: 0.2920 - mean_iou: 0.461 - ETA: 7s - loss: 0.2926 - mean_iou: 0.46 - ETA: 5s - loss: 0.2922 - mean_iou: 0.46 - ETA: 3s - loss: 0.2927 - mean_iou: 0.46 - ETA: 1s - loss: 0.2925 - mean_iou: 0.4611Epoch 00058: val_loss improved from 0.28796 to 0.28254, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 75s - loss: 0.2930 - mean_iou: 0.4612 - val_loss: 0.2825 - val_mean_iou: 0.4616\n",
      "Epoch 60/100\n",
      "592/603 [============================>.] - ETA: 61s - loss: 0.2907 - mean_iou: 0.461 - ETA: 58s - loss: 0.2984 - mean_iou: 0.461 - ETA: 55s - loss: 0.3039 - mean_iou: 0.461 - ETA: 53s - loss: 0.3052 - mean_iou: 0.461 - ETA: 52s - loss: 0.3000 - mean_iou: 0.461 - ETA: 50s - loss: 0.2978 - mean_iou: 0.461 - ETA: 48s - loss: 0.2940 - mean_iou: 0.461 - ETA: 46s - loss: 0.2921 - mean_iou: 0.461 - ETA: 45s - loss: 0.2932 - mean_iou: 0.461 - ETA: 43s - loss: 0.2934 - mean_iou: 0.461 - ETA: 42s - loss: 0.2916 - mean_iou: 0.461 - ETA: 41s - loss: 0.2942 - mean_iou: 0.461 - ETA: 39s - loss: 0.2951 - mean_iou: 0.461 - ETA: 38s - loss: 0.2964 - mean_iou: 0.461 - ETA: 36s - loss: 0.2966 - mean_iou: 0.461 - ETA: 35s - loss: 0.2966 - mean_iou: 0.461 - ETA: 33s - loss: 0.2943 - mean_iou: 0.461 - ETA: 31s - loss: 0.2926 - mean_iou: 0.461 - ETA: 30s - loss: 0.2931 - mean_iou: 0.461 - ETA: 28s - loss: 0.2912 - mean_iou: 0.461 - ETA: 26s - loss: 0.2909 - mean_iou: 0.461 - ETA: 25s - loss: 0.2925 - mean_iou: 0.461 - ETA: 23s - loss: 0.2924 - mean_iou: 0.461 - ETA: 21s - loss: 0.2907 - mean_iou: 0.461 - ETA: 20s - loss: 0.2906 - mean_iou: 0.461 - ETA: 18s - loss: 0.2900 - mean_iou: 0.461 - ETA: 17s - loss: 0.2909 - mean_iou: 0.462 - ETA: 15s - loss: 0.2898 - mean_iou: 0.462 - ETA: 13s - loss: 0.2887 - mean_iou: 0.462 - ETA: 12s - loss: 0.2894 - mean_iou: 0.462 - ETA: 10s - loss: 0.2894 - mean_iou: 0.462 - ETA: 9s - loss: 0.2903 - mean_iou: 0.462 - ETA: 7s - loss: 0.2910 - mean_iou: 0.46 - ETA: 5s - loss: 0.2901 - mean_iou: 0.46 - ETA: 4s - loss: 0.2907 - mean_iou: 0.46 - ETA: 2s - loss: 0.2906 - mean_iou: 0.46 - ETA: 1s - loss: 0.2899 - mean_iou: 0.4621Epoch 00059: val_loss improved from 0.28254 to 0.28065, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.2897 - mean_iou: 0.4621 - val_loss: 0.2807 - val_mean_iou: 0.4625\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 59s - loss: 0.3038 - mean_iou: 0.462 - ETA: 57s - loss: 0.2922 - mean_iou: 0.462 - ETA: 55s - loss: 0.3031 - mean_iou: 0.462 - ETA: 54s - loss: 0.3032 - mean_iou: 0.462 - ETA: 54s - loss: 0.3040 - mean_iou: 0.462 - ETA: 52s - loss: 0.3039 - mean_iou: 0.462 - ETA: 50s - loss: 0.3007 - mean_iou: 0.462 - ETA: 48s - loss: 0.3002 - mean_iou: 0.462 - ETA: 46s - loss: 0.2966 - mean_iou: 0.462 - ETA: 44s - loss: 0.2968 - mean_iou: 0.462 - ETA: 43s - loss: 0.2939 - mean_iou: 0.462 - ETA: 41s - loss: 0.2951 - mean_iou: 0.462 - ETA: 40s - loss: 0.2952 - mean_iou: 0.462 - ETA: 38s - loss: 0.2951 - mean_iou: 0.462 - ETA: 36s - loss: 0.2937 - mean_iou: 0.462 - ETA: 35s - loss: 0.2919 - mean_iou: 0.462 - ETA: 33s - loss: 0.2893 - mean_iou: 0.462 - ETA: 31s - loss: 0.2893 - mean_iou: 0.462 - ETA: 30s - loss: 0.2875 - mean_iou: 0.462 - ETA: 28s - loss: 0.2883 - mean_iou: 0.462 - ETA: 26s - loss: 0.2907 - mean_iou: 0.462 - ETA: 25s - loss: 0.2901 - mean_iou: 0.462 - ETA: 23s - loss: 0.2911 - mean_iou: 0.462 - ETA: 21s - loss: 0.2904 - mean_iou: 0.462 - ETA: 20s - loss: 0.2917 - mean_iou: 0.462 - ETA: 18s - loss: 0.2916 - mean_iou: 0.462 - ETA: 17s - loss: 0.2898 - mean_iou: 0.462 - ETA: 15s - loss: 0.2887 - mean_iou: 0.462 - ETA: 13s - loss: 0.2882 - mean_iou: 0.462 - ETA: 12s - loss: 0.2876 - mean_iou: 0.462 - ETA: 10s - loss: 0.2892 - mean_iou: 0.462 - ETA: 9s - loss: 0.2891 - mean_iou: 0.462 - ETA: 7s - loss: 0.2916 - mean_iou: 0.46 - ETA: 5s - loss: 0.2909 - mean_iou: 0.46 - ETA: 4s - loss: 0.2909 - mean_iou: 0.46 - ETA: 2s - loss: 0.2898 - mean_iou: 0.46 - ETA: 1s - loss: 0.2910 - mean_iou: 0.4629Epoch 00060: val_loss improved from 0.28065 to 0.27744, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 63s - loss: 0.2907 - mean_iou: 0.4629 - val_loss: 0.2774 - val_mean_iou: 0.4634\n",
      "Epoch 62/100\n",
      "592/603 [============================>.] - ETA: 61s - loss: 0.3091 - mean_iou: 0.463 - ETA: 59s - loss: 0.2924 - mean_iou: 0.463 - ETA: 56s - loss: 0.2802 - mean_iou: 0.463 - ETA: 54s - loss: 0.2721 - mean_iou: 0.463 - ETA: 53s - loss: 0.2843 - mean_iou: 0.463 - ETA: 52s - loss: 0.2854 - mean_iou: 0.463 - ETA: 50s - loss: 0.2893 - mean_iou: 0.463 - ETA: 49s - loss: 0.2840 - mean_iou: 0.463 - ETA: 47s - loss: 0.2857 - mean_iou: 0.463 - ETA: 45s - loss: 0.2844 - mean_iou: 0.463 - ETA: 43s - loss: 0.2853 - mean_iou: 0.463 - ETA: 42s - loss: 0.2867 - mean_iou: 0.463 - ETA: 40s - loss: 0.2898 - mean_iou: 0.463 - ETA: 38s - loss: 0.2899 - mean_iou: 0.463 - ETA: 37s - loss: 0.2883 - mean_iou: 0.463 - ETA: 35s - loss: 0.2869 - mean_iou: 0.463 - ETA: 33s - loss: 0.2880 - mean_iou: 0.463 - ETA: 32s - loss: 0.2879 - mean_iou: 0.463 - ETA: 30s - loss: 0.2894 - mean_iou: 0.463 - ETA: 29s - loss: 0.2903 - mean_iou: 0.463 - ETA: 27s - loss: 0.2895 - mean_iou: 0.463 - ETA: 25s - loss: 0.2885 - mean_iou: 0.463 - ETA: 24s - loss: 0.2879 - mean_iou: 0.463 - ETA: 22s - loss: 0.2872 - mean_iou: 0.463 - ETA: 20s - loss: 0.2861 - mean_iou: 0.463 - ETA: 19s - loss: 0.2871 - mean_iou: 0.463 - ETA: 17s - loss: 0.2886 - mean_iou: 0.463 - ETA: 15s - loss: 0.2879 - mean_iou: 0.463 - ETA: 14s - loss: 0.2885 - mean_iou: 0.463 - ETA: 12s - loss: 0.2875 - mean_iou: 0.463 - ETA: 11s - loss: 0.2866 - mean_iou: 0.463 - ETA: 9s - loss: 0.2861 - mean_iou: 0.463 - ETA: 7s - loss: 0.2856 - mean_iou: 0.46 - ETA: 6s - loss: 0.2856 - mean_iou: 0.46 - ETA: 4s - loss: 0.2855 - mean_iou: 0.46 - ETA: 2s - loss: 0.2855 - mean_iou: 0.46 - ETA: 1s - loss: 0.2859 - mean_iou: 0.4638Epoch 00061: val_loss did not improve\n",
      "603/603 [==============================] - 66s - loss: 0.2862 - mean_iou: 0.4638 - val_loss: 0.2796 - val_mean_iou: 0.4642\n",
      "Epoch 63/100\n",
      "592/603 [============================>.] - ETA: 68s - loss: 0.2918 - mean_iou: 0.464 - ETA: 65s - loss: 0.2736 - mean_iou: 0.464 - ETA: 63s - loss: 0.2836 - mean_iou: 0.464 - ETA: 62s - loss: 0.2949 - mean_iou: 0.464 - ETA: 60s - loss: 0.2867 - mean_iou: 0.464 - ETA: 60s - loss: 0.2919 - mean_iou: 0.464 - ETA: 58s - loss: 0.2960 - mean_iou: 0.464 - ETA: 55s - loss: 0.2938 - mean_iou: 0.464 - ETA: 53s - loss: 0.2940 - mean_iou: 0.464 - ETA: 50s - loss: 0.2955 - mean_iou: 0.464 - ETA: 48s - loss: 0.2950 - mean_iou: 0.464 - ETA: 46s - loss: 0.2922 - mean_iou: 0.464 - ETA: 44s - loss: 0.2920 - mean_iou: 0.464 - ETA: 42s - loss: 0.2926 - mean_iou: 0.464 - ETA: 40s - loss: 0.2940 - mean_iou: 0.464 - ETA: 38s - loss: 0.2940 - mean_iou: 0.464 - ETA: 36s - loss: 0.2915 - mean_iou: 0.464 - ETA: 34s - loss: 0.2919 - mean_iou: 0.464 - ETA: 32s - loss: 0.2925 - mean_iou: 0.464 - ETA: 31s - loss: 0.2910 - mean_iou: 0.464 - ETA: 29s - loss: 0.2920 - mean_iou: 0.464 - ETA: 27s - loss: 0.2933 - mean_iou: 0.464 - ETA: 25s - loss: 0.2929 - mean_iou: 0.464 - ETA: 23s - loss: 0.2946 - mean_iou: 0.464 - ETA: 21s - loss: 0.2958 - mean_iou: 0.464 - ETA: 20s - loss: 0.2949 - mean_iou: 0.464 - ETA: 18s - loss: 0.2945 - mean_iou: 0.464 - ETA: 16s - loss: 0.2937 - mean_iou: 0.464 - ETA: 14s - loss: 0.2938 - mean_iou: 0.464 - ETA: 13s - loss: 0.2940 - mean_iou: 0.464 - ETA: 11s - loss: 0.2922 - mean_iou: 0.464 - ETA: 9s - loss: 0.2922 - mean_iou: 0.464 - ETA: 7s - loss: 0.2923 - mean_iou: 0.46 - ETA: 6s - loss: 0.2919 - mean_iou: 0.46 - ETA: 4s - loss: 0.2908 - mean_iou: 0.46 - ETA: 2s - loss: 0.2907 - mean_iou: 0.46 - ETA: 1s - loss: 0.2902 - mean_iou: 0.4646Epoch 00062: val_loss improved from 0.27744 to 0.27418, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 67s - loss: 0.2894 - mean_iou: 0.4646 - val_loss: 0.2742 - val_mean_iou: 0.4650\n",
      "Epoch 64/100\n",
      "592/603 [============================>.] - ETA: 57s - loss: 0.2539 - mean_iou: 0.465 - ETA: 56s - loss: 0.2783 - mean_iou: 0.465 - ETA: 54s - loss: 0.2899 - mean_iou: 0.465 - ETA: 53s - loss: 0.2903 - mean_iou: 0.465 - ETA: 52s - loss: 0.2890 - mean_iou: 0.465 - ETA: 50s - loss: 0.2867 - mean_iou: 0.465 - ETA: 48s - loss: 0.2861 - mean_iou: 0.465 - ETA: 47s - loss: 0.2862 - mean_iou: 0.465 - ETA: 45s - loss: 0.2921 - mean_iou: 0.465 - ETA: 43s - loss: 0.2909 - mean_iou: 0.465 - ETA: 42s - loss: 0.2912 - mean_iou: 0.465 - ETA: 40s - loss: 0.2905 - mean_iou: 0.465 - ETA: 39s - loss: 0.2875 - mean_iou: 0.465 - ETA: 37s - loss: 0.2878 - mean_iou: 0.465 - ETA: 35s - loss: 0.2848 - mean_iou: 0.465 - ETA: 34s - loss: 0.2857 - mean_iou: 0.465 - ETA: 32s - loss: 0.2830 - mean_iou: 0.465 - ETA: 31s - loss: 0.2848 - mean_iou: 0.465 - ETA: 29s - loss: 0.2830 - mean_iou: 0.465 - ETA: 28s - loss: 0.2844 - mean_iou: 0.465 - ETA: 26s - loss: 0.2833 - mean_iou: 0.465 - ETA: 24s - loss: 0.2845 - mean_iou: 0.465 - ETA: 23s - loss: 0.2853 - mean_iou: 0.465 - ETA: 21s - loss: 0.2854 - mean_iou: 0.465 - ETA: 20s - loss: 0.2852 - mean_iou: 0.465 - ETA: 18s - loss: 0.2857 - mean_iou: 0.465 - ETA: 17s - loss: 0.2857 - mean_iou: 0.465 - ETA: 15s - loss: 0.2849 - mean_iou: 0.465 - ETA: 13s - loss: 0.2852 - mean_iou: 0.465 - ETA: 12s - loss: 0.2847 - mean_iou: 0.465 - ETA: 10s - loss: 0.2846 - mean_iou: 0.465 - ETA: 9s - loss: 0.2843 - mean_iou: 0.465 - ETA: 7s - loss: 0.2846 - mean_iou: 0.46 - ETA: 5s - loss: 0.2855 - mean_iou: 0.46 - ETA: 4s - loss: 0.2841 - mean_iou: 0.46 - ETA: 2s - loss: 0.2843 - mean_iou: 0.46 - ETA: 1s - loss: 0.2845 - mean_iou: 0.4654Epoch 00063: val_loss improved from 0.27418 to 0.27162, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 63s - loss: 0.2842 - mean_iou: 0.4654 - val_loss: 0.2716 - val_mean_iou: 0.4657\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 58s - loss: 0.3713 - mean_iou: 0.465 - ETA: 56s - loss: 0.3398 - mean_iou: 0.465 - ETA: 55s - loss: 0.3191 - mean_iou: 0.465 - ETA: 53s - loss: 0.3167 - mean_iou: 0.465 - ETA: 51s - loss: 0.3146 - mean_iou: 0.465 - ETA: 50s - loss: 0.3092 - mean_iou: 0.465 - ETA: 49s - loss: 0.3088 - mean_iou: 0.465 - ETA: 47s - loss: 0.3003 - mean_iou: 0.465 - ETA: 46s - loss: 0.2986 - mean_iou: 0.465 - ETA: 44s - loss: 0.2980 - mean_iou: 0.465 - ETA: 43s - loss: 0.2958 - mean_iou: 0.465 - ETA: 41s - loss: 0.2920 - mean_iou: 0.465 - ETA: 39s - loss: 0.2938 - mean_iou: 0.465 - ETA: 37s - loss: 0.2914 - mean_iou: 0.465 - ETA: 36s - loss: 0.2890 - mean_iou: 0.465 - ETA: 34s - loss: 0.2892 - mean_iou: 0.465 - ETA: 33s - loss: 0.2874 - mean_iou: 0.465 - ETA: 31s - loss: 0.2891 - mean_iou: 0.465 - ETA: 29s - loss: 0.2889 - mean_iou: 0.465 - ETA: 28s - loss: 0.2889 - mean_iou: 0.466 - ETA: 26s - loss: 0.2881 - mean_iou: 0.466 - ETA: 24s - loss: 0.2873 - mean_iou: 0.466 - ETA: 23s - loss: 0.2872 - mean_iou: 0.466 - ETA: 21s - loss: 0.2869 - mean_iou: 0.466 - ETA: 20s - loss: 0.2855 - mean_iou: 0.466 - ETA: 18s - loss: 0.2851 - mean_iou: 0.466 - ETA: 17s - loss: 0.2838 - mean_iou: 0.466 - ETA: 15s - loss: 0.2845 - mean_iou: 0.466 - ETA: 13s - loss: 0.2840 - mean_iou: 0.466 - ETA: 12s - loss: 0.2836 - mean_iou: 0.466 - ETA: 10s - loss: 0.2847 - mean_iou: 0.466 - ETA: 9s - loss: 0.2827 - mean_iou: 0.466 - ETA: 7s - loss: 0.2835 - mean_iou: 0.46 - ETA: 5s - loss: 0.2828 - mean_iou: 0.46 - ETA: 4s - loss: 0.2829 - mean_iou: 0.46 - ETA: 2s - loss: 0.2833 - mean_iou: 0.46 - ETA: 1s - loss: 0.2838 - mean_iou: 0.4661Epoch 00064: val_loss did not improve\n",
      "603/603 [==============================] - 63s - loss: 0.2839 - mean_iou: 0.4661 - val_loss: 0.2730 - val_mean_iou: 0.4665\n",
      "Epoch 66/100\n",
      "592/603 [============================>.] - ETA: 58s - loss: 0.2882 - mean_iou: 0.466 - ETA: 56s - loss: 0.2900 - mean_iou: 0.466 - ETA: 54s - loss: 0.3023 - mean_iou: 0.466 - ETA: 52s - loss: 0.2898 - mean_iou: 0.466 - ETA: 51s - loss: 0.2857 - mean_iou: 0.466 - ETA: 49s - loss: 0.2826 - mean_iou: 0.466 - ETA: 47s - loss: 0.2816 - mean_iou: 0.466 - ETA: 46s - loss: 0.2799 - mean_iou: 0.466 - ETA: 44s - loss: 0.2788 - mean_iou: 0.466 - ETA: 43s - loss: 0.2815 - mean_iou: 0.466 - ETA: 42s - loss: 0.2807 - mean_iou: 0.466 - ETA: 40s - loss: 0.2792 - mean_iou: 0.466 - ETA: 39s - loss: 0.2792 - mean_iou: 0.466 - ETA: 37s - loss: 0.2793 - mean_iou: 0.466 - ETA: 36s - loss: 0.2803 - mean_iou: 0.466 - ETA: 34s - loss: 0.2787 - mean_iou: 0.466 - ETA: 33s - loss: 0.2809 - mean_iou: 0.466 - ETA: 31s - loss: 0.2813 - mean_iou: 0.466 - ETA: 30s - loss: 0.2823 - mean_iou: 0.466 - ETA: 28s - loss: 0.2816 - mean_iou: 0.466 - ETA: 27s - loss: 0.2806 - mean_iou: 0.466 - ETA: 26s - loss: 0.2810 - mean_iou: 0.466 - ETA: 24s - loss: 0.2810 - mean_iou: 0.466 - ETA: 22s - loss: 0.2797 - mean_iou: 0.466 - ETA: 21s - loss: 0.2796 - mean_iou: 0.466 - ETA: 19s - loss: 0.2780 - mean_iou: 0.466 - ETA: 18s - loss: 0.2776 - mean_iou: 0.466 - ETA: 16s - loss: 0.2770 - mean_iou: 0.466 - ETA: 14s - loss: 0.2768 - mean_iou: 0.466 - ETA: 12s - loss: 0.2760 - mean_iou: 0.466 - ETA: 11s - loss: 0.2773 - mean_iou: 0.466 - ETA: 9s - loss: 0.2774 - mean_iou: 0.466 - ETA: 7s - loss: 0.2774 - mean_iou: 0.46 - ETA: 6s - loss: 0.2774 - mean_iou: 0.46 - ETA: 4s - loss: 0.2765 - mean_iou: 0.46 - ETA: 2s - loss: 0.2764 - mean_iou: 0.46 - ETA: 1s - loss: 0.2778 - mean_iou: 0.4670Epoch 00065: val_loss improved from 0.27162 to 0.26406, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 68s - loss: 0.2776 - mean_iou: 0.4670 - val_loss: 0.2641 - val_mean_iou: 0.4675\n",
      "Epoch 67/100\n",
      "592/603 [============================>.] - ETA: 67s - loss: 0.3040 - mean_iou: 0.467 - ETA: 63s - loss: 0.2659 - mean_iou: 0.467 - ETA: 61s - loss: 0.2761 - mean_iou: 0.467 - ETA: 59s - loss: 0.2664 - mean_iou: 0.467 - ETA: 58s - loss: 0.2609 - mean_iou: 0.467 - ETA: 57s - loss: 0.2622 - mean_iou: 0.467 - ETA: 55s - loss: 0.2651 - mean_iou: 0.467 - ETA: 53s - loss: 0.2654 - mean_iou: 0.467 - ETA: 51s - loss: 0.2671 - mean_iou: 0.467 - ETA: 49s - loss: 0.2662 - mean_iou: 0.467 - ETA: 47s - loss: 0.2674 - mean_iou: 0.467 - ETA: 45s - loss: 0.2645 - mean_iou: 0.467 - ETA: 43s - loss: 0.2643 - mean_iou: 0.467 - ETA: 41s - loss: 0.2674 - mean_iou: 0.467 - ETA: 39s - loss: 0.2679 - mean_iou: 0.467 - ETA: 38s - loss: 0.2680 - mean_iou: 0.467 - ETA: 36s - loss: 0.2686 - mean_iou: 0.467 - ETA: 34s - loss: 0.2693 - mean_iou: 0.467 - ETA: 32s - loss: 0.2689 - mean_iou: 0.467 - ETA: 30s - loss: 0.2689 - mean_iou: 0.467 - ETA: 28s - loss: 0.2692 - mean_iou: 0.467 - ETA: 27s - loss: 0.2691 - mean_iou: 0.467 - ETA: 25s - loss: 0.2688 - mean_iou: 0.467 - ETA: 23s - loss: 0.2684 - mean_iou: 0.467 - ETA: 21s - loss: 0.2702 - mean_iou: 0.467 - ETA: 20s - loss: 0.2708 - mean_iou: 0.467 - ETA: 18s - loss: 0.2710 - mean_iou: 0.467 - ETA: 16s - loss: 0.2716 - mean_iou: 0.468 - ETA: 14s - loss: 0.2717 - mean_iou: 0.468 - ETA: 13s - loss: 0.2705 - mean_iou: 0.468 - ETA: 11s - loss: 0.2709 - mean_iou: 0.468 - ETA: 9s - loss: 0.2703 - mean_iou: 0.468 - ETA: 7s - loss: 0.2706 - mean_iou: 0.46 - ETA: 6s - loss: 0.2720 - mean_iou: 0.46 - ETA: 4s - loss: 0.2722 - mean_iou: 0.46 - ETA: 2s - loss: 0.2722 - mean_iou: 0.46 - ETA: 1s - loss: 0.2728 - mean_iou: 0.4681Epoch 00066: val_loss improved from 0.26406 to 0.26247, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 66s - loss: 0.2729 - mean_iou: 0.4681 - val_loss: 0.2625 - val_mean_iou: 0.4686\n",
      "Epoch 68/100\n",
      "592/603 [============================>.] - ETA: 57s - loss: 0.2260 - mean_iou: 0.468 - ETA: 55s - loss: 0.2532 - mean_iou: 0.468 - ETA: 54s - loss: 0.2701 - mean_iou: 0.468 - ETA: 53s - loss: 0.2695 - mean_iou: 0.468 - ETA: 52s - loss: 0.2763 - mean_iou: 0.468 - ETA: 51s - loss: 0.2767 - mean_iou: 0.468 - ETA: 49s - loss: 0.2770 - mean_iou: 0.468 - ETA: 48s - loss: 0.2715 - mean_iou: 0.468 - ETA: 46s - loss: 0.2694 - mean_iou: 0.468 - ETA: 44s - loss: 0.2694 - mean_iou: 0.468 - ETA: 43s - loss: 0.2696 - mean_iou: 0.468 - ETA: 41s - loss: 0.2714 - mean_iou: 0.468 - ETA: 40s - loss: 0.2714 - mean_iou: 0.468 - ETA: 38s - loss: 0.2744 - mean_iou: 0.468 - ETA: 37s - loss: 0.2721 - mean_iou: 0.468 - ETA: 35s - loss: 0.2706 - mean_iou: 0.468 - ETA: 33s - loss: 0.2695 - mean_iou: 0.468 - ETA: 31s - loss: 0.2696 - mean_iou: 0.468 - ETA: 30s - loss: 0.2704 - mean_iou: 0.468 - ETA: 28s - loss: 0.2717 - mean_iou: 0.468 - ETA: 26s - loss: 0.2711 - mean_iou: 0.468 - ETA: 25s - loss: 0.2701 - mean_iou: 0.469 - ETA: 23s - loss: 0.2700 - mean_iou: 0.469 - ETA: 22s - loss: 0.2702 - mean_iou: 0.469 - ETA: 20s - loss: 0.2691 - mean_iou: 0.469 - ETA: 18s - loss: 0.2672 - mean_iou: 0.469 - ETA: 17s - loss: 0.2682 - mean_iou: 0.469 - ETA: 15s - loss: 0.2684 - mean_iou: 0.469 - ETA: 13s - loss: 0.2680 - mean_iou: 0.469 - ETA: 12s - loss: 0.2694 - mean_iou: 0.469 - ETA: 10s - loss: 0.2699 - mean_iou: 0.469 - ETA: 9s - loss: 0.2691 - mean_iou: 0.469 - ETA: 7s - loss: 0.2697 - mean_iou: 0.46 - ETA: 5s - loss: 0.2701 - mean_iou: 0.46 - ETA: 4s - loss: 0.2705 - mean_iou: 0.46 - ETA: 2s - loss: 0.2703 - mean_iou: 0.46 - ETA: 1s - loss: 0.2717 - mean_iou: 0.4691Epoch 00067: val_loss improved from 0.26247 to 0.25998, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.2722 - mean_iou: 0.4692 - val_loss: 0.2600 - val_mean_iou: 0.4697\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 60s - loss: 0.2830 - mean_iou: 0.469 - ETA: 59s - loss: 0.2615 - mean_iou: 0.469 - ETA: 57s - loss: 0.2680 - mean_iou: 0.469 - ETA: 55s - loss: 0.2662 - mean_iou: 0.469 - ETA: 54s - loss: 0.2685 - mean_iou: 0.469 - ETA: 52s - loss: 0.2661 - mean_iou: 0.469 - ETA: 50s - loss: 0.2721 - mean_iou: 0.469 - ETA: 48s - loss: 0.2717 - mean_iou: 0.469 - ETA: 46s - loss: 0.2755 - mean_iou: 0.469 - ETA: 45s - loss: 0.2776 - mean_iou: 0.469 - ETA: 43s - loss: 0.2748 - mean_iou: 0.469 - ETA: 42s - loss: 0.2756 - mean_iou: 0.469 - ETA: 40s - loss: 0.2789 - mean_iou: 0.469 - ETA: 38s - loss: 0.2834 - mean_iou: 0.469 - ETA: 36s - loss: 0.2856 - mean_iou: 0.469 - ETA: 35s - loss: 0.2827 - mean_iou: 0.469 - ETA: 33s - loss: 0.2823 - mean_iou: 0.469 - ETA: 31s - loss: 0.2821 - mean_iou: 0.469 - ETA: 30s - loss: 0.2829 - mean_iou: 0.470 - ETA: 28s - loss: 0.2818 - mean_iou: 0.470 - ETA: 27s - loss: 0.2842 - mean_iou: 0.470 - ETA: 25s - loss: 0.2834 - mean_iou: 0.470 - ETA: 23s - loss: 0.2839 - mean_iou: 0.470 - ETA: 22s - loss: 0.2849 - mean_iou: 0.470 - ETA: 20s - loss: 0.2841 - mean_iou: 0.470 - ETA: 18s - loss: 0.2837 - mean_iou: 0.470 - ETA: 17s - loss: 0.2832 - mean_iou: 0.470 - ETA: 15s - loss: 0.2827 - mean_iou: 0.470 - ETA: 14s - loss: 0.2823 - mean_iou: 0.470 - ETA: 12s - loss: 0.2824 - mean_iou: 0.470 - ETA: 10s - loss: 0.2807 - mean_iou: 0.470 - ETA: 9s - loss: 0.2817 - mean_iou: 0.470 - ETA: 7s - loss: 0.2813 - mean_iou: 0.47 - ETA: 5s - loss: 0.2818 - mean_iou: 0.47 - ETA: 4s - loss: 0.2841 - mean_iou: 0.47 - ETA: 2s - loss: 0.2861 - mean_iou: 0.47 - ETA: 1s - loss: 0.2874 - mean_iou: 0.4701Epoch 00068: val_loss did not improve\n",
      "603/603 [==============================] - 64s - loss: 0.2866 - mean_iou: 0.4701 - val_loss: 0.2807 - val_mean_iou: 0.4706\n",
      "Epoch 70/100\n",
      "592/603 [============================>.] - ETA: 61s - loss: 0.3330 - mean_iou: 0.470 - ETA: 58s - loss: 0.3056 - mean_iou: 0.470 - ETA: 56s - loss: 0.2936 - mean_iou: 0.470 - ETA: 54s - loss: 0.2829 - mean_iou: 0.470 - ETA: 52s - loss: 0.2796 - mean_iou: 0.470 - ETA: 50s - loss: 0.2833 - mean_iou: 0.470 - ETA: 48s - loss: 0.2792 - mean_iou: 0.470 - ETA: 46s - loss: 0.2733 - mean_iou: 0.470 - ETA: 45s - loss: 0.2755 - mean_iou: 0.470 - ETA: 44s - loss: 0.2732 - mean_iou: 0.470 - ETA: 42s - loss: 0.2748 - mean_iou: 0.470 - ETA: 41s - loss: 0.2732 - mean_iou: 0.470 - ETA: 40s - loss: 0.2731 - mean_iou: 0.470 - ETA: 38s - loss: 0.2731 - mean_iou: 0.470 - ETA: 36s - loss: 0.2708 - mean_iou: 0.470 - ETA: 35s - loss: 0.2756 - mean_iou: 0.470 - ETA: 33s - loss: 0.2766 - mean_iou: 0.470 - ETA: 31s - loss: 0.2762 - mean_iou: 0.470 - ETA: 30s - loss: 0.2764 - mean_iou: 0.470 - ETA: 28s - loss: 0.2769 - mean_iou: 0.470 - ETA: 26s - loss: 0.2772 - mean_iou: 0.470 - ETA: 25s - loss: 0.2771 - mean_iou: 0.470 - ETA: 23s - loss: 0.2774 - mean_iou: 0.470 - ETA: 22s - loss: 0.2772 - mean_iou: 0.470 - ETA: 20s - loss: 0.2771 - mean_iou: 0.470 - ETA: 19s - loss: 0.2786 - mean_iou: 0.470 - ETA: 17s - loss: 0.2785 - mean_iou: 0.470 - ETA: 15s - loss: 0.2783 - mean_iou: 0.470 - ETA: 14s - loss: 0.2774 - mean_iou: 0.470 - ETA: 12s - loss: 0.2779 - mean_iou: 0.470 - ETA: 10s - loss: 0.2781 - mean_iou: 0.470 - ETA: 9s - loss: 0.2790 - mean_iou: 0.471 - ETA: 7s - loss: 0.2785 - mean_iou: 0.47 - ETA: 5s - loss: 0.2784 - mean_iou: 0.47 - ETA: 4s - loss: 0.2787 - mean_iou: 0.47 - ETA: 2s - loss: 0.2781 - mean_iou: 0.47 - ETA: 1s - loss: 0.2792 - mean_iou: 0.4710Epoch 00069: val_loss did not improve\n",
      "603/603 [==============================] - 64s - loss: 0.2789 - mean_iou: 0.4710 - val_loss: 0.2759 - val_mean_iou: 0.4715\n",
      "Epoch 71/100\n",
      "592/603 [============================>.] - ETA: 64s - loss: 0.2859 - mean_iou: 0.471 - ETA: 64s - loss: 0.2621 - mean_iou: 0.471 - ETA: 62s - loss: 0.2757 - mean_iou: 0.471 - ETA: 66s - loss: 0.2780 - mean_iou: 0.471 - ETA: 68s - loss: 0.2889 - mean_iou: 0.471 - ETA: 69s - loss: 0.2835 - mean_iou: 0.471 - ETA: 69s - loss: 0.2870 - mean_iou: 0.471 - ETA: 67s - loss: 0.2885 - mean_iou: 0.471 - ETA: 63s - loss: 0.2934 - mean_iou: 0.471 - ETA: 59s - loss: 0.2976 - mean_iou: 0.471 - ETA: 56s - loss: 0.2917 - mean_iou: 0.471 - ETA: 53s - loss: 0.2871 - mean_iou: 0.471 - ETA: 50s - loss: 0.2859 - mean_iou: 0.471 - ETA: 48s - loss: 0.2855 - mean_iou: 0.471 - ETA: 45s - loss: 0.2861 - mean_iou: 0.471 - ETA: 42s - loss: 0.2851 - mean_iou: 0.471 - ETA: 40s - loss: 0.2854 - mean_iou: 0.471 - ETA: 37s - loss: 0.2843 - mean_iou: 0.471 - ETA: 35s - loss: 0.2842 - mean_iou: 0.471 - ETA: 33s - loss: 0.2840 - mean_iou: 0.471 - ETA: 31s - loss: 0.2837 - mean_iou: 0.471 - ETA: 29s - loss: 0.2840 - mean_iou: 0.471 - ETA: 27s - loss: 0.2842 - mean_iou: 0.471 - ETA: 25s - loss: 0.2825 - mean_iou: 0.471 - ETA: 23s - loss: 0.2823 - mean_iou: 0.471 - ETA: 21s - loss: 0.2826 - mean_iou: 0.471 - ETA: 19s - loss: 0.2828 - mean_iou: 0.471 - ETA: 17s - loss: 0.2818 - mean_iou: 0.471 - ETA: 15s - loss: 0.2817 - mean_iou: 0.471 - ETA: 13s - loss: 0.2807 - mean_iou: 0.471 - ETA: 11s - loss: 0.2803 - mean_iou: 0.471 - ETA: 10s - loss: 0.2803 - mean_iou: 0.471 - ETA: 8s - loss: 0.2803 - mean_iou: 0.471 - ETA: 6s - loss: 0.2817 - mean_iou: 0.47 - ETA: 4s - loss: 0.2805 - mean_iou: 0.47 - ETA: 2s - loss: 0.2799 - mean_iou: 0.47 - ETA: 1s - loss: 0.2808 - mean_iou: 0.4719Epoch 00070: val_loss improved from 0.25998 to 0.25716, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 68s - loss: 0.2808 - mean_iou: 0.4719 - val_loss: 0.2572 - val_mean_iou: 0.4723\n",
      "Epoch 72/100\n",
      "592/603 [============================>.] - ETA: 58s - loss: 0.3057 - mean_iou: 0.472 - ETA: 55s - loss: 0.2820 - mean_iou: 0.472 - ETA: 54s - loss: 0.2786 - mean_iou: 0.472 - ETA: 52s - loss: 0.2732 - mean_iou: 0.472 - ETA: 52s - loss: 0.2735 - mean_iou: 0.472 - ETA: 51s - loss: 0.2777 - mean_iou: 0.472 - ETA: 49s - loss: 0.2735 - mean_iou: 0.472 - ETA: 47s - loss: 0.2753 - mean_iou: 0.472 - ETA: 45s - loss: 0.2739 - mean_iou: 0.472 - ETA: 44s - loss: 0.2826 - mean_iou: 0.472 - ETA: 42s - loss: 0.2855 - mean_iou: 0.472 - ETA: 41s - loss: 0.2870 - mean_iou: 0.472 - ETA: 39s - loss: 0.2865 - mean_iou: 0.472 - ETA: 38s - loss: 0.2839 - mean_iou: 0.472 - ETA: 36s - loss: 0.2830 - mean_iou: 0.472 - ETA: 35s - loss: 0.2830 - mean_iou: 0.472 - ETA: 33s - loss: 0.2828 - mean_iou: 0.472 - ETA: 32s - loss: 0.2833 - mean_iou: 0.472 - ETA: 31s - loss: 0.2826 - mean_iou: 0.472 - ETA: 29s - loss: 0.2825 - mean_iou: 0.472 - ETA: 27s - loss: 0.2802 - mean_iou: 0.472 - ETA: 26s - loss: 0.2804 - mean_iou: 0.472 - ETA: 24s - loss: 0.2783 - mean_iou: 0.472 - ETA: 22s - loss: 0.2772 - mean_iou: 0.472 - ETA: 21s - loss: 0.2772 - mean_iou: 0.472 - ETA: 19s - loss: 0.2765 - mean_iou: 0.472 - ETA: 17s - loss: 0.2752 - mean_iou: 0.472 - ETA: 16s - loss: 0.2749 - mean_iou: 0.472 - ETA: 14s - loss: 0.2743 - mean_iou: 0.472 - ETA: 13s - loss: 0.2747 - mean_iou: 0.472 - ETA: 11s - loss: 0.2753 - mean_iou: 0.472 - ETA: 9s - loss: 0.2749 - mean_iou: 0.472 - ETA: 7s - loss: 0.2763 - mean_iou: 0.47 - ETA: 6s - loss: 0.2767 - mean_iou: 0.47 - ETA: 4s - loss: 0.2758 - mean_iou: 0.47 - ETA: 2s - loss: 0.2760 - mean_iou: 0.47 - ETA: 1s - loss: 0.2756 - mean_iou: 0.4727Epoch 00071: val_loss did not improve\n",
      "603/603 [==============================] - 66s - loss: 0.2767 - mean_iou: 0.4727 - val_loss: 0.2807 - val_mean_iou: 0.4731\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 62s - loss: 0.2593 - mean_iou: 0.473 - ETA: 61s - loss: 0.2548 - mean_iou: 0.473 - ETA: 57s - loss: 0.2799 - mean_iou: 0.473 - ETA: 54s - loss: 0.3129 - mean_iou: 0.473 - ETA: 52s - loss: 0.3168 - mean_iou: 0.473 - ETA: 50s - loss: 0.3091 - mean_iou: 0.473 - ETA: 48s - loss: 0.3024 - mean_iou: 0.473 - ETA: 47s - loss: 0.3003 - mean_iou: 0.473 - ETA: 45s - loss: 0.2965 - mean_iou: 0.473 - ETA: 43s - loss: 0.3003 - mean_iou: 0.473 - ETA: 42s - loss: 0.3018 - mean_iou: 0.473 - ETA: 40s - loss: 0.2956 - mean_iou: 0.473 - ETA: 38s - loss: 0.2919 - mean_iou: 0.473 - ETA: 37s - loss: 0.2898 - mean_iou: 0.473 - ETA: 35s - loss: 0.2877 - mean_iou: 0.473 - ETA: 33s - loss: 0.2855 - mean_iou: 0.473 - ETA: 32s - loss: 0.2885 - mean_iou: 0.473 - ETA: 30s - loss: 0.2900 - mean_iou: 0.473 - ETA: 29s - loss: 0.2893 - mean_iou: 0.473 - ETA: 27s - loss: 0.2907 - mean_iou: 0.473 - ETA: 26s - loss: 0.2890 - mean_iou: 0.473 - ETA: 24s - loss: 0.2875 - mean_iou: 0.473 - ETA: 22s - loss: 0.2858 - mean_iou: 0.473 - ETA: 21s - loss: 0.2860 - mean_iou: 0.473 - ETA: 19s - loss: 0.2855 - mean_iou: 0.473 - ETA: 18s - loss: 0.2841 - mean_iou: 0.473 - ETA: 16s - loss: 0.2833 - mean_iou: 0.473 - ETA: 15s - loss: 0.2820 - mean_iou: 0.473 - ETA: 13s - loss: 0.2819 - mean_iou: 0.473 - ETA: 12s - loss: 0.2818 - mean_iou: 0.473 - ETA: 10s - loss: 0.2831 - mean_iou: 0.473 - ETA: 8s - loss: 0.2822 - mean_iou: 0.473 - ETA: 7s - loss: 0.2832 - mean_iou: 0.47 - ETA: 5s - loss: 0.2826 - mean_iou: 0.47 - ETA: 4s - loss: 0.2820 - mean_iou: 0.47 - ETA: 2s - loss: 0.2827 - mean_iou: 0.47 - ETA: 1s - loss: 0.2825 - mean_iou: 0.4735Epoch 00072: val_loss did not improve\n",
      "603/603 [==============================] - 62s - loss: 0.2820 - mean_iou: 0.4735 - val_loss: 0.2604 - val_mean_iou: 0.4739\n",
      "Epoch 74/100\n",
      "592/603 [============================>.] - ETA: 66s - loss: 0.3057 - mean_iou: 0.474 - ETA: 61s - loss: 0.2918 - mean_iou: 0.474 - ETA: 58s - loss: 0.2861 - mean_iou: 0.474 - ETA: 55s - loss: 0.2826 - mean_iou: 0.474 - ETA: 52s - loss: 0.2788 - mean_iou: 0.474 - ETA: 50s - loss: 0.2801 - mean_iou: 0.474 - ETA: 48s - loss: 0.2737 - mean_iou: 0.474 - ETA: 47s - loss: 0.2711 - mean_iou: 0.474 - ETA: 45s - loss: 0.2707 - mean_iou: 0.474 - ETA: 43s - loss: 0.2703 - mean_iou: 0.474 - ETA: 41s - loss: 0.2707 - mean_iou: 0.474 - ETA: 40s - loss: 0.2714 - mean_iou: 0.474 - ETA: 38s - loss: 0.2709 - mean_iou: 0.474 - ETA: 37s - loss: 0.2695 - mean_iou: 0.474 - ETA: 35s - loss: 0.2689 - mean_iou: 0.474 - ETA: 33s - loss: 0.2662 - mean_iou: 0.474 - ETA: 32s - loss: 0.2656 - mean_iou: 0.474 - ETA: 30s - loss: 0.2663 - mean_iou: 0.474 - ETA: 29s - loss: 0.2657 - mean_iou: 0.474 - ETA: 27s - loss: 0.2649 - mean_iou: 0.474 - ETA: 25s - loss: 0.2657 - mean_iou: 0.474 - ETA: 24s - loss: 0.2647 - mean_iou: 0.474 - ETA: 22s - loss: 0.2662 - mean_iou: 0.474 - ETA: 21s - loss: 0.2668 - mean_iou: 0.474 - ETA: 19s - loss: 0.2680 - mean_iou: 0.474 - ETA: 18s - loss: 0.2673 - mean_iou: 0.474 - ETA: 16s - loss: 0.2673 - mean_iou: 0.474 - ETA: 15s - loss: 0.2665 - mean_iou: 0.474 - ETA: 13s - loss: 0.2668 - mean_iou: 0.474 - ETA: 11s - loss: 0.2653 - mean_iou: 0.474 - ETA: 10s - loss: 0.2637 - mean_iou: 0.474 - ETA: 8s - loss: 0.2650 - mean_iou: 0.474 - ETA: 7s - loss: 0.2655 - mean_iou: 0.47 - ETA: 5s - loss: 0.2641 - mean_iou: 0.47 - ETA: 4s - loss: 0.2637 - mean_iou: 0.47 - ETA: 2s - loss: 0.2639 - mean_iou: 0.47 - ETA: 1s - loss: 0.2642 - mean_iou: 0.4743Epoch 00073: val_loss improved from 0.25716 to 0.25206, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 62s - loss: 0.2644 - mean_iou: 0.4743 - val_loss: 0.2521 - val_mean_iou: 0.4748\n",
      "Epoch 75/100\n",
      "592/603 [============================>.] - ETA: 62s - loss: 0.2827 - mean_iou: 0.474 - ETA: 57s - loss: 0.2669 - mean_iou: 0.474 - ETA: 55s - loss: 0.2648 - mean_iou: 0.474 - ETA: 52s - loss: 0.2577 - mean_iou: 0.474 - ETA: 51s - loss: 0.2614 - mean_iou: 0.474 - ETA: 49s - loss: 0.2558 - mean_iou: 0.474 - ETA: 48s - loss: 0.2521 - mean_iou: 0.474 - ETA: 46s - loss: 0.2575 - mean_iou: 0.474 - ETA: 45s - loss: 0.2567 - mean_iou: 0.474 - ETA: 43s - loss: 0.2542 - mean_iou: 0.474 - ETA: 42s - loss: 0.2577 - mean_iou: 0.474 - ETA: 40s - loss: 0.2568 - mean_iou: 0.474 - ETA: 38s - loss: 0.2598 - mean_iou: 0.474 - ETA: 37s - loss: 0.2591 - mean_iou: 0.475 - ETA: 35s - loss: 0.2611 - mean_iou: 0.475 - ETA: 34s - loss: 0.2575 - mean_iou: 0.475 - ETA: 33s - loss: 0.2563 - mean_iou: 0.475 - ETA: 31s - loss: 0.2578 - mean_iou: 0.475 - ETA: 29s - loss: 0.2568 - mean_iou: 0.475 - ETA: 28s - loss: 0.2578 - mean_iou: 0.475 - ETA: 26s - loss: 0.2573 - mean_iou: 0.475 - ETA: 25s - loss: 0.2574 - mean_iou: 0.475 - ETA: 23s - loss: 0.2579 - mean_iou: 0.475 - ETA: 21s - loss: 0.2589 - mean_iou: 0.475 - ETA: 20s - loss: 0.2582 - mean_iou: 0.475 - ETA: 18s - loss: 0.2567 - mean_iou: 0.475 - ETA: 17s - loss: 0.2581 - mean_iou: 0.475 - ETA: 15s - loss: 0.2585 - mean_iou: 0.475 - ETA: 13s - loss: 0.2579 - mean_iou: 0.475 - ETA: 12s - loss: 0.2576 - mean_iou: 0.475 - ETA: 10s - loss: 0.2584 - mean_iou: 0.475 - ETA: 9s - loss: 0.2576 - mean_iou: 0.475 - ETA: 7s - loss: 0.2579 - mean_iou: 0.47 - ETA: 5s - loss: 0.2584 - mean_iou: 0.47 - ETA: 4s - loss: 0.2577 - mean_iou: 0.47 - ETA: 2s - loss: 0.2570 - mean_iou: 0.47 - ETA: 1s - loss: 0.2576 - mean_iou: 0.4752Epoch 00074: val_loss improved from 0.25206 to 0.24870, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 63s - loss: 0.2584 - mean_iou: 0.4752 - val_loss: 0.2487 - val_mean_iou: 0.4756\n",
      "Epoch 76/100\n",
      "592/603 [============================>.] - ETA: 60s - loss: 0.2570 - mean_iou: 0.475 - ETA: 57s - loss: 0.2525 - mean_iou: 0.475 - ETA: 55s - loss: 0.2485 - mean_iou: 0.475 - ETA: 54s - loss: 0.2460 - mean_iou: 0.475 - ETA: 52s - loss: 0.2487 - mean_iou: 0.475 - ETA: 50s - loss: 0.2486 - mean_iou: 0.475 - ETA: 48s - loss: 0.2511 - mean_iou: 0.475 - ETA: 47s - loss: 0.2480 - mean_iou: 0.475 - ETA: 45s - loss: 0.2543 - mean_iou: 0.475 - ETA: 44s - loss: 0.2500 - mean_iou: 0.475 - ETA: 42s - loss: 0.2503 - mean_iou: 0.475 - ETA: 41s - loss: 0.2508 - mean_iou: 0.475 - ETA: 39s - loss: 0.2534 - mean_iou: 0.475 - ETA: 37s - loss: 0.2537 - mean_iou: 0.475 - ETA: 35s - loss: 0.2540 - mean_iou: 0.475 - ETA: 34s - loss: 0.2550 - mean_iou: 0.475 - ETA: 32s - loss: 0.2537 - mean_iou: 0.475 - ETA: 31s - loss: 0.2536 - mean_iou: 0.475 - ETA: 29s - loss: 0.2546 - mean_iou: 0.475 - ETA: 27s - loss: 0.2585 - mean_iou: 0.475 - ETA: 26s - loss: 0.2560 - mean_iou: 0.475 - ETA: 24s - loss: 0.2570 - mean_iou: 0.475 - ETA: 23s - loss: 0.2580 - mean_iou: 0.475 - ETA: 21s - loss: 0.2568 - mean_iou: 0.475 - ETA: 19s - loss: 0.2565 - mean_iou: 0.475 - ETA: 18s - loss: 0.2596 - mean_iou: 0.475 - ETA: 16s - loss: 0.2606 - mean_iou: 0.476 - ETA: 15s - loss: 0.2605 - mean_iou: 0.476 - ETA: 13s - loss: 0.2601 - mean_iou: 0.476 - ETA: 12s - loss: 0.2588 - mean_iou: 0.476 - ETA: 10s - loss: 0.2589 - mean_iou: 0.476 - ETA: 8s - loss: 0.2584 - mean_iou: 0.476 - ETA: 7s - loss: 0.2582 - mean_iou: 0.47 - ETA: 5s - loss: 0.2570 - mean_iou: 0.47 - ETA: 4s - loss: 0.2564 - mean_iou: 0.47 - ETA: 2s - loss: 0.2563 - mean_iou: 0.47 - ETA: 1s - loss: 0.2559 - mean_iou: 0.4761Epoch 00075: val_loss improved from 0.24870 to 0.24508, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 62s - loss: 0.2563 - mean_iou: 0.4761 - val_loss: 0.2451 - val_mean_iou: 0.4765\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 56s - loss: 0.2478 - mean_iou: 0.476 - ETA: 54s - loss: 0.2480 - mean_iou: 0.476 - ETA: 53s - loss: 0.2402 - mean_iou: 0.476 - ETA: 52s - loss: 0.2391 - mean_iou: 0.476 - ETA: 50s - loss: 0.2434 - mean_iou: 0.476 - ETA: 48s - loss: 0.2480 - mean_iou: 0.476 - ETA: 47s - loss: 0.2492 - mean_iou: 0.476 - ETA: 45s - loss: 0.2535 - mean_iou: 0.476 - ETA: 44s - loss: 0.2557 - mean_iou: 0.476 - ETA: 42s - loss: 0.2557 - mean_iou: 0.476 - ETA: 40s - loss: 0.2543 - mean_iou: 0.476 - ETA: 39s - loss: 0.2532 - mean_iou: 0.476 - ETA: 37s - loss: 0.2567 - mean_iou: 0.476 - ETA: 36s - loss: 0.2556 - mean_iou: 0.476 - ETA: 34s - loss: 0.2556 - mean_iou: 0.476 - ETA: 33s - loss: 0.2565 - mean_iou: 0.476 - ETA: 31s - loss: 0.2580 - mean_iou: 0.476 - ETA: 30s - loss: 0.2569 - mean_iou: 0.476 - ETA: 28s - loss: 0.2565 - mean_iou: 0.476 - ETA: 27s - loss: 0.2567 - mean_iou: 0.476 - ETA: 25s - loss: 0.2558 - mean_iou: 0.476 - ETA: 24s - loss: 0.2550 - mean_iou: 0.476 - ETA: 22s - loss: 0.2546 - mean_iou: 0.476 - ETA: 21s - loss: 0.2548 - mean_iou: 0.476 - ETA: 19s - loss: 0.2541 - mean_iou: 0.476 - ETA: 18s - loss: 0.2523 - mean_iou: 0.476 - ETA: 16s - loss: 0.2529 - mean_iou: 0.476 - ETA: 14s - loss: 0.2533 - mean_iou: 0.476 - ETA: 13s - loss: 0.2526 - mean_iou: 0.476 - ETA: 11s - loss: 0.2537 - mean_iou: 0.476 - ETA: 10s - loss: 0.2530 - mean_iou: 0.476 - ETA: 8s - loss: 0.2534 - mean_iou: 0.476 - ETA: 7s - loss: 0.2533 - mean_iou: 0.47 - ETA: 5s - loss: 0.2538 - mean_iou: 0.47 - ETA: 4s - loss: 0.2530 - mean_iou: 0.47 - ETA: 2s - loss: 0.2527 - mean_iou: 0.47 - ETA: 1s - loss: 0.2524 - mean_iou: 0.4769Epoch 00076: val_loss improved from 0.24508 to 0.24320, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 61s - loss: 0.2514 - mean_iou: 0.4769 - val_loss: 0.2432 - val_mean_iou: 0.4773\n",
      "Epoch 78/100\n",
      "592/603 [============================>.] - ETA: 57s - loss: 0.2261 - mean_iou: 0.477 - ETA: 55s - loss: 0.2614 - mean_iou: 0.477 - ETA: 53s - loss: 0.2567 - mean_iou: 0.477 - ETA: 51s - loss: 0.2519 - mean_iou: 0.477 - ETA: 50s - loss: 0.2489 - mean_iou: 0.477 - ETA: 48s - loss: 0.2483 - mean_iou: 0.477 - ETA: 47s - loss: 0.2458 - mean_iou: 0.477 - ETA: 45s - loss: 0.2485 - mean_iou: 0.477 - ETA: 44s - loss: 0.2484 - mean_iou: 0.477 - ETA: 42s - loss: 0.2493 - mean_iou: 0.477 - ETA: 41s - loss: 0.2507 - mean_iou: 0.477 - ETA: 39s - loss: 0.2525 - mean_iou: 0.477 - ETA: 37s - loss: 0.2512 - mean_iou: 0.477 - ETA: 36s - loss: 0.2489 - mean_iou: 0.477 - ETA: 34s - loss: 0.2501 - mean_iou: 0.477 - ETA: 33s - loss: 0.2491 - mean_iou: 0.477 - ETA: 31s - loss: 0.2489 - mean_iou: 0.477 - ETA: 30s - loss: 0.2525 - mean_iou: 0.477 - ETA: 28s - loss: 0.2537 - mean_iou: 0.477 - ETA: 27s - loss: 0.2536 - mean_iou: 0.477 - ETA: 25s - loss: 0.2538 - mean_iou: 0.477 - ETA: 24s - loss: 0.2526 - mean_iou: 0.477 - ETA: 22s - loss: 0.2536 - mean_iou: 0.477 - ETA: 21s - loss: 0.2538 - mean_iou: 0.477 - ETA: 19s - loss: 0.2532 - mean_iou: 0.477 - ETA: 17s - loss: 0.2523 - mean_iou: 0.477 - ETA: 16s - loss: 0.2518 - mean_iou: 0.477 - ETA: 14s - loss: 0.2517 - mean_iou: 0.477 - ETA: 13s - loss: 0.2516 - mean_iou: 0.477 - ETA: 11s - loss: 0.2514 - mean_iou: 0.477 - ETA: 10s - loss: 0.2519 - mean_iou: 0.477 - ETA: 8s - loss: 0.2517 - mean_iou: 0.477 - ETA: 7s - loss: 0.2522 - mean_iou: 0.47 - ETA: 5s - loss: 0.2518 - mean_iou: 0.47 - ETA: 4s - loss: 0.2515 - mean_iou: 0.47 - ETA: 2s - loss: 0.2511 - mean_iou: 0.47 - ETA: 1s - loss: 0.2514 - mean_iou: 0.4778Epoch 00077: val_loss improved from 0.24320 to 0.24097, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 61s - loss: 0.2507 - mean_iou: 0.4778 - val_loss: 0.2410 - val_mean_iou: 0.4783\n",
      "Epoch 79/100\n",
      "592/603 [============================>.] - ETA: 56s - loss: 0.2458 - mean_iou: 0.478 - ETA: 54s - loss: 0.2394 - mean_iou: 0.478 - ETA: 52s - loss: 0.2509 - mean_iou: 0.478 - ETA: 51s - loss: 0.2525 - mean_iou: 0.478 - ETA: 49s - loss: 0.2580 - mean_iou: 0.478 - ETA: 48s - loss: 0.2523 - mean_iou: 0.478 - ETA: 47s - loss: 0.2481 - mean_iou: 0.478 - ETA: 45s - loss: 0.2476 - mean_iou: 0.478 - ETA: 44s - loss: 0.2491 - mean_iou: 0.478 - ETA: 43s - loss: 0.2481 - mean_iou: 0.478 - ETA: 41s - loss: 0.2455 - mean_iou: 0.478 - ETA: 39s - loss: 0.2440 - mean_iou: 0.478 - ETA: 38s - loss: 0.2459 - mean_iou: 0.478 - ETA: 36s - loss: 0.2460 - mean_iou: 0.478 - ETA: 35s - loss: 0.2446 - mean_iou: 0.478 - ETA: 33s - loss: 0.2447 - mean_iou: 0.478 - ETA: 32s - loss: 0.2446 - mean_iou: 0.478 - ETA: 30s - loss: 0.2456 - mean_iou: 0.478 - ETA: 28s - loss: 0.2454 - mean_iou: 0.478 - ETA: 27s - loss: 0.2463 - mean_iou: 0.478 - ETA: 25s - loss: 0.2492 - mean_iou: 0.478 - ETA: 24s - loss: 0.2485 - mean_iou: 0.478 - ETA: 22s - loss: 0.2476 - mean_iou: 0.478 - ETA: 21s - loss: 0.2482 - mean_iou: 0.478 - ETA: 19s - loss: 0.2475 - mean_iou: 0.478 - ETA: 18s - loss: 0.2481 - mean_iou: 0.478 - ETA: 16s - loss: 0.2474 - mean_iou: 0.478 - ETA: 15s - loss: 0.2479 - mean_iou: 0.478 - ETA: 13s - loss: 0.2470 - mean_iou: 0.478 - ETA: 12s - loss: 0.2466 - mean_iou: 0.478 - ETA: 10s - loss: 0.2474 - mean_iou: 0.478 - ETA: 8s - loss: 0.2478 - mean_iou: 0.478 - ETA: 7s - loss: 0.2480 - mean_iou: 0.47 - ETA: 5s - loss: 0.2485 - mean_iou: 0.47 - ETA: 4s - loss: 0.2487 - mean_iou: 0.47 - ETA: 2s - loss: 0.2490 - mean_iou: 0.47 - ETA: 1s - loss: 0.2511 - mean_iou: 0.4788Epoch 00078: val_loss improved from 0.24097 to 0.23855, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 62s - loss: 0.2511 - mean_iou: 0.4788 - val_loss: 0.2385 - val_mean_iou: 0.4794\n",
      "Epoch 80/100\n",
      "592/603 [============================>.] - ETA: 58s - loss: 0.2420 - mean_iou: 0.479 - ETA: 56s - loss: 0.2445 - mean_iou: 0.479 - ETA: 54s - loss: 0.2447 - mean_iou: 0.479 - ETA: 52s - loss: 0.2431 - mean_iou: 0.479 - ETA: 51s - loss: 0.2402 - mean_iou: 0.479 - ETA: 49s - loss: 0.2373 - mean_iou: 0.479 - ETA: 47s - loss: 0.2375 - mean_iou: 0.479 - ETA: 46s - loss: 0.2370 - mean_iou: 0.479 - ETA: 44s - loss: 0.2421 - mean_iou: 0.479 - ETA: 42s - loss: 0.2402 - mean_iou: 0.479 - ETA: 41s - loss: 0.2464 - mean_iou: 0.479 - ETA: 39s - loss: 0.2476 - mean_iou: 0.479 - ETA: 38s - loss: 0.2472 - mean_iou: 0.479 - ETA: 37s - loss: 0.2466 - mean_iou: 0.479 - ETA: 35s - loss: 0.2493 - mean_iou: 0.479 - ETA: 34s - loss: 0.2510 - mean_iou: 0.479 - ETA: 32s - loss: 0.2495 - mean_iou: 0.479 - ETA: 31s - loss: 0.2492 - mean_iou: 0.479 - ETA: 29s - loss: 0.2493 - mean_iou: 0.479 - ETA: 27s - loss: 0.2518 - mean_iou: 0.479 - ETA: 26s - loss: 0.2508 - mean_iou: 0.479 - ETA: 24s - loss: 0.2521 - mean_iou: 0.479 - ETA: 23s - loss: 0.2517 - mean_iou: 0.479 - ETA: 21s - loss: 0.2514 - mean_iou: 0.479 - ETA: 20s - loss: 0.2510 - mean_iou: 0.479 - ETA: 18s - loss: 0.2516 - mean_iou: 0.479 - ETA: 17s - loss: 0.2533 - mean_iou: 0.479 - ETA: 15s - loss: 0.2529 - mean_iou: 0.479 - ETA: 13s - loss: 0.2527 - mean_iou: 0.479 - ETA: 12s - loss: 0.2526 - mean_iou: 0.479 - ETA: 10s - loss: 0.2514 - mean_iou: 0.479 - ETA: 9s - loss: 0.2507 - mean_iou: 0.479 - ETA: 7s - loss: 0.2498 - mean_iou: 0.47 - ETA: 5s - loss: 0.2507 - mean_iou: 0.47 - ETA: 4s - loss: 0.2498 - mean_iou: 0.47 - ETA: 2s - loss: 0.2491 - mean_iou: 0.47 - ETA: 1s - loss: 0.2488 - mean_iou: 0.4799Epoch 00079: val_loss improved from 0.23855 to 0.23750, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.2488 - mean_iou: 0.4799 - val_loss: 0.2375 - val_mean_iou: 0.4805\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 61s - loss: 0.2193 - mean_iou: 0.480 - ETA: 59s - loss: 0.2468 - mean_iou: 0.480 - ETA: 57s - loss: 0.2351 - mean_iou: 0.480 - ETA: 55s - loss: 0.2458 - mean_iou: 0.480 - ETA: 53s - loss: 0.2424 - mean_iou: 0.480 - ETA: 52s - loss: 0.2429 - mean_iou: 0.480 - ETA: 50s - loss: 0.2467 - mean_iou: 0.480 - ETA: 48s - loss: 0.2479 - mean_iou: 0.480 - ETA: 47s - loss: 0.2497 - mean_iou: 0.480 - ETA: 45s - loss: 0.2466 - mean_iou: 0.480 - ETA: 43s - loss: 0.2482 - mean_iou: 0.480 - ETA: 41s - loss: 0.2500 - mean_iou: 0.480 - ETA: 40s - loss: 0.2498 - mean_iou: 0.480 - ETA: 38s - loss: 0.2489 - mean_iou: 0.480 - ETA: 37s - loss: 0.2496 - mean_iou: 0.480 - ETA: 35s - loss: 0.2482 - mean_iou: 0.480 - ETA: 34s - loss: 0.2484 - mean_iou: 0.480 - ETA: 32s - loss: 0.2467 - mean_iou: 0.480 - ETA: 30s - loss: 0.2472 - mean_iou: 0.480 - ETA: 29s - loss: 0.2461 - mean_iou: 0.480 - ETA: 27s - loss: 0.2454 - mean_iou: 0.480 - ETA: 26s - loss: 0.2447 - mean_iou: 0.480 - ETA: 24s - loss: 0.2434 - mean_iou: 0.480 - ETA: 22s - loss: 0.2443 - mean_iou: 0.480 - ETA: 21s - loss: 0.2444 - mean_iou: 0.480 - ETA: 19s - loss: 0.2445 - mean_iou: 0.480 - ETA: 17s - loss: 0.2440 - mean_iou: 0.480 - ETA: 16s - loss: 0.2455 - mean_iou: 0.480 - ETA: 14s - loss: 0.2444 - mean_iou: 0.480 - ETA: 12s - loss: 0.2447 - mean_iou: 0.480 - ETA: 11s - loss: 0.2441 - mean_iou: 0.480 - ETA: 9s - loss: 0.2438 - mean_iou: 0.480 - ETA: 7s - loss: 0.2433 - mean_iou: 0.48 - ETA: 6s - loss: 0.2438 - mean_iou: 0.48 - ETA: 4s - loss: 0.2443 - mean_iou: 0.48 - ETA: 2s - loss: 0.2433 - mean_iou: 0.48 - ETA: 1s - loss: 0.2436 - mean_iou: 0.4810Epoch 00080: val_loss improved from 0.23750 to 0.23588, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 67s - loss: 0.2437 - mean_iou: 0.4810 - val_loss: 0.2359 - val_mean_iou: 0.4815\n",
      "Epoch 82/100\n",
      "592/603 [============================>.] - ETA: 64s - loss: 0.2934 - mean_iou: 0.481 - ETA: 60s - loss: 0.2698 - mean_iou: 0.481 - ETA: 57s - loss: 0.2669 - mean_iou: 0.481 - ETA: 55s - loss: 0.2536 - mean_iou: 0.481 - ETA: 54s - loss: 0.2513 - mean_iou: 0.481 - ETA: 52s - loss: 0.2493 - mean_iou: 0.481 - ETA: 50s - loss: 0.2500 - mean_iou: 0.481 - ETA: 48s - loss: 0.2471 - mean_iou: 0.481 - ETA: 47s - loss: 0.2459 - mean_iou: 0.481 - ETA: 45s - loss: 0.2493 - mean_iou: 0.481 - ETA: 44s - loss: 0.2487 - mean_iou: 0.481 - ETA: 42s - loss: 0.2454 - mean_iou: 0.481 - ETA: 40s - loss: 0.2440 - mean_iou: 0.481 - ETA: 38s - loss: 0.2435 - mean_iou: 0.481 - ETA: 37s - loss: 0.2470 - mean_iou: 0.481 - ETA: 35s - loss: 0.2462 - mean_iou: 0.481 - ETA: 33s - loss: 0.2453 - mean_iou: 0.481 - ETA: 32s - loss: 0.2464 - mean_iou: 0.481 - ETA: 30s - loss: 0.2462 - mean_iou: 0.481 - ETA: 28s - loss: 0.2439 - mean_iou: 0.481 - ETA: 27s - loss: 0.2434 - mean_iou: 0.481 - ETA: 25s - loss: 0.2438 - mean_iou: 0.481 - ETA: 23s - loss: 0.2453 - mean_iou: 0.481 - ETA: 22s - loss: 0.2438 - mean_iou: 0.481 - ETA: 20s - loss: 0.2434 - mean_iou: 0.481 - ETA: 18s - loss: 0.2425 - mean_iou: 0.481 - ETA: 17s - loss: 0.2413 - mean_iou: 0.481 - ETA: 15s - loss: 0.2412 - mean_iou: 0.481 - ETA: 14s - loss: 0.2424 - mean_iou: 0.482 - ETA: 12s - loss: 0.2426 - mean_iou: 0.482 - ETA: 11s - loss: 0.2436 - mean_iou: 0.482 - ETA: 9s - loss: 0.2431 - mean_iou: 0.482 - ETA: 7s - loss: 0.2444 - mean_iou: 0.48 - ETA: 6s - loss: 0.2440 - mean_iou: 0.48 - ETA: 4s - loss: 0.2435 - mean_iou: 0.48 - ETA: 2s - loss: 0.2442 - mean_iou: 0.48 - ETA: 1s - loss: 0.2439 - mean_iou: 0.4821Epoch 00081: val_loss improved from 0.23588 to 0.23405, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 66s - loss: 0.2444 - mean_iou: 0.4821 - val_loss: 0.2341 - val_mean_iou: 0.4826\n",
      "Epoch 83/100\n",
      "592/603 [============================>.] - ETA: 61s - loss: 0.2485 - mean_iou: 0.482 - ETA: 59s - loss: 0.2378 - mean_iou: 0.482 - ETA: 57s - loss: 0.2411 - mean_iou: 0.482 - ETA: 55s - loss: 0.2425 - mean_iou: 0.482 - ETA: 54s - loss: 0.2326 - mean_iou: 0.482 - ETA: 52s - loss: 0.2315 - mean_iou: 0.482 - ETA: 51s - loss: 0.2268 - mean_iou: 0.482 - ETA: 50s - loss: 0.2275 - mean_iou: 0.482 - ETA: 48s - loss: 0.2245 - mean_iou: 0.482 - ETA: 47s - loss: 0.2312 - mean_iou: 0.482 - ETA: 45s - loss: 0.2335 - mean_iou: 0.482 - ETA: 43s - loss: 0.2320 - mean_iou: 0.482 - ETA: 41s - loss: 0.2307 - mean_iou: 0.482 - ETA: 40s - loss: 0.2316 - mean_iou: 0.482 - ETA: 38s - loss: 0.2304 - mean_iou: 0.482 - ETA: 36s - loss: 0.2315 - mean_iou: 0.482 - ETA: 35s - loss: 0.2324 - mean_iou: 0.482 - ETA: 33s - loss: 0.2351 - mean_iou: 0.482 - ETA: 31s - loss: 0.2355 - mean_iou: 0.482 - ETA: 29s - loss: 0.2355 - mean_iou: 0.482 - ETA: 28s - loss: 0.2348 - mean_iou: 0.482 - ETA: 26s - loss: 0.2341 - mean_iou: 0.482 - ETA: 24s - loss: 0.2357 - mean_iou: 0.482 - ETA: 23s - loss: 0.2344 - mean_iou: 0.482 - ETA: 21s - loss: 0.2360 - mean_iou: 0.482 - ETA: 19s - loss: 0.2368 - mean_iou: 0.483 - ETA: 17s - loss: 0.2386 - mean_iou: 0.483 - ETA: 16s - loss: 0.2391 - mean_iou: 0.483 - ETA: 14s - loss: 0.2388 - mean_iou: 0.483 - ETA: 12s - loss: 0.2391 - mean_iou: 0.483 - ETA: 11s - loss: 0.2395 - mean_iou: 0.483 - ETA: 9s - loss: 0.2392 - mean_iou: 0.483 - ETA: 7s - loss: 0.2404 - mean_iou: 0.48 - ETA: 6s - loss: 0.2405 - mean_iou: 0.48 - ETA: 4s - loss: 0.2411 - mean_iou: 0.48 - ETA: 2s - loss: 0.2406 - mean_iou: 0.48 - ETA: 1s - loss: 0.2405 - mean_iou: 0.4831Epoch 00082: val_loss improved from 0.23405 to 0.23246, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 66s - loss: 0.2408 - mean_iou: 0.4831 - val_loss: 0.2325 - val_mean_iou: 0.4836\n",
      "Epoch 84/100\n",
      "592/603 [============================>.] - ETA: 58s - loss: 0.2041 - mean_iou: 0.483 - ETA: 57s - loss: 0.2379 - mean_iou: 0.483 - ETA: 56s - loss: 0.2474 - mean_iou: 0.483 - ETA: 54s - loss: 0.2390 - mean_iou: 0.483 - ETA: 52s - loss: 0.2445 - mean_iou: 0.483 - ETA: 51s - loss: 0.2495 - mean_iou: 0.483 - ETA: 49s - loss: 0.2442 - mean_iou: 0.483 - ETA: 47s - loss: 0.2459 - mean_iou: 0.483 - ETA: 46s - loss: 0.2464 - mean_iou: 0.483 - ETA: 44s - loss: 0.2489 - mean_iou: 0.483 - ETA: 43s - loss: 0.2469 - mean_iou: 0.483 - ETA: 41s - loss: 0.2441 - mean_iou: 0.483 - ETA: 39s - loss: 0.2448 - mean_iou: 0.483 - ETA: 38s - loss: 0.2408 - mean_iou: 0.483 - ETA: 36s - loss: 0.2390 - mean_iou: 0.483 - ETA: 35s - loss: 0.2415 - mean_iou: 0.483 - ETA: 33s - loss: 0.2430 - mean_iou: 0.483 - ETA: 31s - loss: 0.2443 - mean_iou: 0.483 - ETA: 30s - loss: 0.2448 - mean_iou: 0.483 - ETA: 28s - loss: 0.2463 - mean_iou: 0.483 - ETA: 26s - loss: 0.2458 - mean_iou: 0.483 - ETA: 25s - loss: 0.2460 - mean_iou: 0.483 - ETA: 23s - loss: 0.2434 - mean_iou: 0.483 - ETA: 22s - loss: 0.2424 - mean_iou: 0.483 - ETA: 20s - loss: 0.2413 - mean_iou: 0.483 - ETA: 19s - loss: 0.2427 - mean_iou: 0.483 - ETA: 17s - loss: 0.2429 - mean_iou: 0.483 - ETA: 15s - loss: 0.2421 - mean_iou: 0.484 - ETA: 14s - loss: 0.2430 - mean_iou: 0.484 - ETA: 12s - loss: 0.2421 - mean_iou: 0.484 - ETA: 10s - loss: 0.2421 - mean_iou: 0.484 - ETA: 9s - loss: 0.2415 - mean_iou: 0.484 - ETA: 7s - loss: 0.2413 - mean_iou: 0.48 - ETA: 6s - loss: 0.2409 - mean_iou: 0.48 - ETA: 4s - loss: 0.2419 - mean_iou: 0.48 - ETA: 2s - loss: 0.2413 - mean_iou: 0.48 - ETA: 1s - loss: 0.2410 - mean_iou: 0.4841Epoch 00083: val_loss improved from 0.23246 to 0.22947, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 65s - loss: 0.2408 - mean_iou: 0.4841 - val_loss: 0.2295 - val_mean_iou: 0.4846\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 63s - loss: 0.2329 - mean_iou: 0.484 - ETA: 61s - loss: 0.2466 - mean_iou: 0.484 - ETA: 60s - loss: 0.2537 - mean_iou: 0.484 - ETA: 58s - loss: 0.2468 - mean_iou: 0.484 - ETA: 57s - loss: 0.2388 - mean_iou: 0.484 - ETA: 56s - loss: 0.2449 - mean_iou: 0.484 - ETA: 54s - loss: 0.2444 - mean_iou: 0.484 - ETA: 52s - loss: 0.2438 - mean_iou: 0.484 - ETA: 50s - loss: 0.2443 - mean_iou: 0.484 - ETA: 49s - loss: 0.2403 - mean_iou: 0.484 - ETA: 50s - loss: 0.2420 - mean_iou: 0.484 - ETA: 49s - loss: 0.2407 - mean_iou: 0.484 - ETA: 48s - loss: 0.2402 - mean_iou: 0.484 - ETA: 46s - loss: 0.2420 - mean_iou: 0.484 - ETA: 45s - loss: 0.2414 - mean_iou: 0.484 - ETA: 43s - loss: 0.2395 - mean_iou: 0.484 - ETA: 41s - loss: 0.2372 - mean_iou: 0.484 - ETA: 39s - loss: 0.2390 - mean_iou: 0.484 - ETA: 37s - loss: 0.2395 - mean_iou: 0.484 - ETA: 35s - loss: 0.2392 - mean_iou: 0.484 - ETA: 33s - loss: 0.2387 - mean_iou: 0.484 - ETA: 31s - loss: 0.2400 - mean_iou: 0.484 - ETA: 28s - loss: 0.2387 - mean_iou: 0.484 - ETA: 26s - loss: 0.2395 - mean_iou: 0.484 - ETA: 24s - loss: 0.2391 - mean_iou: 0.484 - ETA: 23s - loss: 0.2376 - mean_iou: 0.484 - ETA: 21s - loss: 0.2377 - mean_iou: 0.485 - ETA: 18s - loss: 0.2387 - mean_iou: 0.485 - ETA: 16s - loss: 0.2387 - mean_iou: 0.485 - ETA: 14s - loss: 0.2400 - mean_iou: 0.485 - ETA: 13s - loss: 0.2408 - mean_iou: 0.485 - ETA: 11s - loss: 0.2397 - mean_iou: 0.485 - ETA: 9s - loss: 0.2397 - mean_iou: 0.485 - ETA: 7s - loss: 0.2390 - mean_iou: 0.48 - ETA: 5s - loss: 0.2380 - mean_iou: 0.48 - ETA: 3s - loss: 0.2377 - mean_iou: 0.48 - ETA: 1s - loss: 0.2373 - mean_iou: 0.4851Epoch 00084: val_loss improved from 0.22947 to 0.22925, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 75s - loss: 0.2376 - mean_iou: 0.4851 - val_loss: 0.2293 - val_mean_iou: 0.4856\n",
      "Epoch 86/100\n",
      "592/603 [============================>.] - ETA: 62s - loss: 0.2197 - mean_iou: 0.485 - ETA: 62s - loss: 0.2254 - mean_iou: 0.485 - ETA: 59s - loss: 0.2309 - mean_iou: 0.485 - ETA: 58s - loss: 0.2271 - mean_iou: 0.485 - ETA: 56s - loss: 0.2349 - mean_iou: 0.485 - ETA: 54s - loss: 0.2335 - mean_iou: 0.485 - ETA: 52s - loss: 0.2416 - mean_iou: 0.485 - ETA: 51s - loss: 0.2495 - mean_iou: 0.485 - ETA: 49s - loss: 0.2464 - mean_iou: 0.485 - ETA: 47s - loss: 0.2496 - mean_iou: 0.485 - ETA: 46s - loss: 0.2479 - mean_iou: 0.485 - ETA: 44s - loss: 0.2490 - mean_iou: 0.485 - ETA: 42s - loss: 0.2482 - mean_iou: 0.485 - ETA: 41s - loss: 0.2472 - mean_iou: 0.485 - ETA: 39s - loss: 0.2448 - mean_iou: 0.485 - ETA: 37s - loss: 0.2441 - mean_iou: 0.485 - ETA: 35s - loss: 0.2440 - mean_iou: 0.485 - ETA: 33s - loss: 0.2446 - mean_iou: 0.485 - ETA: 32s - loss: 0.2431 - mean_iou: 0.485 - ETA: 30s - loss: 0.2421 - mean_iou: 0.485 - ETA: 28s - loss: 0.2413 - mean_iou: 0.485 - ETA: 26s - loss: 0.2434 - mean_iou: 0.485 - ETA: 24s - loss: 0.2435 - mean_iou: 0.485 - ETA: 23s - loss: 0.2438 - mean_iou: 0.485 - ETA: 21s - loss: 0.2427 - mean_iou: 0.485 - ETA: 19s - loss: 0.2426 - mean_iou: 0.485 - ETA: 18s - loss: 0.2429 - mean_iou: 0.485 - ETA: 16s - loss: 0.2426 - mean_iou: 0.485 - ETA: 14s - loss: 0.2421 - mean_iou: 0.485 - ETA: 13s - loss: 0.2425 - mean_iou: 0.485 - ETA: 11s - loss: 0.2415 - mean_iou: 0.485 - ETA: 9s - loss: 0.2416 - mean_iou: 0.486 - ETA: 8s - loss: 0.2406 - mean_iou: 0.48 - ETA: 6s - loss: 0.2395 - mean_iou: 0.48 - ETA: 4s - loss: 0.2400 - mean_iou: 0.48 - ETA: 2s - loss: 0.2386 - mean_iou: 0.48 - ETA: 1s - loss: 0.2379 - mean_iou: 0.4860Epoch 00085: val_loss improved from 0.22925 to 0.22654, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 67s - loss: 0.2382 - mean_iou: 0.4860 - val_loss: 0.2265 - val_mean_iou: 0.4865\n",
      "Epoch 87/100\n",
      "592/603 [============================>.] - ETA: 62s - loss: 0.2247 - mean_iou: 0.486 - ETA: 60s - loss: 0.2258 - mean_iou: 0.486 - ETA: 59s - loss: 0.2379 - mean_iou: 0.486 - ETA: 59s - loss: 0.2399 - mean_iou: 0.486 - ETA: 58s - loss: 0.2344 - mean_iou: 0.486 - ETA: 56s - loss: 0.2373 - mean_iou: 0.486 - ETA: 56s - loss: 0.2335 - mean_iou: 0.486 - ETA: 54s - loss: 0.2291 - mean_iou: 0.486 - ETA: 52s - loss: 0.2253 - mean_iou: 0.486 - ETA: 50s - loss: 0.2286 - mean_iou: 0.486 - ETA: 48s - loss: 0.2284 - mean_iou: 0.486 - ETA: 46s - loss: 0.2291 - mean_iou: 0.486 - ETA: 45s - loss: 0.2306 - mean_iou: 0.486 - ETA: 43s - loss: 0.2294 - mean_iou: 0.486 - ETA: 41s - loss: 0.2288 - mean_iou: 0.486 - ETA: 39s - loss: 0.2291 - mean_iou: 0.486 - ETA: 37s - loss: 0.2292 - mean_iou: 0.486 - ETA: 35s - loss: 0.2302 - mean_iou: 0.486 - ETA: 33s - loss: 0.2296 - mean_iou: 0.486 - ETA: 32s - loss: 0.2296 - mean_iou: 0.486 - ETA: 30s - loss: 0.2285 - mean_iou: 0.486 - ETA: 28s - loss: 0.2284 - mean_iou: 0.486 - ETA: 27s - loss: 0.2301 - mean_iou: 0.486 - ETA: 25s - loss: 0.2308 - mean_iou: 0.486 - ETA: 23s - loss: 0.2319 - mean_iou: 0.486 - ETA: 21s - loss: 0.2330 - mean_iou: 0.486 - ETA: 19s - loss: 0.2332 - mean_iou: 0.486 - ETA: 17s - loss: 0.2337 - mean_iou: 0.486 - ETA: 15s - loss: 0.2327 - mean_iou: 0.486 - ETA: 13s - loss: 0.2320 - mean_iou: 0.486 - ETA: 12s - loss: 0.2322 - mean_iou: 0.486 - ETA: 10s - loss: 0.2325 - mean_iou: 0.486 - ETA: 8s - loss: 0.2331 - mean_iou: 0.486 - ETA: 6s - loss: 0.2350 - mean_iou: 0.48 - ETA: 4s - loss: 0.2353 - mean_iou: 0.48 - ETA: 3s - loss: 0.2349 - mean_iou: 0.48 - ETA: 1s - loss: 0.2348 - mean_iou: 0.4870Epoch 00086: val_loss improved from 0.22654 to 0.22583, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 71s - loss: 0.2358 - mean_iou: 0.4870 - val_loss: 0.2258 - val_mean_iou: 0.4874\n",
      "Epoch 88/100\n",
      "592/603 [============================>.] - ETA: 69s - loss: 0.2237 - mean_iou: 0.487 - ETA: 67s - loss: 0.2256 - mean_iou: 0.487 - ETA: 64s - loss: 0.2351 - mean_iou: 0.487 - ETA: 60s - loss: 0.2254 - mean_iou: 0.487 - ETA: 58s - loss: 0.2302 - mean_iou: 0.487 - ETA: 55s - loss: 0.2301 - mean_iou: 0.487 - ETA: 53s - loss: 0.2317 - mean_iou: 0.487 - ETA: 51s - loss: 0.2403 - mean_iou: 0.487 - ETA: 50s - loss: 0.2404 - mean_iou: 0.487 - ETA: 48s - loss: 0.2428 - mean_iou: 0.487 - ETA: 46s - loss: 0.2394 - mean_iou: 0.487 - ETA: 44s - loss: 0.2368 - mean_iou: 0.487 - ETA: 43s - loss: 0.2334 - mean_iou: 0.487 - ETA: 41s - loss: 0.2370 - mean_iou: 0.487 - ETA: 40s - loss: 0.2347 - mean_iou: 0.487 - ETA: 39s - loss: 0.2368 - mean_iou: 0.487 - ETA: 37s - loss: 0.2365 - mean_iou: 0.487 - ETA: 35s - loss: 0.2366 - mean_iou: 0.487 - ETA: 33s - loss: 0.2372 - mean_iou: 0.487 - ETA: 31s - loss: 0.2371 - mean_iou: 0.487 - ETA: 30s - loss: 0.2385 - mean_iou: 0.487 - ETA: 28s - loss: 0.2379 - mean_iou: 0.487 - ETA: 26s - loss: 0.2382 - mean_iou: 0.487 - ETA: 24s - loss: 0.2383 - mean_iou: 0.487 - ETA: 22s - loss: 0.2401 - mean_iou: 0.487 - ETA: 21s - loss: 0.2396 - mean_iou: 0.487 - ETA: 19s - loss: 0.2395 - mean_iou: 0.487 - ETA: 17s - loss: 0.2400 - mean_iou: 0.487 - ETA: 15s - loss: 0.2400 - mean_iou: 0.487 - ETA: 13s - loss: 0.2417 - mean_iou: 0.487 - ETA: 11s - loss: 0.2419 - mean_iou: 0.487 - ETA: 10s - loss: 0.2402 - mean_iou: 0.487 - ETA: 8s - loss: 0.2399 - mean_iou: 0.487 - ETA: 6s - loss: 0.2390 - mean_iou: 0.48 - ETA: 4s - loss: 0.2408 - mean_iou: 0.48 - ETA: 3s - loss: 0.2396 - mean_iou: 0.48 - ETA: 1s - loss: 0.2403 - mean_iou: 0.4879Epoch 00087: val_loss did not improve\n",
      "603/603 [==============================] - 71s - loss: 0.2394 - mean_iou: 0.4879 - val_loss: 0.2264 - val_mean_iou: 0.4883\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 63s - loss: 0.2328 - mean_iou: 0.488 - ETA: 60s - loss: 0.2383 - mean_iou: 0.488 - ETA: 58s - loss: 0.2199 - mean_iou: 0.488 - ETA: 56s - loss: 0.2350 - mean_iou: 0.488 - ETA: 54s - loss: 0.2354 - mean_iou: 0.488 - ETA: 53s - loss: 0.2387 - mean_iou: 0.488 - ETA: 51s - loss: 0.2323 - mean_iou: 0.488 - ETA: 49s - loss: 0.2286 - mean_iou: 0.488 - ETA: 48s - loss: 0.2296 - mean_iou: 0.488 - ETA: 46s - loss: 0.2327 - mean_iou: 0.488 - ETA: 45s - loss: 0.2327 - mean_iou: 0.488 - ETA: 43s - loss: 0.2322 - mean_iou: 0.488 - ETA: 41s - loss: 0.2302 - mean_iou: 0.488 - ETA: 40s - loss: 0.2290 - mean_iou: 0.488 - ETA: 39s - loss: 0.2279 - mean_iou: 0.488 - ETA: 38s - loss: 0.2299 - mean_iou: 0.488 - ETA: 36s - loss: 0.2292 - mean_iou: 0.488 - ETA: 35s - loss: 0.2291 - mean_iou: 0.488 - ETA: 34s - loss: 0.2291 - mean_iou: 0.488 - ETA: 32s - loss: 0.2279 - mean_iou: 0.488 - ETA: 30s - loss: 0.2283 - mean_iou: 0.488 - ETA: 28s - loss: 0.2282 - mean_iou: 0.488 - ETA: 26s - loss: 0.2301 - mean_iou: 0.488 - ETA: 24s - loss: 0.2303 - mean_iou: 0.488 - ETA: 23s - loss: 0.2307 - mean_iou: 0.488 - ETA: 21s - loss: 0.2296 - mean_iou: 0.488 - ETA: 19s - loss: 0.2314 - mean_iou: 0.488 - ETA: 17s - loss: 0.2328 - mean_iou: 0.488 - ETA: 15s - loss: 0.2332 - mean_iou: 0.488 - ETA: 13s - loss: 0.2323 - mean_iou: 0.488 - ETA: 12s - loss: 0.2324 - mean_iou: 0.488 - ETA: 10s - loss: 0.2311 - mean_iou: 0.488 - ETA: 8s - loss: 0.2313 - mean_iou: 0.488 - ETA: 6s - loss: 0.2319 - mean_iou: 0.48 - ETA: 4s - loss: 0.2318 - mean_iou: 0.48 - ETA: 3s - loss: 0.2326 - mean_iou: 0.48 - ETA: 1s - loss: 0.2319 - mean_iou: 0.4888Epoch 00088: val_loss improved from 0.22583 to 0.22269, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 72s - loss: 0.2326 - mean_iou: 0.4888 - val_loss: 0.2227 - val_mean_iou: 0.4893\n",
      "Epoch 90/100\n",
      "592/603 [============================>.] - ETA: 76s - loss: 0.2299 - mean_iou: 0.489 - ETA: 74s - loss: 0.2492 - mean_iou: 0.489 - ETA: 71s - loss: 0.2471 - mean_iou: 0.489 - ETA: 69s - loss: 0.2440 - mean_iou: 0.489 - ETA: 68s - loss: 0.2407 - mean_iou: 0.489 - ETA: 65s - loss: 0.2349 - mean_iou: 0.489 - ETA: 64s - loss: 0.2323 - mean_iou: 0.489 - ETA: 62s - loss: 0.2349 - mean_iou: 0.489 - ETA: 60s - loss: 0.2328 - mean_iou: 0.489 - ETA: 58s - loss: 0.2358 - mean_iou: 0.489 - ETA: 58s - loss: 0.2375 - mean_iou: 0.489 - ETA: 55s - loss: 0.2334 - mean_iou: 0.489 - ETA: 53s - loss: 0.2303 - mean_iou: 0.489 - ETA: 51s - loss: 0.2318 - mean_iou: 0.489 - ETA: 49s - loss: 0.2333 - mean_iou: 0.489 - ETA: 46s - loss: 0.2320 - mean_iou: 0.489 - ETA: 44s - loss: 0.2292 - mean_iou: 0.489 - ETA: 42s - loss: 0.2276 - mean_iou: 0.489 - ETA: 39s - loss: 0.2283 - mean_iou: 0.489 - ETA: 37s - loss: 0.2300 - mean_iou: 0.489 - ETA: 35s - loss: 0.2319 - mean_iou: 0.489 - ETA: 33s - loss: 0.2332 - mean_iou: 0.489 - ETA: 31s - loss: 0.2329 - mean_iou: 0.489 - ETA: 29s - loss: 0.2336 - mean_iou: 0.489 - ETA: 27s - loss: 0.2322 - mean_iou: 0.489 - ETA: 25s - loss: 0.2318 - mean_iou: 0.489 - ETA: 23s - loss: 0.2306 - mean_iou: 0.489 - ETA: 21s - loss: 0.2313 - mean_iou: 0.489 - ETA: 18s - loss: 0.2313 - mean_iou: 0.489 - ETA: 16s - loss: 0.2304 - mean_iou: 0.489 - ETA: 14s - loss: 0.2294 - mean_iou: 0.489 - ETA: 12s - loss: 0.2298 - mean_iou: 0.489 - ETA: 10s - loss: 0.2295 - mean_iou: 0.489 - ETA: 7s - loss: 0.2298 - mean_iou: 0.489 - ETA: 5s - loss: 0.2307 - mean_iou: 0.48 - ETA: 3s - loss: 0.2308 - mean_iou: 0.48 - ETA: 1s - loss: 0.2306 - mean_iou: 0.4899Epoch 00089: val_loss improved from 0.22269 to 0.22085, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 82s - loss: 0.2312 - mean_iou: 0.4899 - val_loss: 0.2209 - val_mean_iou: 0.4905\n",
      "Epoch 91/100\n",
      "592/603 [============================>.] - ETA: 65s - loss: 0.2741 - mean_iou: 0.490 - ETA: 67s - loss: 0.2609 - mean_iou: 0.490 - ETA: 65s - loss: 0.2626 - mean_iou: 0.490 - ETA: 63s - loss: 0.2452 - mean_iou: 0.490 - ETA: 61s - loss: 0.2450 - mean_iou: 0.490 - ETA: 59s - loss: 0.2452 - mean_iou: 0.490 - ETA: 56s - loss: 0.2389 - mean_iou: 0.490 - ETA: 54s - loss: 0.2380 - mean_iou: 0.490 - ETA: 52s - loss: 0.2387 - mean_iou: 0.490 - ETA: 50s - loss: 0.2395 - mean_iou: 0.490 - ETA: 48s - loss: 0.2407 - mean_iou: 0.490 - ETA: 46s - loss: 0.2389 - mean_iou: 0.490 - ETA: 45s - loss: 0.2367 - mean_iou: 0.490 - ETA: 43s - loss: 0.2359 - mean_iou: 0.490 - ETA: 41s - loss: 0.2334 - mean_iou: 0.490 - ETA: 39s - loss: 0.2333 - mean_iou: 0.490 - ETA: 37s - loss: 0.2323 - mean_iou: 0.490 - ETA: 35s - loss: 0.2308 - mean_iou: 0.490 - ETA: 34s - loss: 0.2300 - mean_iou: 0.490 - ETA: 32s - loss: 0.2292 - mean_iou: 0.490 - ETA: 30s - loss: 0.2300 - mean_iou: 0.490 - ETA: 28s - loss: 0.2294 - mean_iou: 0.490 - ETA: 26s - loss: 0.2281 - mean_iou: 0.490 - ETA: 24s - loss: 0.2264 - mean_iou: 0.490 - ETA: 23s - loss: 0.2270 - mean_iou: 0.490 - ETA: 21s - loss: 0.2273 - mean_iou: 0.490 - ETA: 19s - loss: 0.2263 - mean_iou: 0.490 - ETA: 17s - loss: 0.2273 - mean_iou: 0.490 - ETA: 15s - loss: 0.2276 - mean_iou: 0.490 - ETA: 13s - loss: 0.2273 - mean_iou: 0.490 - ETA: 12s - loss: 0.2288 - mean_iou: 0.491 - ETA: 10s - loss: 0.2296 - mean_iou: 0.491 - ETA: 8s - loss: 0.2295 - mean_iou: 0.491 - ETA: 6s - loss: 0.2288 - mean_iou: 0.49 - ETA: 4s - loss: 0.2288 - mean_iou: 0.49 - ETA: 3s - loss: 0.2291 - mean_iou: 0.49 - ETA: 1s - loss: 0.2287 - mean_iou: 0.4910Epoch 00090: val_loss improved from 0.22085 to 0.21935, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 71s - loss: 0.2299 - mean_iou: 0.4910 - val_loss: 0.2194 - val_mean_iou: 0.4916\n",
      "Epoch 92/100\n",
      "592/603 [============================>.] - ETA: 73s - loss: 0.2079 - mean_iou: 0.491 - ETA: 69s - loss: 0.2279 - mean_iou: 0.491 - ETA: 67s - loss: 0.2153 - mean_iou: 0.491 - ETA: 66s - loss: 0.2161 - mean_iou: 0.491 - ETA: 63s - loss: 0.2244 - mean_iou: 0.491 - ETA: 61s - loss: 0.2270 - mean_iou: 0.491 - ETA: 59s - loss: 0.2295 - mean_iou: 0.491 - ETA: 56s - loss: 0.2312 - mean_iou: 0.491 - ETA: 53s - loss: 0.2292 - mean_iou: 0.491 - ETA: 51s - loss: 0.2282 - mean_iou: 0.491 - ETA: 48s - loss: 0.2305 - mean_iou: 0.491 - ETA: 47s - loss: 0.2253 - mean_iou: 0.491 - ETA: 45s - loss: 0.2232 - mean_iou: 0.491 - ETA: 43s - loss: 0.2228 - mean_iou: 0.491 - ETA: 41s - loss: 0.2251 - mean_iou: 0.491 - ETA: 39s - loss: 0.2232 - mean_iou: 0.491 - ETA: 37s - loss: 0.2236 - mean_iou: 0.491 - ETA: 35s - loss: 0.2261 - mean_iou: 0.491 - ETA: 33s - loss: 0.2251 - mean_iou: 0.491 - ETA: 31s - loss: 0.2252 - mean_iou: 0.491 - ETA: 29s - loss: 0.2263 - mean_iou: 0.491 - ETA: 28s - loss: 0.2261 - mean_iou: 0.491 - ETA: 26s - loss: 0.2266 - mean_iou: 0.492 - ETA: 24s - loss: 0.2270 - mean_iou: 0.492 - ETA: 22s - loss: 0.2275 - mean_iou: 0.492 - ETA: 20s - loss: 0.2289 - mean_iou: 0.492 - ETA: 18s - loss: 0.2286 - mean_iou: 0.492 - ETA: 17s - loss: 0.2296 - mean_iou: 0.492 - ETA: 15s - loss: 0.2291 - mean_iou: 0.492 - ETA: 13s - loss: 0.2296 - mean_iou: 0.492 - ETA: 11s - loss: 0.2292 - mean_iou: 0.492 - ETA: 10s - loss: 0.2286 - mean_iou: 0.492 - ETA: 8s - loss: 0.2297 - mean_iou: 0.492 - ETA: 6s - loss: 0.2293 - mean_iou: 0.49 - ETA: 4s - loss: 0.2291 - mean_iou: 0.49 - ETA: 2s - loss: 0.2286 - mean_iou: 0.49 - ETA: 1s - loss: 0.2288 - mean_iou: 0.4921Epoch 00091: val_loss improved from 0.21935 to 0.21877, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 70s - loss: 0.2282 - mean_iou: 0.4922 - val_loss: 0.2188 - val_mean_iou: 0.4927\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 63s - loss: 0.2524 - mean_iou: 0.492 - ETA: 65s - loss: 0.2487 - mean_iou: 0.492 - ETA: 63s - loss: 0.2420 - mean_iou: 0.492 - ETA: 62s - loss: 0.2431 - mean_iou: 0.492 - ETA: 59s - loss: 0.2375 - mean_iou: 0.492 - ETA: 57s - loss: 0.2297 - mean_iou: 0.492 - ETA: 54s - loss: 0.2276 - mean_iou: 0.492 - ETA: 52s - loss: 0.2258 - mean_iou: 0.492 - ETA: 50s - loss: 0.2253 - mean_iou: 0.492 - ETA: 49s - loss: 0.2248 - mean_iou: 0.492 - ETA: 47s - loss: 0.2254 - mean_iou: 0.492 - ETA: 45s - loss: 0.2244 - mean_iou: 0.492 - ETA: 43s - loss: 0.2223 - mean_iou: 0.492 - ETA: 41s - loss: 0.2211 - mean_iou: 0.492 - ETA: 40s - loss: 0.2204 - mean_iou: 0.492 - ETA: 38s - loss: 0.2209 - mean_iou: 0.493 - ETA: 37s - loss: 0.2210 - mean_iou: 0.493 - ETA: 35s - loss: 0.2216 - mean_iou: 0.493 - ETA: 33s - loss: 0.2204 - mean_iou: 0.493 - ETA: 31s - loss: 0.2221 - mean_iou: 0.493 - ETA: 29s - loss: 0.2224 - mean_iou: 0.493 - ETA: 27s - loss: 0.2235 - mean_iou: 0.493 - ETA: 26s - loss: 0.2241 - mean_iou: 0.493 - ETA: 24s - loss: 0.2253 - mean_iou: 0.493 - ETA: 22s - loss: 0.2239 - mean_iou: 0.493 - ETA: 20s - loss: 0.2234 - mean_iou: 0.493 - ETA: 19s - loss: 0.2234 - mean_iou: 0.493 - ETA: 17s - loss: 0.2240 - mean_iou: 0.493 - ETA: 15s - loss: 0.2228 - mean_iou: 0.493 - ETA: 13s - loss: 0.2241 - mean_iou: 0.493 - ETA: 12s - loss: 0.2248 - mean_iou: 0.493 - ETA: 10s - loss: 0.2263 - mean_iou: 0.493 - ETA: 8s - loss: 0.2258 - mean_iou: 0.493 - ETA: 6s - loss: 0.2263 - mean_iou: 0.49 - ETA: 4s - loss: 0.2258 - mean_iou: 0.49 - ETA: 3s - loss: 0.2261 - mean_iou: 0.49 - ETA: 1s - loss: 0.2256 - mean_iou: 0.4932Epoch 00092: val_loss improved from 0.21877 to 0.21634, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 71s - loss: 0.2262 - mean_iou: 0.4932 - val_loss: 0.2163 - val_mean_iou: 0.4938\n",
      "Epoch 94/100\n",
      "592/603 [============================>.] - ETA: 63s - loss: 0.2524 - mean_iou: 0.493 - ETA: 60s - loss: 0.2492 - mean_iou: 0.493 - ETA: 58s - loss: 0.2459 - mean_iou: 0.493 - ETA: 55s - loss: 0.2424 - mean_iou: 0.493 - ETA: 53s - loss: 0.2347 - mean_iou: 0.493 - ETA: 52s - loss: 0.2378 - mean_iou: 0.493 - ETA: 50s - loss: 0.2336 - mean_iou: 0.493 - ETA: 48s - loss: 0.2288 - mean_iou: 0.493 - ETA: 46s - loss: 0.2272 - mean_iou: 0.493 - ETA: 44s - loss: 0.2238 - mean_iou: 0.494 - ETA: 43s - loss: 0.2228 - mean_iou: 0.494 - ETA: 41s - loss: 0.2242 - mean_iou: 0.494 - ETA: 39s - loss: 0.2233 - mean_iou: 0.494 - ETA: 38s - loss: 0.2244 - mean_iou: 0.494 - ETA: 36s - loss: 0.2253 - mean_iou: 0.494 - ETA: 34s - loss: 0.2240 - mean_iou: 0.494 - ETA: 33s - loss: 0.2255 - mean_iou: 0.494 - ETA: 31s - loss: 0.2257 - mean_iou: 0.494 - ETA: 29s - loss: 0.2257 - mean_iou: 0.494 - ETA: 28s - loss: 0.2259 - mean_iou: 0.494 - ETA: 26s - loss: 0.2248 - mean_iou: 0.494 - ETA: 25s - loss: 0.2242 - mean_iou: 0.494 - ETA: 23s - loss: 0.2254 - mean_iou: 0.494 - ETA: 21s - loss: 0.2250 - mean_iou: 0.494 - ETA: 20s - loss: 0.2260 - mean_iou: 0.494 - ETA: 18s - loss: 0.2257 - mean_iou: 0.494 - ETA: 17s - loss: 0.2263 - mean_iou: 0.494 - ETA: 15s - loss: 0.2268 - mean_iou: 0.494 - ETA: 13s - loss: 0.2273 - mean_iou: 0.494 - ETA: 12s - loss: 0.2275 - mean_iou: 0.494 - ETA: 10s - loss: 0.2280 - mean_iou: 0.494 - ETA: 9s - loss: 0.2269 - mean_iou: 0.494 - ETA: 7s - loss: 0.2263 - mean_iou: 0.49 - ETA: 5s - loss: 0.2259 - mean_iou: 0.49 - ETA: 4s - loss: 0.2270 - mean_iou: 0.49 - ETA: 2s - loss: 0.2277 - mean_iou: 0.49 - ETA: 1s - loss: 0.2266 - mean_iou: 0.4943Epoch 00093: val_loss did not improve\n",
      "603/603 [==============================] - 63s - loss: 0.2257 - mean_iou: 0.4943 - val_loss: 0.2168 - val_mean_iou: 0.4948\n",
      "Epoch 95/100\n",
      "592/603 [============================>.] - ETA: 59s - loss: 0.1949 - mean_iou: 0.494 - ETA: 58s - loss: 0.2238 - mean_iou: 0.494 - ETA: 55s - loss: 0.2248 - mean_iou: 0.494 - ETA: 54s - loss: 0.2163 - mean_iou: 0.494 - ETA: 52s - loss: 0.2213 - mean_iou: 0.494 - ETA: 50s - loss: 0.2270 - mean_iou: 0.494 - ETA: 48s - loss: 0.2311 - mean_iou: 0.495 - ETA: 47s - loss: 0.2296 - mean_iou: 0.495 - ETA: 45s - loss: 0.2302 - mean_iou: 0.495 - ETA: 43s - loss: 0.2293 - mean_iou: 0.495 - ETA: 42s - loss: 0.2288 - mean_iou: 0.495 - ETA: 40s - loss: 0.2341 - mean_iou: 0.495 - ETA: 39s - loss: 0.2321 - mean_iou: 0.495 - ETA: 37s - loss: 0.2308 - mean_iou: 0.495 - ETA: 35s - loss: 0.2314 - mean_iou: 0.495 - ETA: 34s - loss: 0.2351 - mean_iou: 0.495 - ETA: 32s - loss: 0.2338 - mean_iou: 0.495 - ETA: 31s - loss: 0.2311 - mean_iou: 0.495 - ETA: 29s - loss: 0.2309 - mean_iou: 0.495 - ETA: 27s - loss: 0.2317 - mean_iou: 0.495 - ETA: 26s - loss: 0.2297 - mean_iou: 0.495 - ETA: 24s - loss: 0.2303 - mean_iou: 0.495 - ETA: 23s - loss: 0.2324 - mean_iou: 0.495 - ETA: 21s - loss: 0.2315 - mean_iou: 0.495 - ETA: 19s - loss: 0.2311 - mean_iou: 0.495 - ETA: 18s - loss: 0.2309 - mean_iou: 0.495 - ETA: 16s - loss: 0.2290 - mean_iou: 0.495 - ETA: 15s - loss: 0.2274 - mean_iou: 0.495 - ETA: 13s - loss: 0.2266 - mean_iou: 0.495 - ETA: 12s - loss: 0.2260 - mean_iou: 0.495 - ETA: 10s - loss: 0.2258 - mean_iou: 0.495 - ETA: 9s - loss: 0.2258 - mean_iou: 0.495 - ETA: 7s - loss: 0.2265 - mean_iou: 0.49 - ETA: 5s - loss: 0.2269 - mean_iou: 0.49 - ETA: 4s - loss: 0.2258 - mean_iou: 0.49 - ETA: 2s - loss: 0.2265 - mean_iou: 0.49 - ETA: 1s - loss: 0.2263 - mean_iou: 0.4953Epoch 00094: val_loss improved from 0.21634 to 0.21386, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 63s - loss: 0.2262 - mean_iou: 0.4953 - val_loss: 0.2139 - val_mean_iou: 0.4958\n",
      "Epoch 96/100\n",
      "592/603 [============================>.] - ETA: 59s - loss: 0.2373 - mean_iou: 0.495 - ETA: 59s - loss: 0.2323 - mean_iou: 0.495 - ETA: 56s - loss: 0.2213 - mean_iou: 0.495 - ETA: 54s - loss: 0.2225 - mean_iou: 0.495 - ETA: 52s - loss: 0.2275 - mean_iou: 0.495 - ETA: 51s - loss: 0.2322 - mean_iou: 0.496 - ETA: 50s - loss: 0.2265 - mean_iou: 0.496 - ETA: 48s - loss: 0.2318 - mean_iou: 0.496 - ETA: 46s - loss: 0.2299 - mean_iou: 0.496 - ETA: 44s - loss: 0.2297 - mean_iou: 0.496 - ETA: 43s - loss: 0.2293 - mean_iou: 0.496 - ETA: 41s - loss: 0.2307 - mean_iou: 0.496 - ETA: 40s - loss: 0.2296 - mean_iou: 0.496 - ETA: 38s - loss: 0.2274 - mean_iou: 0.496 - ETA: 36s - loss: 0.2233 - mean_iou: 0.496 - ETA: 35s - loss: 0.2214 - mean_iou: 0.496 - ETA: 33s - loss: 0.2209 - mean_iou: 0.496 - ETA: 31s - loss: 0.2198 - mean_iou: 0.496 - ETA: 30s - loss: 0.2184 - mean_iou: 0.496 - ETA: 28s - loss: 0.2169 - mean_iou: 0.496 - ETA: 26s - loss: 0.2166 - mean_iou: 0.496 - ETA: 25s - loss: 0.2167 - mean_iou: 0.496 - ETA: 23s - loss: 0.2169 - mean_iou: 0.496 - ETA: 22s - loss: 0.2170 - mean_iou: 0.496 - ETA: 20s - loss: 0.2164 - mean_iou: 0.496 - ETA: 18s - loss: 0.2182 - mean_iou: 0.496 - ETA: 17s - loss: 0.2181 - mean_iou: 0.496 - ETA: 15s - loss: 0.2173 - mean_iou: 0.496 - ETA: 13s - loss: 0.2190 - mean_iou: 0.496 - ETA: 12s - loss: 0.2197 - mean_iou: 0.496 - ETA: 10s - loss: 0.2202 - mean_iou: 0.496 - ETA: 9s - loss: 0.2199 - mean_iou: 0.496 - ETA: 7s - loss: 0.2198 - mean_iou: 0.49 - ETA: 5s - loss: 0.2209 - mean_iou: 0.49 - ETA: 4s - loss: 0.2204 - mean_iou: 0.49 - ETA: 2s - loss: 0.2203 - mean_iou: 0.49 - ETA: 1s - loss: 0.2215 - mean_iou: 0.4963Epoch 00095: val_loss improved from 0.21386 to 0.21212, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.2214 - mean_iou: 0.4964 - val_loss: 0.2121 - val_mean_iou: 0.4969\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592/603 [============================>.] - ETA: 63s - loss: 0.2303 - mean_iou: 0.496 - ETA: 64s - loss: 0.2396 - mean_iou: 0.496 - ETA: 63s - loss: 0.2388 - mean_iou: 0.496 - ETA: 61s - loss: 0.2382 - mean_iou: 0.497 - ETA: 60s - loss: 0.2316 - mean_iou: 0.497 - ETA: 58s - loss: 0.2330 - mean_iou: 0.497 - ETA: 56s - loss: 0.2364 - mean_iou: 0.497 - ETA: 54s - loss: 0.2351 - mean_iou: 0.497 - ETA: 52s - loss: 0.2367 - mean_iou: 0.497 - ETA: 50s - loss: 0.2365 - mean_iou: 0.497 - ETA: 48s - loss: 0.2376 - mean_iou: 0.497 - ETA: 46s - loss: 0.2388 - mean_iou: 0.497 - ETA: 44s - loss: 0.2385 - mean_iou: 0.497 - ETA: 42s - loss: 0.2341 - mean_iou: 0.497 - ETA: 40s - loss: 0.2328 - mean_iou: 0.497 - ETA: 38s - loss: 0.2322 - mean_iou: 0.497 - ETA: 36s - loss: 0.2293 - mean_iou: 0.497 - ETA: 34s - loss: 0.2280 - mean_iou: 0.497 - ETA: 32s - loss: 0.2267 - mean_iou: 0.497 - ETA: 30s - loss: 0.2246 - mean_iou: 0.497 - ETA: 29s - loss: 0.2232 - mean_iou: 0.497 - ETA: 27s - loss: 0.2237 - mean_iou: 0.497 - ETA: 25s - loss: 0.2250 - mean_iou: 0.497 - ETA: 23s - loss: 0.2250 - mean_iou: 0.497 - ETA: 21s - loss: 0.2231 - mean_iou: 0.497 - ETA: 20s - loss: 0.2239 - mean_iou: 0.497 - ETA: 18s - loss: 0.2233 - mean_iou: 0.497 - ETA: 16s - loss: 0.2237 - mean_iou: 0.497 - ETA: 15s - loss: 0.2223 - mean_iou: 0.497 - ETA: 13s - loss: 0.2248 - mean_iou: 0.497 - ETA: 11s - loss: 0.2240 - mean_iou: 0.497 - ETA: 9s - loss: 0.2231 - mean_iou: 0.497 - ETA: 8s - loss: 0.2236 - mean_iou: 0.49 - ETA: 6s - loss: 0.2241 - mean_iou: 0.49 - ETA: 4s - loss: 0.2244 - mean_iou: 0.49 - ETA: 2s - loss: 0.2242 - mean_iou: 0.49 - ETA: 1s - loss: 0.2230 - mean_iou: 0.4973Epoch 00096: val_loss improved from 0.21212 to 0.21178, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 68s - loss: 0.2231 - mean_iou: 0.4973 - val_loss: 0.2118 - val_mean_iou: 0.4978\n",
      "Epoch 98/100\n",
      "592/603 [============================>.] - ETA: 62s - loss: 0.2449 - mean_iou: 0.497 - ETA: 58s - loss: 0.2409 - mean_iou: 0.497 - ETA: 56s - loss: 0.2300 - mean_iou: 0.497 - ETA: 54s - loss: 0.2324 - mean_iou: 0.497 - ETA: 52s - loss: 0.2345 - mean_iou: 0.497 - ETA: 50s - loss: 0.2343 - mean_iou: 0.498 - ETA: 49s - loss: 0.2324 - mean_iou: 0.498 - ETA: 47s - loss: 0.2311 - mean_iou: 0.498 - ETA: 45s - loss: 0.2343 - mean_iou: 0.498 - ETA: 44s - loss: 0.2339 - mean_iou: 0.498 - ETA: 42s - loss: 0.2335 - mean_iou: 0.498 - ETA: 40s - loss: 0.2323 - mean_iou: 0.498 - ETA: 39s - loss: 0.2310 - mean_iou: 0.498 - ETA: 38s - loss: 0.2295 - mean_iou: 0.498 - ETA: 36s - loss: 0.2280 - mean_iou: 0.498 - ETA: 34s - loss: 0.2259 - mean_iou: 0.498 - ETA: 33s - loss: 0.2246 - mean_iou: 0.498 - ETA: 31s - loss: 0.2248 - mean_iou: 0.498 - ETA: 30s - loss: 0.2238 - mean_iou: 0.498 - ETA: 28s - loss: 0.2237 - mean_iou: 0.498 - ETA: 26s - loss: 0.2245 - mean_iou: 0.498 - ETA: 25s - loss: 0.2272 - mean_iou: 0.498 - ETA: 23s - loss: 0.2260 - mean_iou: 0.498 - ETA: 22s - loss: 0.2272 - mean_iou: 0.498 - ETA: 20s - loss: 0.2257 - mean_iou: 0.498 - ETA: 18s - loss: 0.2266 - mean_iou: 0.498 - ETA: 17s - loss: 0.2264 - mean_iou: 0.498 - ETA: 15s - loss: 0.2260 - mean_iou: 0.498 - ETA: 14s - loss: 0.2253 - mean_iou: 0.498 - ETA: 12s - loss: 0.2242 - mean_iou: 0.498 - ETA: 10s - loss: 0.2237 - mean_iou: 0.498 - ETA: 9s - loss: 0.2237 - mean_iou: 0.498 - ETA: 7s - loss: 0.2222 - mean_iou: 0.49 - ETA: 5s - loss: 0.2215 - mean_iou: 0.49 - ETA: 4s - loss: 0.2223 - mean_iou: 0.49 - ETA: 2s - loss: 0.2206 - mean_iou: 0.49 - ETA: 1s - loss: 0.2213 - mean_iou: 0.4983Epoch 00097: val_loss improved from 0.21178 to 0.21002, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 64s - loss: 0.2217 - mean_iou: 0.4983 - val_loss: 0.2100 - val_mean_iou: 0.4988\n",
      "Epoch 99/100\n",
      "592/603 [============================>.] - ETA: 59s - loss: 0.2669 - mean_iou: 0.498 - ETA: 57s - loss: 0.2470 - mean_iou: 0.498 - ETA: 55s - loss: 0.2439 - mean_iou: 0.498 - ETA: 53s - loss: 0.2392 - mean_iou: 0.498 - ETA: 51s - loss: 0.2404 - mean_iou: 0.498 - ETA: 50s - loss: 0.2385 - mean_iou: 0.498 - ETA: 48s - loss: 0.2356 - mean_iou: 0.498 - ETA: 47s - loss: 0.2289 - mean_iou: 0.498 - ETA: 46s - loss: 0.2295 - mean_iou: 0.498 - ETA: 44s - loss: 0.2240 - mean_iou: 0.499 - ETA: 42s - loss: 0.2226 - mean_iou: 0.499 - ETA: 41s - loss: 0.2213 - mean_iou: 0.499 - ETA: 39s - loss: 0.2213 - mean_iou: 0.499 - ETA: 37s - loss: 0.2235 - mean_iou: 0.499 - ETA: 36s - loss: 0.2230 - mean_iou: 0.499 - ETA: 34s - loss: 0.2231 - mean_iou: 0.499 - ETA: 33s - loss: 0.2257 - mean_iou: 0.499 - ETA: 31s - loss: 0.2264 - mean_iou: 0.499 - ETA: 29s - loss: 0.2269 - mean_iou: 0.499 - ETA: 28s - loss: 0.2241 - mean_iou: 0.499 - ETA: 26s - loss: 0.2241 - mean_iou: 0.499 - ETA: 25s - loss: 0.2237 - mean_iou: 0.499 - ETA: 23s - loss: 0.2239 - mean_iou: 0.499 - ETA: 21s - loss: 0.2252 - mean_iou: 0.499 - ETA: 20s - loss: 0.2226 - mean_iou: 0.499 - ETA: 18s - loss: 0.2217 - mean_iou: 0.499 - ETA: 17s - loss: 0.2215 - mean_iou: 0.499 - ETA: 15s - loss: 0.2223 - mean_iou: 0.499 - ETA: 14s - loss: 0.2237 - mean_iou: 0.499 - ETA: 12s - loss: 0.2243 - mean_iou: 0.499 - ETA: 10s - loss: 0.2242 - mean_iou: 0.499 - ETA: 9s - loss: 0.2230 - mean_iou: 0.499 - ETA: 7s - loss: 0.2234 - mean_iou: 0.49 - ETA: 5s - loss: 0.2239 - mean_iou: 0.49 - ETA: 4s - loss: 0.2227 - mean_iou: 0.49 - ETA: 2s - loss: 0.2218 - mean_iou: 0.49 - ETA: 1s - loss: 0.2224 - mean_iou: 0.4993Epoch 00098: val_loss did not improve\n",
      "603/603 [==============================] - 64s - loss: 0.2225 - mean_iou: 0.4993 - val_loss: 0.2109 - val_mean_iou: 0.4997\n",
      "Epoch 100/100\n",
      "592/603 [============================>.] - ETA: 63s - loss: 0.2389 - mean_iou: 0.499 - ETA: 59s - loss: 0.2357 - mean_iou: 0.499 - ETA: 56s - loss: 0.2377 - mean_iou: 0.499 - ETA: 55s - loss: 0.2252 - mean_iou: 0.499 - ETA: 53s - loss: 0.2204 - mean_iou: 0.499 - ETA: 51s - loss: 0.2207 - mean_iou: 0.499 - ETA: 50s - loss: 0.2217 - mean_iou: 0.499 - ETA: 48s - loss: 0.2203 - mean_iou: 0.499 - ETA: 47s - loss: 0.2166 - mean_iou: 0.499 - ETA: 45s - loss: 0.2146 - mean_iou: 0.499 - ETA: 43s - loss: 0.2182 - mean_iou: 0.499 - ETA: 42s - loss: 0.2182 - mean_iou: 0.499 - ETA: 40s - loss: 0.2188 - mean_iou: 0.499 - ETA: 39s - loss: 0.2163 - mean_iou: 0.499 - ETA: 37s - loss: 0.2168 - mean_iou: 0.499 - ETA: 35s - loss: 0.2149 - mean_iou: 0.500 - ETA: 34s - loss: 0.2164 - mean_iou: 0.500 - ETA: 32s - loss: 0.2156 - mean_iou: 0.500 - ETA: 30s - loss: 0.2162 - mean_iou: 0.500 - ETA: 28s - loss: 0.2187 - mean_iou: 0.500 - ETA: 27s - loss: 0.2198 - mean_iou: 0.500 - ETA: 25s - loss: 0.2208 - mean_iou: 0.500 - ETA: 24s - loss: 0.2196 - mean_iou: 0.500 - ETA: 22s - loss: 0.2196 - mean_iou: 0.500 - ETA: 20s - loss: 0.2202 - mean_iou: 0.500 - ETA: 19s - loss: 0.2197 - mean_iou: 0.500 - ETA: 17s - loss: 0.2197 - mean_iou: 0.500 - ETA: 15s - loss: 0.2194 - mean_iou: 0.500 - ETA: 14s - loss: 0.2198 - mean_iou: 0.500 - ETA: 12s - loss: 0.2204 - mean_iou: 0.500 - ETA: 11s - loss: 0.2204 - mean_iou: 0.500 - ETA: 9s - loss: 0.2200 - mean_iou: 0.500 - ETA: 7s - loss: 0.2207 - mean_iou: 0.50 - ETA: 6s - loss: 0.2214 - mean_iou: 0.50 - ETA: 4s - loss: 0.2211 - mean_iou: 0.50 - ETA: 2s - loss: 0.2210 - mean_iou: 0.50 - ETA: 1s - loss: 0.2210 - mean_iou: 0.5002Epoch 00099: val_loss improved from 0.21002 to 0.20965, saving model to model-dsbowl2018-mode-simplecnn-ep-100.h5\n",
      "603/603 [==============================] - 67s - loss: 0.2211 - mean_iou: 0.5002 - val_loss: 0.2097 - val_mean_iou: 0.5006\n"
     ]
    }
   ],
   "source": [
    "# Do the Training \n",
    "\n",
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model-dsbowl2018-mode-simplecnn-ep-100.h5', verbose=1, save_best_only=True)\n",
    "results = cnnmodel.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=100, \n",
    "                    callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c3b9f148-1dba-4b6a-981b-6cdbf394fc3c",
    "_uuid": "986488a4c5223576be370e224426a30431911eb2"
   },
   "source": [
    "# Build and train our neural network\n",
    "Next we build our U-Net model, loosely based on [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/pdf/1505.04597.pdf) and very similar to [this repo](https://github.com/jocicmarko/ultrasound-nerve-segmentation) from the Kaggle Ultrasound Nerve Segmentation competition.\n",
    "\n",
    "![](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "c1dbc57c-b497-4ccb-b077-2053203ab7ed",
    "_uuid": "0aa97d66c29f45dfac9b0f45fcf74ba0e778ba5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 128, 128, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)                (None, 128, 128, 3)   0           input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)               (None, 128, 128, 16)  448         lambda_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 128, 128, 16)  0           conv2d_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)               (None, 128, 128, 16)  2320        dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, 64, 64, 16)    0           conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)               (None, 64, 64, 32)    4640        max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 64, 64, 32)    0           conv2d_22[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)               (None, 64, 64, 32)    9248        dropout_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)   (None, 32, 32, 32)    0           conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 32, 32, 64)    18496       max_pooling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 32, 32, 64)    0           conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)               (None, 32, 32, 64)    36928       dropout_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)   (None, 16, 16, 64)    0           conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)               (None, 16, 16, 128)   73856       max_pooling2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)             (None, 16, 16, 128)   0           conv2d_26[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)               (None, 16, 16, 128)   147584      dropout_13[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)   (None, 8, 8, 128)     0           conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)               (None, 8, 8, 256)     295168      max_pooling2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)             (None, 8, 8, 256)     0           conv2d_28[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)               (None, 8, 8, 256)     590080      dropout_14[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTransp (None, 16, 16, 128)   131200      conv2d_29[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 16, 16, 256)   0           conv2d_transpose_5[0][0]         \n",
      "                                                                   conv2d_27[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)               (None, 16, 16, 128)   295040      concatenate_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)             (None, 16, 16, 128)   0           conv2d_30[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)               (None, 16, 16, 128)   147584      dropout_15[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTransp (None, 32, 32, 64)    32832       conv2d_31[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)      (None, 32, 32, 128)   0           conv2d_transpose_6[0][0]         \n",
      "                                                                   conv2d_25[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)               (None, 32, 32, 64)    73792       concatenate_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)             (None, 32, 32, 64)    0           conv2d_32[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)               (None, 32, 32, 64)    36928       dropout_16[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTransp (None, 64, 64, 32)    8224        conv2d_33[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)      (None, 64, 64, 64)    0           conv2d_transpose_7[0][0]         \n",
      "                                                                   conv2d_23[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)               (None, 64, 64, 32)    18464       concatenate_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)             (None, 64, 64, 32)    0           conv2d_34[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)               (None, 64, 64, 32)    9248        dropout_17[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTransp (None, 128, 128, 16)  2064        conv2d_35[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)      (None, 128, 128, 32)  0           conv2d_transpose_8[0][0]         \n",
      "                                                                   conv2d_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)               (None, 128, 128, 16)  4624        concatenate_8[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)             (None, 128, 128, 16)  0           conv2d_36[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)               (None, 128, 128, 16)  2320        dropout_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)               (None, 128, 128, 1)   17          conv2d_37[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,941,105\n",
      "Trainable params: 1,941,105\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build U-Net model\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = Lambda(lambda x: x / 255) (inputs) #Normalization \n",
    "\n",
    "# Upconversion\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "#Downconversion\n",
    "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "72330944-6ce7-4070-b276-c3c4b20c4fe5",
    "_uuid": "92350b6e18cc50f3fa7b6e9a02d39fcbff8238f7"
   },
   "source": [
    "*Update: Changed to ELU units, added dropout.*\n",
    "\n",
    "Next we fit the model on the training data, using a validation split of 0.1. We use a small batch size because we have so little data. I recommend using checkpointing and early stopping when training your model. I won't do it here to make things a bit more reproducible (although it's very likely that your results will be different anyway). I'll just train for 10 epochs, which takes around 10 minutes in the Kaggle kernel with the current parameters. \n",
    "\n",
    "*Update: Added early stopping and checkpointing and increased to 30 epochs.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "9415b1c4-aa69-41b9-a1e3-d6053dbd4f64",
    "_uuid": "c060db22daa2abf12b28240cd81bbcbf1ce1bf87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 536 samples, validate on 134 samples\n",
      "Epoch 1/100\n",
      "528/536 [============================>.] - ETA: 128s - loss: 0.0785 - mean_iou: 0.0000e+ - ETA: 117s - loss: 0.0852 - mean_iou: 0.4305   - ETA: 113s - loss: 0.0818 - mean_iou: 0.56 - ETA: 108s - loss: 0.0821 - mean_iou: 0.63 - ETA: 105s - loss: 0.0829 - mean_iou: 0.67 - ETA: 101s - loss: 0.0892 - mean_iou: 0.69 - ETA: 97s - loss: 0.0864 - mean_iou: 0.7142 - ETA: 93s - loss: 0.0838 - mean_iou: 0.727 - ETA: 89s - loss: 0.0875 - mean_iou: 0.737 - ETA: 86s - loss: 0.0878 - mean_iou: 0.745 - ETA: 82s - loss: 0.0858 - mean_iou: 0.752 - ETA: 78s - loss: 0.0849 - mean_iou: 0.759 - ETA: 75s - loss: 0.0889 - mean_iou: 0.764 - ETA: 71s - loss: 0.0892 - mean_iou: 0.768 - ETA: 67s - loss: 0.0898 - mean_iou: 0.772 - ETA: 63s - loss: 0.0903 - mean_iou: 0.776 - ETA: 60s - loss: 0.0899 - mean_iou: 0.779 - ETA: 57s - loss: 0.0887 - mean_iou: 0.782 - ETA: 53s - loss: 0.0894 - mean_iou: 0.784 - ETA: 50s - loss: 0.0901 - mean_iou: 0.786 - ETA: 46s - loss: 0.0897 - mean_iou: 0.788 - ETA: 43s - loss: 0.0896 - mean_iou: 0.790 - ETA: 39s - loss: 0.0891 - mean_iou: 0.792 - ETA: 36s - loss: 0.0884 - mean_iou: 0.793 - ETA: 32s - loss: 0.0891 - mean_iou: 0.795 - ETA: 28s - loss: 0.0892 - mean_iou: 0.796 - ETA: 25s - loss: 0.0898 - mean_iou: 0.797 - ETA: 21s - loss: 0.0899 - mean_iou: 0.798 - ETA: 17s - loss: 0.0899 - mean_iou: 0.799 - ETA: 13s - loss: 0.0895 - mean_iou: 0.800 - ETA: 9s - loss: 0.0889 - mean_iou: 0.801 - ETA: 5s - loss: 0.0886 - mean_iou: 0.80 - ETA: 1s - loss: 0.0885 - mean_iou: 0.8034Epoch 00000: val_loss improved from inf to 0.08196, saving model to model-dsbowl2018-ep-100.h5\n",
      "536/536 [==============================] - 146s - loss: 0.0886 - mean_iou: 0.8038 - val_loss: 0.0820 - val_mean_iou: 0.8332\n",
      "Epoch 2/100\n",
      "528/536 [============================>.] - ETA: 118s - loss: 0.1369 - mean_iou: 0.83 - ETA: 113s - loss: 0.1123 - mean_iou: 0.83 - ETA: 109s - loss: 0.0912 - mean_iou: 0.83 - ETA: 106s - loss: 0.0882 - mean_iou: 0.83 - ETA: 103s - loss: 0.0899 - mean_iou: 0.83 - ETA: 99s - loss: 0.0895 - mean_iou: 0.8336 - ETA: 96s - loss: 0.0931 - mean_iou: 0.833 - ETA: 92s - loss: 0.0944 - mean_iou: 0.833 - ETA: 88s - loss: 0.0901 - mean_iou: 0.833 - ETA: 85s - loss: 0.0921 - mean_iou: 0.833 - ETA: 81s - loss: 0.0902 - mean_iou: 0.833 - ETA: 78s - loss: 0.0914 - mean_iou: 0.833 - ETA: 75s - loss: 0.0906 - mean_iou: 0.833 - ETA: 73s - loss: 0.0890 - mean_iou: 0.833 - ETA: 70s - loss: 0.0884 - mean_iou: 0.833 - ETA: 66s - loss: 0.0874 - mean_iou: 0.833 - ETA: 62s - loss: 0.0873 - mean_iou: 0.834 - ETA: 60s - loss: 0.0860 - mean_iou: 0.834 - ETA: 58s - loss: 0.0848 - mean_iou: 0.834 - ETA: 56s - loss: 0.0845 - mean_iou: 0.834 - ETA: 53s - loss: 0.0861 - mean_iou: 0.834 - ETA: 49s - loss: 0.0857 - mean_iou: 0.834 - ETA: 45s - loss: 0.0850 - mean_iou: 0.834 - ETA: 41s - loss: 0.0860 - mean_iou: 0.834 - ETA: 36s - loss: 0.0858 - mean_iou: 0.834 - ETA: 32s - loss: 0.0873 - mean_iou: 0.834 - ETA: 27s - loss: 0.0873 - mean_iou: 0.834 - ETA: 23s - loss: 0.0874 - mean_iou: 0.834 - ETA: 19s - loss: 0.0860 - mean_iou: 0.834 - ETA: 14s - loss: 0.0858 - mean_iou: 0.834 - ETA: 10s - loss: 0.0855 - mean_iou: 0.834 - ETA: 6s - loss: 0.0854 - mean_iou: 0.834 - ETA: 2s - loss: 0.0865 - mean_iou: 0.8346Epoch 00001: val_loss improved from 0.08196 to 0.07789, saving model to model-dsbowl2018-ep-100.h5\n",
      "536/536 [==============================] - 151s - loss: 0.0866 - mean_iou: 0.8346 - val_loss: 0.0779 - val_mean_iou: 0.8344\n",
      "Epoch 3/100\n",
      "528/536 [============================>.] - ETA: 117s - loss: 0.0967 - mean_iou: 0.83 - ETA: 118s - loss: 0.0898 - mean_iou: 0.83 - ETA: 113s - loss: 0.0822 - mean_iou: 0.83 - ETA: 110s - loss: 0.0791 - mean_iou: 0.83 - ETA: 106s - loss: 0.0786 - mean_iou: 0.83 - ETA: 102s - loss: 0.0800 - mean_iou: 0.83 - ETA: 98s - loss: 0.0855 - mean_iou: 0.8345 - ETA: 94s - loss: 0.0853 - mean_iou: 0.834 - ETA: 90s - loss: 0.0875 - mean_iou: 0.834 - ETA: 87s - loss: 0.0889 - mean_iou: 0.834 - ETA: 83s - loss: 0.0883 - mean_iou: 0.834 - ETA: 79s - loss: 0.0880 - mean_iou: 0.834 - ETA: 75s - loss: 0.0894 - mean_iou: 0.834 - ETA: 72s - loss: 0.0886 - mean_iou: 0.834 - ETA: 68s - loss: 0.0885 - mean_iou: 0.834 - ETA: 64s - loss: 0.0894 - mean_iou: 0.834 - ETA: 60s - loss: 0.0879 - mean_iou: 0.834 - ETA: 57s - loss: 0.0864 - mean_iou: 0.834 - ETA: 53s - loss: 0.0861 - mean_iou: 0.834 - ETA: 49s - loss: 0.0870 - mean_iou: 0.834 - ETA: 46s - loss: 0.0857 - mean_iou: 0.834 - ETA: 42s - loss: 0.0845 - mean_iou: 0.834 - ETA: 38s - loss: 0.0855 - mean_iou: 0.834 - ETA: 35s - loss: 0.0844 - mean_iou: 0.834 - ETA: 31s - loss: 0.0854 - mean_iou: 0.834 - ETA: 27s - loss: 0.0850 - mean_iou: 0.834 - ETA: 24s - loss: 0.0851 - mean_iou: 0.834 - ETA: 20s - loss: 0.0860 - mean_iou: 0.834 - ETA: 16s - loss: 0.0879 - mean_iou: 0.834 - ETA: 12s - loss: 0.0874 - mean_iou: 0.834 - ETA: 9s - loss: 0.0891 - mean_iou: 0.834 - ETA: 5s - loss: 0.0887 - mean_iou: 0.83 - ETA: 1s - loss: 0.0888 - mean_iou: 0.8341Epoch 00002: val_loss did not improve\n",
      "536/536 [==============================] - 135s - loss: 0.0885 - mean_iou: 0.8341 - val_loss: 0.0824 - val_mean_iou: 0.8342\n",
      "Epoch 4/100\n",
      "528/536 [============================>.] - ETA: 115s - loss: 0.0613 - mean_iou: 0.83 - ETA: 112s - loss: 0.0650 - mean_iou: 0.83 - ETA: 109s - loss: 0.0842 - mean_iou: 0.83 - ETA: 106s - loss: 0.0837 - mean_iou: 0.83 - ETA: 102s - loss: 0.0795 - mean_iou: 0.83 - ETA: 99s - loss: 0.0797 - mean_iou: 0.8337 - ETA: 96s - loss: 0.0848 - mean_iou: 0.833 - ETA: 92s - loss: 0.0837 - mean_iou: 0.833 - ETA: 88s - loss: 0.0829 - mean_iou: 0.833 - ETA: 85s - loss: 0.0818 - mean_iou: 0.833 - ETA: 81s - loss: 0.0821 - mean_iou: 0.833 - ETA: 78s - loss: 0.0841 - mean_iou: 0.833 - ETA: 74s - loss: 0.0849 - mean_iou: 0.833 - ETA: 70s - loss: 0.0830 - mean_iou: 0.833 - ETA: 67s - loss: 0.0825 - mean_iou: 0.833 - ETA: 63s - loss: 0.0808 - mean_iou: 0.833 - ETA: 59s - loss: 0.0803 - mean_iou: 0.833 - ETA: 56s - loss: 0.0821 - mean_iou: 0.833 - ETA: 52s - loss: 0.0830 - mean_iou: 0.833 - ETA: 49s - loss: 0.0816 - mean_iou: 0.833 - ETA: 45s - loss: 0.0825 - mean_iou: 0.833 - ETA: 41s - loss: 0.0824 - mean_iou: 0.833 - ETA: 38s - loss: 0.0834 - mean_iou: 0.833 - ETA: 34s - loss: 0.0825 - mean_iou: 0.833 - ETA: 30s - loss: 0.0817 - mean_iou: 0.833 - ETA: 27s - loss: 0.0816 - mean_iou: 0.833 - ETA: 24s - loss: 0.0821 - mean_iou: 0.833 - ETA: 20s - loss: 0.0826 - mean_iou: 0.833 - ETA: 16s - loss: 0.0840 - mean_iou: 0.833 - ETA: 13s - loss: 0.0846 - mean_iou: 0.833 - ETA: 9s - loss: 0.0842 - mean_iou: 0.833 - ETA: 5s - loss: 0.0848 - mean_iou: 0.83 - ETA: 1s - loss: 0.0857 - mean_iou: 0.8331Epoch 00003: val_loss improved from 0.07789 to 0.07668, saving model to model-dsbowl2018-ep-100.h5\n",
      "536/536 [==============================] - 140s - loss: 0.0856 - mean_iou: 0.8331 - val_loss: 0.0767 - val_mean_iou: 0.8339\n",
      "Epoch 5/100\n",
      "528/536 [============================>.] - ETA: 132s - loss: 0.1091 - mean_iou: 0.83 - ETA: 124s - loss: 0.0920 - mean_iou: 0.83 - ETA: 119s - loss: 0.0897 - mean_iou: 0.83 - ETA: 114s - loss: 0.0894 - mean_iou: 0.83 - ETA: 109s - loss: 0.0903 - mean_iou: 0.83 - ETA: 104s - loss: 0.0895 - mean_iou: 0.83 - ETA: 100s - loss: 0.0908 - mean_iou: 0.83 - ETA: 96s - loss: 0.0931 - mean_iou: 0.8343 - ETA: 92s - loss: 0.0889 - mean_iou: 0.834 - ETA: 88s - loss: 0.0881 - mean_iou: 0.834 - ETA: 84s - loss: 0.0910 - mean_iou: 0.834 - ETA: 80s - loss: 0.0880 - mean_iou: 0.834 - ETA: 76s - loss: 0.0854 - mean_iou: 0.834 - ETA: 72s - loss: 0.0825 - mean_iou: 0.834 - ETA: 69s - loss: 0.0819 - mean_iou: 0.834 - ETA: 65s - loss: 0.0811 - mean_iou: 0.834 - ETA: 61s - loss: 0.0827 - mean_iou: 0.834 - ETA: 57s - loss: 0.0828 - mean_iou: 0.834 - ETA: 53s - loss: 0.0836 - mean_iou: 0.834 - ETA: 50s - loss: 0.0834 - mean_iou: 0.834 - ETA: 46s - loss: 0.0839 - mean_iou: 0.834 - ETA: 42s - loss: 0.0839 - mean_iou: 0.834 - ETA: 39s - loss: 0.0848 - mean_iou: 0.834 - ETA: 35s - loss: 0.0848 - mean_iou: 0.834 - ETA: 31s - loss: 0.0863 - mean_iou: 0.834 - ETA: 27s - loss: 0.0860 - mean_iou: 0.834 - ETA: 24s - loss: 0.0861 - mean_iou: 0.834 - ETA: 20s - loss: 0.0853 - mean_iou: 0.835 - ETA: 16s - loss: 0.0871 - mean_iou: 0.835 - ETA: 12s - loss: 0.0873 - mean_iou: 0.835 - ETA: 9s - loss: 0.0868 - mean_iou: 0.835 - ETA: 5s - loss: 0.0868 - mean_iou: 0.83 - ETA: 1s - loss: 0.0855 - mean_iou: 0.8350Epoch 00004: val_loss did not improve\n",
      "536/536 [==============================] - 135s - loss: 0.0853 - mean_iou: 0.8350 - val_loss: 0.0791 - val_mean_iou: 0.8347\n",
      "Epoch 6/100\n",
      "528/536 [============================>.] - ETA: 118s - loss: 0.0958 - mean_iou: 0.83 - ETA: 114s - loss: 0.0868 - mean_iou: 0.83 - ETA: 112s - loss: 0.0829 - mean_iou: 0.83 - ETA: 107s - loss: 0.0882 - mean_iou: 0.83 - ETA: 104s - loss: 0.0816 - mean_iou: 0.83 - ETA: 101s - loss: 0.0827 - mean_iou: 0.83 - ETA: 97s - loss: 0.0830 - mean_iou: 0.8342 - ETA: 93s - loss: 0.0829 - mean_iou: 0.834 - ETA: 90s - loss: 0.0848 - mean_iou: 0.834 - ETA: 87s - loss: 0.0837 - mean_iou: 0.834 - ETA: 84s - loss: 0.0822 - mean_iou: 0.834 - ETA: 80s - loss: 0.0887 - mean_iou: 0.834 - ETA: 76s - loss: 0.0928 - mean_iou: 0.834 - ETA: 72s - loss: 0.0897 - mean_iou: 0.834 - ETA: 69s - loss: 0.0886 - mean_iou: 0.834 - ETA: 65s - loss: 0.0870 - mean_iou: 0.834 - ETA: 61s - loss: 0.0887 - mean_iou: 0.834 - ETA: 57s - loss: 0.0873 - mean_iou: 0.834 - ETA: 53s - loss: 0.0889 - mean_iou: 0.834 - ETA: 50s - loss: 0.0876 - mean_iou: 0.834 - ETA: 46s - loss: 0.0864 - mean_iou: 0.834 - ETA: 42s - loss: 0.0861 - mean_iou: 0.834 - ETA: 38s - loss: 0.0859 - mean_iou: 0.834 - ETA: 35s - loss: 0.0844 - mean_iou: 0.834 - ETA: 31s - loss: 0.0848 - mean_iou: 0.834 - ETA: 27s - loss: 0.0832 - mean_iou: 0.834 - ETA: 24s - loss: 0.0828 - mean_iou: 0.834 - ETA: 20s - loss: 0.0830 - mean_iou: 0.834 - ETA: 16s - loss: 0.0822 - mean_iou: 0.834 - ETA: 12s - loss: 0.0832 - mean_iou: 0.834 - ETA: 9s - loss: 0.0831 - mean_iou: 0.834 - ETA: 5s - loss: 0.0827 - mean_iou: 0.83 - ETA: 1s - loss: 0.0834 - mean_iou: 0.8347Epoch 00005: val_loss improved from 0.07668 to 0.07430, saving model to model-dsbowl2018-ep-100.h5\n",
      "536/536 [==============================] - 136s - loss: 0.0835 - mean_iou: 0.8347 - val_loss: 0.0743 - val_mean_iou: 0.8352\n",
      "Epoch 7/100\n",
      "528/536 [============================>.] - ETA: 123s - loss: 0.0941 - mean_iou: 0.83 - ETA: 121s - loss: 0.0825 - mean_iou: 0.83 - ETA: 116s - loss: 0.0811 - mean_iou: 0.83 - ETA: 113s - loss: 0.0759 - mean_iou: 0.83 - ETA: 109s - loss: 0.0748 - mean_iou: 0.83 - ETA: 105s - loss: 0.0821 - mean_iou: 0.83 - ETA: 102s - loss: 0.0819 - mean_iou: 0.83 - ETA: 98s - loss: 0.0825 - mean_iou: 0.8355 - ETA: 94s - loss: 0.0826 - mean_iou: 0.835 - ETA: 90s - loss: 0.0798 - mean_iou: 0.835 - ETA: 86s - loss: 0.0786 - mean_iou: 0.835 - ETA: 82s - loss: 0.0794 - mean_iou: 0.835 - ETA: 78s - loss: 0.0778 - mean_iou: 0.835 - ETA: 74s - loss: 0.0787 - mean_iou: 0.835 - ETA: 70s - loss: 0.0775 - mean_iou: 0.835 - ETA: 66s - loss: 0.0800 - mean_iou: 0.835 - ETA: 62s - loss: 0.0815 - mean_iou: 0.835 - ETA: 59s - loss: 0.0815 - mean_iou: 0.835 - ETA: 55s - loss: 0.0822 - mean_iou: 0.835 - ETA: 51s - loss: 0.0827 - mean_iou: 0.835 - ETA: 47s - loss: 0.0824 - mean_iou: 0.835 - ETA: 43s - loss: 0.0810 - mean_iou: 0.835 - ETA: 39s - loss: 0.0808 - mean_iou: 0.835 - ETA: 36s - loss: 0.0817 - mean_iou: 0.835 - ETA: 32s - loss: 0.0823 - mean_iou: 0.835 - ETA: 28s - loss: 0.0827 - mean_iou: 0.835 - ETA: 24s - loss: 0.0820 - mean_iou: 0.835 - ETA: 20s - loss: 0.0811 - mean_iou: 0.835 - ETA: 17s - loss: 0.0809 - mean_iou: 0.835 - ETA: 13s - loss: 0.0805 - mean_iou: 0.835 - ETA: 9s - loss: 0.0805 - mean_iou: 0.835 - ETA: 5s - loss: 0.0799 - mean_iou: 0.83 - ETA: 1s - loss: 0.0800 - mean_iou: 0.8358Epoch 00006: val_loss improved from 0.07430 to 0.07212, saving model to model-dsbowl2018-ep-100.h5\n",
      "536/536 [==============================] - 138s - loss: 0.0806 - mean_iou: 0.8359 - val_loss: 0.0721 - val_mean_iou: 0.8364\n",
      "Epoch 8/100\n",
      "528/536 [============================>.] - ETA: 117s - loss: 0.0801 - mean_iou: 0.83 - ETA: 113s - loss: 0.0603 - mean_iou: 0.83 - ETA: 110s - loss: 0.0714 - mean_iou: 0.83 - ETA: 107s - loss: 0.0736 - mean_iou: 0.83 - ETA: 103s - loss: 0.0724 - mean_iou: 0.83 - ETA: 99s - loss: 0.0745 - mean_iou: 0.8369 - ETA: 96s - loss: 0.0758 - mean_iou: 0.836 - ETA: 93s - loss: 0.0734 - mean_iou: 0.837 - ETA: 89s - loss: 0.0753 - mean_iou: 0.837 - ETA: 86s - loss: 0.0760 - mean_iou: 0.837 - ETA: 82s - loss: 0.0773 - mean_iou: 0.837 - ETA: 78s - loss: 0.0770 - mean_iou: 0.837 - ETA: 74s - loss: 0.0771 - mean_iou: 0.837 - ETA: 71s - loss: 0.0779 - mean_iou: 0.837 - ETA: 67s - loss: 0.0788 - mean_iou: 0.837 - ETA: 63s - loss: 0.0803 - mean_iou: 0.837 - ETA: 60s - loss: 0.0811 - mean_iou: 0.837 - ETA: 56s - loss: 0.0814 - mean_iou: 0.837 - ETA: 52s - loss: 0.0810 - mean_iou: 0.837 - ETA: 49s - loss: 0.0802 - mean_iou: 0.837 - ETA: 45s - loss: 0.0798 - mean_iou: 0.837 - ETA: 42s - loss: 0.0799 - mean_iou: 0.837 - ETA: 38s - loss: 0.0801 - mean_iou: 0.837 - ETA: 34s - loss: 0.0802 - mean_iou: 0.837 - ETA: 31s - loss: 0.0806 - mean_iou: 0.837 - ETA: 27s - loss: 0.0796 - mean_iou: 0.837 - ETA: 23s - loss: 0.0800 - mean_iou: 0.837 - ETA: 20s - loss: 0.0791 - mean_iou: 0.837 - ETA: 16s - loss: 0.0784 - mean_iou: 0.837 - ETA: 12s - loss: 0.0794 - mean_iou: 0.837 - ETA: 9s - loss: 0.0784 - mean_iou: 0.837 - ETA: 5s - loss: 0.0800 - mean_iou: 0.83 - ETA: 1s - loss: 0.0795 - mean_iou: 0.8372Epoch 00007: val_loss improved from 0.07212 to 0.07003, saving model to model-dsbowl2018-ep-100.h5\n",
      "536/536 [==============================] - 134s - loss: 0.0795 - mean_iou: 0.8372 - val_loss: 0.0700 - val_mean_iou: 0.8376\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528/536 [============================>.] - ETA: 116s - loss: 0.0822 - mean_iou: 0.83 - ETA: 113s - loss: 0.0760 - mean_iou: 0.83 - ETA: 110s - loss: 0.0841 - mean_iou: 0.83 - ETA: 107s - loss: 0.0802 - mean_iou: 0.83 - ETA: 104s - loss: 0.0812 - mean_iou: 0.83 - ETA: 100s - loss: 0.0814 - mean_iou: 0.83 - ETA: 96s - loss: 0.0782 - mean_iou: 0.8378 - ETA: 93s - loss: 0.0770 - mean_iou: 0.837 - ETA: 89s - loss: 0.0785 - mean_iou: 0.837 - ETA: 85s - loss: 0.0769 - mean_iou: 0.837 - ETA: 82s - loss: 0.0756 - mean_iou: 0.837 - ETA: 78s - loss: 0.0761 - mean_iou: 0.837 - ETA: 75s - loss: 0.0757 - mean_iou: 0.837 - ETA: 71s - loss: 0.0757 - mean_iou: 0.837 - ETA: 67s - loss: 0.0757 - mean_iou: 0.837 - ETA: 64s - loss: 0.0754 - mean_iou: 0.837 - ETA: 60s - loss: 0.0752 - mean_iou: 0.837 - ETA: 56s - loss: 0.0753 - mean_iou: 0.837 - ETA: 53s - loss: 0.0743 - mean_iou: 0.837 - ETA: 49s - loss: 0.0749 - mean_iou: 0.837 - ETA: 46s - loss: 0.0754 - mean_iou: 0.837 - ETA: 42s - loss: 0.0750 - mean_iou: 0.837 - ETA: 38s - loss: 0.0751 - mean_iou: 0.837 - ETA: 35s - loss: 0.0749 - mean_iou: 0.837 - ETA: 31s - loss: 0.0744 - mean_iou: 0.838 - ETA: 27s - loss: 0.0749 - mean_iou: 0.838 - ETA: 24s - loss: 0.0755 - mean_iou: 0.838 - ETA: 20s - loss: 0.0761 - mean_iou: 0.838 - ETA: 16s - loss: 0.0774 - mean_iou: 0.838 - ETA: 12s - loss: 0.0773 - mean_iou: 0.838 - ETA: 9s - loss: 0.0784 - mean_iou: 0.838 - ETA: 5s - loss: 0.0779 - mean_iou: 0.83 - ETA: 1s - loss: 0.0774 - mean_iou: 0.8380Epoch 00008: val_loss improved from 0.07003 to 0.06822, saving model to model-dsbowl2018-ep-100.h5\n",
      "536/536 [==============================] - 136s - loss: 0.0776 - mean_iou: 0.8381 - val_loss: 0.0682 - val_mean_iou: 0.8387\n",
      "Epoch 10/100\n",
      "528/536 [============================>.] - ETA: 122s - loss: 0.0673 - mean_iou: 0.83 - ETA: 117s - loss: 0.0760 - mean_iou: 0.83 - ETA: 112s - loss: 0.0814 - mean_iou: 0.83 - ETA: 108s - loss: 0.0804 - mean_iou: 0.83 - ETA: 104s - loss: 0.0845 - mean_iou: 0.83 - ETA: 100s - loss: 0.0836 - mean_iou: 0.83 - ETA: 96s - loss: 0.0872 - mean_iou: 0.8386 - ETA: 93s - loss: 0.0856 - mean_iou: 0.838 - ETA: 89s - loss: 0.0863 - mean_iou: 0.838 - ETA: 85s - loss: 0.0821 - mean_iou: 0.838 - ETA: 81s - loss: 0.0802 - mean_iou: 0.838 - ETA: 78s - loss: 0.0777 - mean_iou: 0.838 - ETA: 74s - loss: 0.0768 - mean_iou: 0.838 - ETA: 71s - loss: 0.0767 - mean_iou: 0.838 - ETA: 67s - loss: 0.0762 - mean_iou: 0.838 - ETA: 63s - loss: 0.0748 - mean_iou: 0.838 - ETA: 60s - loss: 0.0748 - mean_iou: 0.838 - ETA: 56s - loss: 0.0749 - mean_iou: 0.838 - ETA: 53s - loss: 0.0757 - mean_iou: 0.838 - ETA: 49s - loss: 0.0780 - mean_iou: 0.838 - ETA: 45s - loss: 0.0772 - mean_iou: 0.838 - ETA: 42s - loss: 0.0770 - mean_iou: 0.838 - ETA: 38s - loss: 0.0759 - mean_iou: 0.838 - ETA: 34s - loss: 0.0759 - mean_iou: 0.838 - ETA: 31s - loss: 0.0751 - mean_iou: 0.838 - ETA: 27s - loss: 0.0756 - mean_iou: 0.838 - ETA: 23s - loss: 0.0750 - mean_iou: 0.838 - ETA: 20s - loss: 0.0753 - mean_iou: 0.838 - ETA: 16s - loss: 0.0754 - mean_iou: 0.838 - ETA: 12s - loss: 0.0759 - mean_iou: 0.838 - ETA: 9s - loss: 0.0764 - mean_iou: 0.838 - ETA: 5s - loss: 0.0757 - mean_iou: 0.83 - ETA: 1s - loss: 0.0770 - mean_iou: 0.8389Epoch 00009: val_loss improved from 0.06822 to 0.06749, saving model to model-dsbowl2018-ep-100.h5\n",
      "536/536 [==============================] - 134s - loss: 0.0770 - mean_iou: 0.8389 - val_loss: 0.0675 - val_mean_iou: 0.8395\n",
      "Epoch 11/100\n",
      "528/536 [============================>.] - ETA: 115s - loss: 0.0724 - mean_iou: 0.83 - ETA: 112s - loss: 0.0593 - mean_iou: 0.83 - ETA: 109s - loss: 0.0671 - mean_iou: 0.83 - ETA: 106s - loss: 0.0676 - mean_iou: 0.83 - ETA: 102s - loss: 0.0647 - mean_iou: 0.84 - ETA: 99s - loss: 0.0659 - mean_iou: 0.8400 - ETA: 95s - loss: 0.0645 - mean_iou: 0.840 - ETA: 92s - loss: 0.0678 - mean_iou: 0.840 - ETA: 88s - loss: 0.0687 - mean_iou: 0.840 - ETA: 85s - loss: 0.0716 - mean_iou: 0.840 - ETA: 81s - loss: 0.0689 - mean_iou: 0.840 - ETA: 77s - loss: 0.0671 - mean_iou: 0.840 - ETA: 74s - loss: 0.0645 - mean_iou: 0.840 - ETA: 70s - loss: 0.0647 - mean_iou: 0.840 - ETA: 67s - loss: 0.0655 - mean_iou: 0.840 - ETA: 63s - loss: 0.0655 - mean_iou: 0.840 - ETA: 60s - loss: 0.0669 - mean_iou: 0.840 - ETA: 56s - loss: 0.0670 - mean_iou: 0.840 - ETA: 53s - loss: 0.0676 - mean_iou: 0.840 - ETA: 49s - loss: 0.0682 - mean_iou: 0.840 - ETA: 45s - loss: 0.0699 - mean_iou: 0.840 - ETA: 42s - loss: 0.0694 - mean_iou: 0.840 - ETA: 38s - loss: 0.0707 - mean_iou: 0.840 - ETA: 34s - loss: 0.0710 - mean_iou: 0.840 - ETA: 31s - loss: 0.0713 - mean_iou: 0.840 - ETA: 27s - loss: 0.0714 - mean_iou: 0.840 - ETA: 23s - loss: 0.0709 - mean_iou: 0.840 - ETA: 20s - loss: 0.0730 - mean_iou: 0.840 - ETA: 16s - loss: 0.0728 - mean_iou: 0.840 - ETA: 12s - loss: 0.0728 - mean_iou: 0.840 - ETA: 9s - loss: 0.0737 - mean_iou: 0.840 - ETA: 5s - loss: 0.0735 - mean_iou: 0.84 - ETA: 1s - loss: 0.0744 - mean_iou: 0.8405Epoch 00010: val_loss did not improve\n",
      "536/536 [==============================] - 134s - loss: 0.0753 - mean_iou: 0.8405 - val_loss: 0.0737 - val_mean_iou: 0.8407\n",
      "Epoch 12/100\n",
      "528/536 [============================>.] - ETA: 117s - loss: 0.0655 - mean_iou: 0.84 - ETA: 113s - loss: 0.0668 - mean_iou: 0.84 - ETA: 110s - loss: 0.0735 - mean_iou: 0.84 - ETA: 106s - loss: 0.0689 - mean_iou: 0.84 - ETA: 105s - loss: 0.0746 - mean_iou: 0.84 - ETA: 104s - loss: 0.0684 - mean_iou: 0.84 - ETA: 103s - loss: 0.0692 - mean_iou: 0.84 - ETA: 100s - loss: 0.0717 - mean_iou: 0.84 - ETA: 97s - loss: 0.0721 - mean_iou: 0.8409 - ETA: 93s - loss: 0.0716 - mean_iou: 0.840 - ETA: 90s - loss: 0.0726 - mean_iou: 0.840 - ETA: 86s - loss: 0.0710 - mean_iou: 0.840 - ETA: 83s - loss: 0.0727 - mean_iou: 0.840 - ETA: 79s - loss: 0.0712 - mean_iou: 0.840 - ETA: 75s - loss: 0.0713 - mean_iou: 0.840 - ETA: 70s - loss: 0.0715 - mean_iou: 0.840 - ETA: 66s - loss: 0.0734 - mean_iou: 0.840 - ETA: 62s - loss: 0.0738 - mean_iou: 0.840 - ETA: 57s - loss: 0.0737 - mean_iou: 0.841 - ETA: 53s - loss: 0.0736 - mean_iou: 0.841 - ETA: 49s - loss: 0.0739 - mean_iou: 0.841 - ETA: 45s - loss: 0.0751 - mean_iou: 0.841 - ETA: 41s - loss: 0.0761 - mean_iou: 0.841 - ETA: 37s - loss: 0.0758 - mean_iou: 0.841 - ETA: 33s - loss: 0.0783 - mean_iou: 0.841 - ETA: 29s - loss: 0.0778 - mean_iou: 0.841 - ETA: 25s - loss: 0.0777 - mean_iou: 0.841 - ETA: 21s - loss: 0.0773 - mean_iou: 0.841 - ETA: 17s - loss: 0.0774 - mean_iou: 0.841 - ETA: 13s - loss: 0.0775 - mean_iou: 0.841 - ETA: 9s - loss: 0.0767 - mean_iou: 0.841 - ETA: 5s - loss: 0.0764 - mean_iou: 0.84 - ETA: 1s - loss: 0.0762 - mean_iou: 0.8411Epoch 00011: val_loss did not improve\n",
      "536/536 [==============================] - 140s - loss: 0.0766 - mean_iou: 0.8411 - val_loss: 0.0722 - val_mean_iou: 0.8413\n",
      "Epoch 13/100\n",
      "528/536 [============================>.] - ETA: 123s - loss: 0.0742 - mean_iou: 0.84 - ETA: 118s - loss: 0.0887 - mean_iou: 0.84 - ETA: 114s - loss: 0.0942 - mean_iou: 0.84 - ETA: 111s - loss: 0.0826 - mean_iou: 0.84 - ETA: 107s - loss: 0.0795 - mean_iou: 0.84 - ETA: 102s - loss: 0.0757 - mean_iou: 0.84 - ETA: 99s - loss: 0.0757 - mean_iou: 0.8413 - ETA: 95s - loss: 0.0770 - mean_iou: 0.841 - ETA: 92s - loss: 0.0767 - mean_iou: 0.841 - ETA: 89s - loss: 0.0739 - mean_iou: 0.841 - ETA: 86s - loss: 0.0730 - mean_iou: 0.841 - ETA: 82s - loss: 0.0717 - mean_iou: 0.841 - ETA: 78s - loss: 0.0737 - mean_iou: 0.841 - ETA: 74s - loss: 0.0739 - mean_iou: 0.841 - ETA: 70s - loss: 0.0724 - mean_iou: 0.841 - ETA: 66s - loss: 0.0722 - mean_iou: 0.841 - ETA: 62s - loss: 0.0737 - mean_iou: 0.841 - ETA: 58s - loss: 0.0730 - mean_iou: 0.841 - ETA: 54s - loss: 0.0729 - mean_iou: 0.841 - ETA: 50s - loss: 0.0750 - mean_iou: 0.841 - ETA: 46s - loss: 0.0764 - mean_iou: 0.841 - ETA: 43s - loss: 0.0769 - mean_iou: 0.841 - ETA: 39s - loss: 0.0770 - mean_iou: 0.841 - ETA: 35s - loss: 0.0770 - mean_iou: 0.841 - ETA: 31s - loss: 0.0773 - mean_iou: 0.841 - ETA: 28s - loss: 0.0760 - mean_iou: 0.841 - ETA: 24s - loss: 0.0774 - mean_iou: 0.841 - ETA: 20s - loss: 0.0770 - mean_iou: 0.841 - ETA: 16s - loss: 0.0771 - mean_iou: 0.841 - ETA: 13s - loss: 0.0767 - mean_iou: 0.841 - ETA: 9s - loss: 0.0769 - mean_iou: 0.841 - ETA: 5s - loss: 0.0766 - mean_iou: 0.84 - ETA: 1s - loss: 0.0753 - mean_iou: 0.8414Epoch 00012: val_loss improved from 0.06749 to 0.06602, saving model to model-dsbowl2018-ep-100.h5\n",
      "536/536 [==============================] - 137s - loss: 0.0748 - mean_iou: 0.8414 - val_loss: 0.0660 - val_mean_iou: 0.8419\n",
      "Epoch 14/100\n",
      "528/536 [============================>.] - ETA: 115s - loss: 0.0712 - mean_iou: 0.84 - ETA: 115s - loss: 0.0679 - mean_iou: 0.84 - ETA: 111s - loss: 0.0815 - mean_iou: 0.84 - ETA: 107s - loss: 0.0854 - mean_iou: 0.84 - ETA: 105s - loss: 0.0848 - mean_iou: 0.84 - ETA: 101s - loss: 0.0803 - mean_iou: 0.84 - ETA: 97s - loss: 0.0798 - mean_iou: 0.8421 - ETA: 95s - loss: 0.0758 - mean_iou: 0.842 - ETA: 91s - loss: 0.0754 - mean_iou: 0.842 - ETA: 87s - loss: 0.0768 - mean_iou: 0.842 - ETA: 83s - loss: 0.0745 - mean_iou: 0.842 - ETA: 80s - loss: 0.0767 - mean_iou: 0.842 - ETA: 77s - loss: 0.0740 - mean_iou: 0.842 - ETA: 74s - loss: 0.0741 - mean_iou: 0.842 - ETA: 71s - loss: 0.0727 - mean_iou: 0.842 - ETA: 67s - loss: 0.0720 - mean_iou: 0.842 - ETA: 63s - loss: 0.0726 - mean_iou: 0.842 - ETA: 59s - loss: 0.0735 - mean_iou: 0.842 - ETA: 55s - loss: 0.0730 - mean_iou: 0.842 - ETA: 51s - loss: 0.0736 - mean_iou: 0.842 - ETA: 47s - loss: 0.0741 - mean_iou: 0.842 - ETA: 44s - loss: 0.0748 - mean_iou: 0.842 - ETA: 40s - loss: 0.0764 - mean_iou: 0.842 - ETA: 36s - loss: 0.0754 - mean_iou: 0.842 - ETA: 32s - loss: 0.0748 - mean_iou: 0.842 - ETA: 28s - loss: 0.0748 - mean_iou: 0.842 - ETA: 24s - loss: 0.0739 - mean_iou: 0.842 - ETA: 20s - loss: 0.0734 - mean_iou: 0.842 - ETA: 17s - loss: 0.0741 - mean_iou: 0.842 - ETA: 13s - loss: 0.0731 - mean_iou: 0.842 - ETA: 9s - loss: 0.0737 - mean_iou: 0.842 - ETA: 5s - loss: 0.0740 - mean_iou: 0.84 - ETA: 1s - loss: 0.0738 - mean_iou: 0.8423Epoch 00013: val_loss did not improve\n",
      "536/536 [==============================] - 138s - loss: 0.0736 - mean_iou: 0.8423 - val_loss: 0.0684 - val_mean_iou: 0.8428\n",
      "Epoch 15/100\n",
      "528/536 [============================>.] - ETA: 122s - loss: 0.0802 - mean_iou: 0.84 - ETA: 117s - loss: 0.0694 - mean_iou: 0.84 - ETA: 112s - loss: 0.0795 - mean_iou: 0.84 - ETA: 108s - loss: 0.0814 - mean_iou: 0.84 - ETA: 104s - loss: 0.0728 - mean_iou: 0.84 - ETA: 100s - loss: 0.0705 - mean_iou: 0.84 - ETA: 97s - loss: 0.0713 - mean_iou: 0.8431 - ETA: 93s - loss: 0.0699 - mean_iou: 0.843 - ETA: 89s - loss: 0.0696 - mean_iou: 0.843 - ETA: 86s - loss: 0.0736 - mean_iou: 0.843 - ETA: 82s - loss: 0.0730 - mean_iou: 0.843 - ETA: 78s - loss: 0.0720 - mean_iou: 0.843 - ETA: 75s - loss: 0.0750 - mean_iou: 0.843 - ETA: 71s - loss: 0.0744 - mean_iou: 0.843 - ETA: 67s - loss: 0.0739 - mean_iou: 0.843 - ETA: 64s - loss: 0.0732 - mean_iou: 0.843 - ETA: 60s - loss: 0.0740 - mean_iou: 0.843 - ETA: 57s - loss: 0.0756 - mean_iou: 0.843 - ETA: 53s - loss: 0.0779 - mean_iou: 0.843 - ETA: 49s - loss: 0.0778 - mean_iou: 0.843 - ETA: 46s - loss: 0.0778 - mean_iou: 0.843 - ETA: 42s - loss: 0.0781 - mean_iou: 0.843 - ETA: 39s - loss: 0.0781 - mean_iou: 0.843 - ETA: 35s - loss: 0.0776 - mean_iou: 0.843 - ETA: 31s - loss: 0.0772 - mean_iou: 0.843 - ETA: 27s - loss: 0.0763 - mean_iou: 0.843 - ETA: 24s - loss: 0.0754 - mean_iou: 0.843 - ETA: 20s - loss: 0.0752 - mean_iou: 0.843 - ETA: 16s - loss: 0.0749 - mean_iou: 0.843 - ETA: 13s - loss: 0.0744 - mean_iou: 0.843 - ETA: 9s - loss: 0.0748 - mean_iou: 0.843 - ETA: 5s - loss: 0.0743 - mean_iou: 0.84 - ETA: 1s - loss: 0.0751 - mean_iou: 0.8432Epoch 00014: val_loss did not improve\n",
      "536/536 [==============================] - 137s - loss: 0.0747 - mean_iou: 0.8432 - val_loss: 0.0684 - val_mean_iou: 0.8436\n",
      "Epoch 16/100\n",
      "528/536 [============================>.] - ETA: 123s - loss: 0.0521 - mean_iou: 0.84 - ETA: 118s - loss: 0.0666 - mean_iou: 0.84 - ETA: 113s - loss: 0.0651 - mean_iou: 0.84 - ETA: 109s - loss: 0.0713 - mean_iou: 0.84 - ETA: 105s - loss: 0.0640 - mean_iou: 0.84 - ETA: 101s - loss: 0.0674 - mean_iou: 0.84 - ETA: 97s - loss: 0.0715 - mean_iou: 0.8438 - ETA: 93s - loss: 0.0712 - mean_iou: 0.843 - ETA: 90s - loss: 0.0696 - mean_iou: 0.843 - ETA: 86s - loss: 0.0690 - mean_iou: 0.843 - ETA: 82s - loss: 0.0700 - mean_iou: 0.843 - ETA: 79s - loss: 0.0715 - mean_iou: 0.843 - ETA: 75s - loss: 0.0705 - mean_iou: 0.843 - ETA: 71s - loss: 0.0718 - mean_iou: 0.843 - ETA: 68s - loss: 0.0758 - mean_iou: 0.843 - ETA: 64s - loss: 0.0745 - mean_iou: 0.843 - ETA: 60s - loss: 0.0731 - mean_iou: 0.843 - ETA: 57s - loss: 0.0738 - mean_iou: 0.843 - ETA: 53s - loss: 0.0729 - mean_iou: 0.843 - ETA: 49s - loss: 0.0715 - mean_iou: 0.843 - ETA: 45s - loss: 0.0721 - mean_iou: 0.843 - ETA: 42s - loss: 0.0731 - mean_iou: 0.843 - ETA: 38s - loss: 0.0737 - mean_iou: 0.843 - ETA: 34s - loss: 0.0735 - mean_iou: 0.843 - ETA: 31s - loss: 0.0730 - mean_iou: 0.843 - ETA: 27s - loss: 0.0728 - mean_iou: 0.843 - ETA: 23s - loss: 0.0722 - mean_iou: 0.843 - ETA: 20s - loss: 0.0727 - mean_iou: 0.843 - ETA: 16s - loss: 0.0727 - mean_iou: 0.843 - ETA: 12s - loss: 0.0735 - mean_iou: 0.844 - ETA: 9s - loss: 0.0749 - mean_iou: 0.844 - ETA: 5s - loss: 0.0740 - mean_iou: 0.84 - ETA: 1s - loss: 0.0738 - mean_iou: 0.8440Epoch 00015: val_loss did not improve\n",
      "536/536 [==============================] - 134s - loss: 0.0740 - mean_iou: 0.8440 - val_loss: 0.0793 - val_mean_iou: 0.8441\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528/536 [============================>.] - ETA: 119s - loss: 0.0811 - mean_iou: 0.84 - ETA: 115s - loss: 0.0700 - mean_iou: 0.84 - ETA: 111s - loss: 0.0691 - mean_iou: 0.84 - ETA: 109s - loss: 0.0690 - mean_iou: 0.84 - ETA: 105s - loss: 0.0687 - mean_iou: 0.84 - ETA: 101s - loss: 0.0655 - mean_iou: 0.84 - ETA: 97s - loss: 0.0669 - mean_iou: 0.8439 - ETA: 93s - loss: 0.0750 - mean_iou: 0.843 - ETA: 90s - loss: 0.0721 - mean_iou: 0.843 - ETA: 86s - loss: 0.0728 - mean_iou: 0.843 - ETA: 83s - loss: 0.0728 - mean_iou: 0.843 - ETA: 79s - loss: 0.0720 - mean_iou: 0.843 - ETA: 75s - loss: 0.0716 - mean_iou: 0.843 - ETA: 71s - loss: 0.0718 - mean_iou: 0.843 - ETA: 68s - loss: 0.0712 - mean_iou: 0.843 - ETA: 64s - loss: 0.0747 - mean_iou: 0.844 - ETA: 60s - loss: 0.0736 - mean_iou: 0.844 - ETA: 57s - loss: 0.0771 - mean_iou: 0.844 - ETA: 53s - loss: 0.0768 - mean_iou: 0.844 - ETA: 49s - loss: 0.0767 - mean_iou: 0.844 - ETA: 46s - loss: 0.0762 - mean_iou: 0.844 - ETA: 42s - loss: 0.0771 - mean_iou: 0.844 - ETA: 38s - loss: 0.0768 - mean_iou: 0.844 - ETA: 35s - loss: 0.0771 - mean_iou: 0.844 - ETA: 31s - loss: 0.0779 - mean_iou: 0.844 - ETA: 27s - loss: 0.0774 - mean_iou: 0.844 - ETA: 24s - loss: 0.0773 - mean_iou: 0.844 - ETA: 20s - loss: 0.0766 - mean_iou: 0.844 - ETA: 16s - loss: 0.0760 - mean_iou: 0.844 - ETA: 13s - loss: 0.0757 - mean_iou: 0.844 - ETA: 9s - loss: 0.0752 - mean_iou: 0.844 - ETA: 5s - loss: 0.0744 - mean_iou: 0.84 - ETA: 1s - loss: 0.0761 - mean_iou: 0.8440Epoch 00016: val_loss did not improve\n",
      "536/536 [==============================] - 137s - loss: 0.0755 - mean_iou: 0.8440 - val_loss: 0.0688 - val_mean_iou: 0.8442\n",
      "Epoch 18/100\n",
      "528/536 [============================>.] - ETA: 119s - loss: 0.0572 - mean_iou: 0.84 - ETA: 116s - loss: 0.0521 - mean_iou: 0.84 - ETA: 113s - loss: 0.0685 - mean_iou: 0.84 - ETA: 110s - loss: 0.0658 - mean_iou: 0.84 - ETA: 107s - loss: 0.0691 - mean_iou: 0.84 - ETA: 104s - loss: 0.0668 - mean_iou: 0.84 - ETA: 100s - loss: 0.0639 - mean_iou: 0.84 - ETA: 96s - loss: 0.0650 - mean_iou: 0.8445 - ETA: 92s - loss: 0.0671 - mean_iou: 0.844 - ETA: 89s - loss: 0.0671 - mean_iou: 0.844 - ETA: 85s - loss: 0.0672 - mean_iou: 0.844 - ETA: 81s - loss: 0.0687 - mean_iou: 0.844 - ETA: 78s - loss: 0.0664 - mean_iou: 0.844 - ETA: 75s - loss: 0.0669 - mean_iou: 0.844 - ETA: 71s - loss: 0.0695 - mean_iou: 0.844 - ETA: 68s - loss: 0.0699 - mean_iou: 0.844 - ETA: 64s - loss: 0.0688 - mean_iou: 0.844 - ETA: 60s - loss: 0.0690 - mean_iou: 0.844 - ETA: 56s - loss: 0.0702 - mean_iou: 0.844 - ETA: 53s - loss: 0.0728 - mean_iou: 0.844 - ETA: 49s - loss: 0.0722 - mean_iou: 0.844 - ETA: 45s - loss: 0.0730 - mean_iou: 0.844 - ETA: 41s - loss: 0.0728 - mean_iou: 0.844 - ETA: 37s - loss: 0.0732 - mean_iou: 0.844 - ETA: 33s - loss: 0.0728 - mean_iou: 0.844 - ETA: 29s - loss: 0.0721 - mean_iou: 0.844 - ETA: 25s - loss: 0.0723 - mean_iou: 0.844 - ETA: 21s - loss: 0.0729 - mean_iou: 0.844 - ETA: 17s - loss: 0.0727 - mean_iou: 0.844 - ETA: 13s - loss: 0.0718 - mean_iou: 0.844 - ETA: 9s - loss: 0.0712 - mean_iou: 0.844 - ETA: 5s - loss: 0.0709 - mean_iou: 0.84 - ETA: 1s - loss: 0.0709 - mean_iou: 0.8447Epoch 00017: val_loss did not improve\n",
      "536/536 [==============================] - 144s - loss: 0.0705 - mean_iou: 0.8447 - val_loss: 0.0681 - val_mean_iou: 0.8450\n",
      "Epoch 19/100\n",
      "528/536 [============================>.] - ETA: 122s - loss: 0.0456 - mean_iou: 0.84 - ETA: 118s - loss: 0.0504 - mean_iou: 0.84 - ETA: 116s - loss: 0.0466 - mean_iou: 0.84 - ETA: 111s - loss: 0.0513 - mean_iou: 0.84 - ETA: 106s - loss: 0.0561 - mean_iou: 0.84 - ETA: 102s - loss: 0.0583 - mean_iou: 0.84 - ETA: 99s - loss: 0.0656 - mean_iou: 0.8453 - ETA: 95s - loss: 0.0666 - mean_iou: 0.845 - ETA: 92s - loss: 0.0634 - mean_iou: 0.845 - ETA: 88s - loss: 0.0658 - mean_iou: 0.845 - ETA: 84s - loss: 0.0656 - mean_iou: 0.845 - ETA: 80s - loss: 0.0659 - mean_iou: 0.845 - ETA: 77s - loss: 0.0679 - mean_iou: 0.845 - ETA: 73s - loss: 0.0688 - mean_iou: 0.845 - ETA: 70s - loss: 0.0693 - mean_iou: 0.845 - ETA: 66s - loss: 0.0687 - mean_iou: 0.845 - ETA: 62s - loss: 0.0683 - mean_iou: 0.845 - ETA: 58s - loss: 0.0674 - mean_iou: 0.845 - ETA: 55s - loss: 0.0690 - mean_iou: 0.845 - ETA: 51s - loss: 0.0695 - mean_iou: 0.845 - ETA: 47s - loss: 0.0693 - mean_iou: 0.845 - ETA: 43s - loss: 0.0698 - mean_iou: 0.845 - ETA: 39s - loss: 0.0693 - mean_iou: 0.845 - ETA: 36s - loss: 0.0682 - mean_iou: 0.845 - ETA: 32s - loss: 0.0678 - mean_iou: 0.845 - ETA: 28s - loss: 0.0685 - mean_iou: 0.845 - ETA: 24s - loss: 0.0679 - mean_iou: 0.845 - ETA: 20s - loss: 0.0671 - mean_iou: 0.845 - ETA: 17s - loss: 0.0673 - mean_iou: 0.845 - ETA: 13s - loss: 0.0678 - mean_iou: 0.845 - ETA: 9s - loss: 0.0679 - mean_iou: 0.845 - ETA: 5s - loss: 0.0692 - mean_iou: 0.84 - ETA: 1s - loss: 0.0700 - mean_iou: 0.8454Epoch 00018: val_loss improved from 0.06602 to 0.06383, saving model to model-dsbowl2018-ep-100.h5\n",
      "536/536 [==============================] - 141s - loss: 0.0699 - mean_iou: 0.8455 - val_loss: 0.0638 - val_mean_iou: 0.8458\n",
      "Epoch 20/100\n",
      "528/536 [============================>.] - ETA: 123s - loss: 0.0727 - mean_iou: 0.84 - ETA: 118s - loss: 0.0745 - mean_iou: 0.84 - ETA: 114s - loss: 0.0890 - mean_iou: 0.84 - ETA: 110s - loss: 0.0845 - mean_iou: 0.84 - ETA: 106s - loss: 0.0813 - mean_iou: 0.84 - ETA: 102s - loss: 0.0787 - mean_iou: 0.84 - ETA: 99s - loss: 0.0791 - mean_iou: 0.8460 - ETA: 97s - loss: 0.0788 - mean_iou: 0.846 - ETA: 93s - loss: 0.0804 - mean_iou: 0.846 - ETA: 90s - loss: 0.0802 - mean_iou: 0.845 - ETA: 85s - loss: 0.0792 - mean_iou: 0.845 - ETA: 81s - loss: 0.0782 - mean_iou: 0.845 - ETA: 77s - loss: 0.0757 - mean_iou: 0.845 - ETA: 74s - loss: 0.0740 - mean_iou: 0.845 - ETA: 70s - loss: 0.0726 - mean_iou: 0.845 - ETA: 66s - loss: 0.0737 - mean_iou: 0.845 - ETA: 62s - loss: 0.0723 - mean_iou: 0.845 - ETA: 58s - loss: 0.0711 - mean_iou: 0.845 - ETA: 54s - loss: 0.0711 - mean_iou: 0.845 - ETA: 51s - loss: 0.0704 - mean_iou: 0.845 - ETA: 47s - loss: 0.0705 - mean_iou: 0.845 - ETA: 43s - loss: 0.0720 - mean_iou: 0.846 - ETA: 40s - loss: 0.0722 - mean_iou: 0.846 - ETA: 36s - loss: 0.0714 - mean_iou: 0.846 - ETA: 32s - loss: 0.0712 - mean_iou: 0.846 - ETA: 28s - loss: 0.0704 - mean_iou: 0.846 - ETA: 25s - loss: 0.0708 - mean_iou: 0.846 - ETA: 21s - loss: 0.0708 - mean_iou: 0.846 - ETA: 17s - loss: 0.0706 - mean_iou: 0.846 - ETA: 13s - loss: 0.0705 - mean_iou: 0.846 - ETA: 9s - loss: 0.0698 - mean_iou: 0.846 - ETA: 5s - loss: 0.0698 - mean_iou: 0.84 - ETA: 1s - loss: 0.0701 - mean_iou: 0.8461Epoch 00019: val_loss improved from 0.06383 to 0.06191, saving model to model-dsbowl2018-ep-100.h5\n",
      "536/536 [==============================] - 141s - loss: 0.0699 - mean_iou: 0.8461 - val_loss: 0.0619 - val_mean_iou: 0.8465\n",
      "Epoch 21/100\n",
      "528/536 [============================>.] - ETA: 124s - loss: 0.0606 - mean_iou: 0.84 - ETA: 118s - loss: 0.0571 - mean_iou: 0.84 - ETA: 114s - loss: 0.0539 - mean_iou: 0.84 - ETA: 110s - loss: 0.0519 - mean_iou: 0.84 - ETA: 106s - loss: 0.0542 - mean_iou: 0.84 - ETA: 102s - loss: 0.0545 - mean_iou: 0.84 - ETA: 98s - loss: 0.0551 - mean_iou: 0.8467 - ETA: 94s - loss: 0.0570 - mean_iou: 0.846 - ETA: 90s - loss: 0.0585 - mean_iou: 0.846 - ETA: 87s - loss: 0.0565 - mean_iou: 0.846 - ETA: 83s - loss: 0.0568 - mean_iou: 0.846 - ETA: 80s - loss: 0.0589 - mean_iou: 0.846 - ETA: 76s - loss: 0.0618 - mean_iou: 0.846 - ETA: 72s - loss: 0.0650 - mean_iou: 0.846 - ETA: 69s - loss: 0.0655 - mean_iou: 0.846 - ETA: 65s - loss: 0.0669 - mean_iou: 0.846 - ETA: 61s - loss: 0.0674 - mean_iou: 0.846 - ETA: 58s - loss: 0.0673 - mean_iou: 0.846 - ETA: 54s - loss: 0.0671 - mean_iou: 0.846 - ETA: 50s - loss: 0.0674 - mean_iou: 0.846 - ETA: 46s - loss: 0.0689 - mean_iou: 0.846 - ETA: 43s - loss: 0.0689 - mean_iou: 0.846 - ETA: 39s - loss: 0.0677 - mean_iou: 0.846 - ETA: 35s - loss: 0.0690 - mean_iou: 0.846 - ETA: 31s - loss: 0.0688 - mean_iou: 0.846 - ETA: 28s - loss: 0.0691 - mean_iou: 0.846 - ETA: 24s - loss: 0.0702 - mean_iou: 0.846 - ETA: 20s - loss: 0.0695 - mean_iou: 0.846 - ETA: 16s - loss: 0.0700 - mean_iou: 0.846 - ETA: 13s - loss: 0.0712 - mean_iou: 0.846 - ETA: 9s - loss: 0.0716 - mean_iou: 0.846 - ETA: 5s - loss: 0.0723 - mean_iou: 0.84 - ETA: 1s - loss: 0.0721 - mean_iou: 0.8469Epoch 00020: val_loss did not improve\n",
      "536/536 [==============================] - 136s - loss: 0.0714 - mean_iou: 0.8469 - val_loss: 0.0678 - val_mean_iou: 0.8471\n",
      "Epoch 22/100\n",
      "528/536 [============================>.] - ETA: 119s - loss: 0.0750 - mean_iou: 0.84 - ETA: 115s - loss: 0.0668 - mean_iou: 0.84 - ETA: 112s - loss: 0.0685 - mean_iou: 0.84 - ETA: 108s - loss: 0.0716 - mean_iou: 0.84 - ETA: 105s - loss: 0.0693 - mean_iou: 0.84 - ETA: 101s - loss: 0.0686 - mean_iou: 0.84 - ETA: 98s - loss: 0.0682 - mean_iou: 0.8471 - ETA: 94s - loss: 0.0690 - mean_iou: 0.847 - ETA: 91s - loss: 0.0717 - mean_iou: 0.847 - ETA: 87s - loss: 0.0686 - mean_iou: 0.847 - ETA: 83s - loss: 0.0709 - mean_iou: 0.847 - ETA: 79s - loss: 0.0706 - mean_iou: 0.847 - ETA: 76s - loss: 0.0692 - mean_iou: 0.847 - ETA: 72s - loss: 0.0686 - mean_iou: 0.847 - ETA: 69s - loss: 0.0673 - mean_iou: 0.847 - ETA: 65s - loss: 0.0669 - mean_iou: 0.847 - ETA: 61s - loss: 0.0692 - mean_iou: 0.847 - ETA: 58s - loss: 0.0693 - mean_iou: 0.847 - ETA: 54s - loss: 0.0684 - mean_iou: 0.847 - ETA: 50s - loss: 0.0679 - mean_iou: 0.847 - ETA: 46s - loss: 0.0678 - mean_iou: 0.847 - ETA: 42s - loss: 0.0671 - mean_iou: 0.847 - ETA: 39s - loss: 0.0673 - mean_iou: 0.847 - ETA: 35s - loss: 0.0685 - mean_iou: 0.847 - ETA: 31s - loss: 0.0692 - mean_iou: 0.847 - ETA: 28s - loss: 0.0693 - mean_iou: 0.847 - ETA: 24s - loss: 0.0691 - mean_iou: 0.847 - ETA: 20s - loss: 0.0693 - mean_iou: 0.847 - ETA: 16s - loss: 0.0694 - mean_iou: 0.847 - ETA: 13s - loss: 0.0686 - mean_iou: 0.847 - ETA: 9s - loss: 0.0692 - mean_iou: 0.847 - ETA: 5s - loss: 0.0705 - mean_iou: 0.84 - ETA: 1s - loss: 0.0700 - mean_iou: 0.8472Epoch 00021: val_loss did not improve\n",
      "536/536 [==============================] - 137s - loss: 0.0699 - mean_iou: 0.8472 - val_loss: 0.0690 - val_mean_iou: 0.8475\n",
      "Epoch 23/100\n",
      "528/536 [============================>.] - ETA: 123s - loss: 0.0555 - mean_iou: 0.84 - ETA: 118s - loss: 0.0646 - mean_iou: 0.84 - ETA: 115s - loss: 0.0601 - mean_iou: 0.84 - ETA: 111s - loss: 0.0628 - mean_iou: 0.84 - ETA: 107s - loss: 0.0600 - mean_iou: 0.84 - ETA: 103s - loss: 0.0626 - mean_iou: 0.84 - ETA: 99s - loss: 0.0614 - mean_iou: 0.8475 - ETA: 95s - loss: 0.0614 - mean_iou: 0.847 - ETA: 91s - loss: 0.0595 - mean_iou: 0.847 - ETA: 88s - loss: 0.0599 - mean_iou: 0.847 - ETA: 84s - loss: 0.0625 - mean_iou: 0.847 - ETA: 80s - loss: 0.0619 - mean_iou: 0.847 - ETA: 77s - loss: 0.0624 - mean_iou: 0.847 - ETA: 73s - loss: 0.0634 - mean_iou: 0.847 - ETA: 69s - loss: 0.0653 - mean_iou: 0.847 - ETA: 65s - loss: 0.0650 - mean_iou: 0.847 - ETA: 61s - loss: 0.0659 - mean_iou: 0.847 - ETA: 57s - loss: 0.0662 - mean_iou: 0.847 - ETA: 54s - loss: 0.0656 - mean_iou: 0.847 - ETA: 50s - loss: 0.0661 - mean_iou: 0.847 - ETA: 46s - loss: 0.0667 - mean_iou: 0.847 - ETA: 43s - loss: 0.0676 - mean_iou: 0.847 - ETA: 39s - loss: 0.0675 - mean_iou: 0.847 - ETA: 35s - loss: 0.0677 - mean_iou: 0.847 - ETA: 31s - loss: 0.0672 - mean_iou: 0.847 - ETA: 28s - loss: 0.0683 - mean_iou: 0.847 - ETA: 24s - loss: 0.0686 - mean_iou: 0.847 - ETA: 20s - loss: 0.0682 - mean_iou: 0.847 - ETA: 16s - loss: 0.0684 - mean_iou: 0.847 - ETA: 13s - loss: 0.0676 - mean_iou: 0.847 - ETA: 9s - loss: 0.0688 - mean_iou: 0.847 - ETA: 5s - loss: 0.0686 - mean_iou: 0.84 - ETA: 1s - loss: 0.0687 - mean_iou: 0.8477Epoch 00022: val_loss did not improve\n",
      "536/536 [==============================] - 136s - loss: 0.0688 - mean_iou: 0.8477 - val_loss: 0.0641 - val_mean_iou: 0.8479\n",
      "Epoch 24/100\n",
      "528/536 [============================>.] - ETA: 119s - loss: 0.0755 - mean_iou: 0.84 - ETA: 115s - loss: 0.0774 - mean_iou: 0.84 - ETA: 111s - loss: 0.0728 - mean_iou: 0.84 - ETA: 108s - loss: 0.0694 - mean_iou: 0.84 - ETA: 104s - loss: 0.0677 - mean_iou: 0.84 - ETA: 100s - loss: 0.0676 - mean_iou: 0.84 - ETA: 96s - loss: 0.0684 - mean_iou: 0.8480 - ETA: 92s - loss: 0.0678 - mean_iou: 0.848 - ETA: 89s - loss: 0.0684 - mean_iou: 0.848 - ETA: 85s - loss: 0.0654 - mean_iou: 0.848 - ETA: 82s - loss: 0.0667 - mean_iou: 0.848 - ETA: 78s - loss: 0.0659 - mean_iou: 0.848 - ETA: 75s - loss: 0.0640 - mean_iou: 0.848 - ETA: 71s - loss: 0.0647 - mean_iou: 0.848 - ETA: 67s - loss: 0.0669 - mean_iou: 0.848 - ETA: 64s - loss: 0.0669 - mean_iou: 0.848 - ETA: 60s - loss: 0.0675 - mean_iou: 0.848 - ETA: 57s - loss: 0.0693 - mean_iou: 0.848 - ETA: 53s - loss: 0.0698 - mean_iou: 0.848 - ETA: 49s - loss: 0.0691 - mean_iou: 0.848 - ETA: 46s - loss: 0.0699 - mean_iou: 0.848 - ETA: 42s - loss: 0.0691 - mean_iou: 0.848 - ETA: 38s - loss: 0.0683 - mean_iou: 0.848 - ETA: 35s - loss: 0.0681 - mean_iou: 0.848 - ETA: 31s - loss: 0.0678 - mean_iou: 0.848 - ETA: 27s - loss: 0.0670 - mean_iou: 0.848 - ETA: 24s - loss: 0.0661 - mean_iou: 0.848 - ETA: 20s - loss: 0.0668 - mean_iou: 0.848 - ETA: 16s - loss: 0.0663 - mean_iou: 0.848 - ETA: 12s - loss: 0.0661 - mean_iou: 0.848 - ETA: 9s - loss: 0.0660 - mean_iou: 0.848 - ETA: 5s - loss: 0.0684 - mean_iou: 0.84 - ETA: 1s - loss: 0.0680 - mean_iou: 0.8482Epoch 00023: val_loss did not improve\n",
      "536/536 [==============================] - 136s - loss: 0.0681 - mean_iou: 0.8482 - val_loss: 0.0665 - val_mean_iou: 0.8485\n",
      "Epoch 25/100\n",
      "528/536 [============================>.] - ETA: 124s - loss: 0.0886 - mean_iou: 0.84 - ETA: 118s - loss: 0.0760 - mean_iou: 0.84 - ETA: 113s - loss: 0.0665 - mean_iou: 0.84 - ETA: 109s - loss: 0.0710 - mean_iou: 0.84 - ETA: 105s - loss: 0.0708 - mean_iou: 0.84 - ETA: 101s - loss: 0.0672 - mean_iou: 0.84 - ETA: 98s - loss: 0.0674 - mean_iou: 0.8486 - ETA: 94s - loss: 0.0731 - mean_iou: 0.848 - ETA: 90s - loss: 0.0704 - mean_iou: 0.848 - ETA: 87s - loss: 0.0707 - mean_iou: 0.848 - ETA: 83s - loss: 0.0694 - mean_iou: 0.848 - ETA: 79s - loss: 0.0678 - mean_iou: 0.848 - ETA: 76s - loss: 0.0668 - mean_iou: 0.848 - ETA: 72s - loss: 0.0668 - mean_iou: 0.848 - ETA: 69s - loss: 0.0670 - mean_iou: 0.848 - ETA: 65s - loss: 0.0694 - mean_iou: 0.848 - ETA: 61s - loss: 0.0694 - mean_iou: 0.848 - ETA: 57s - loss: 0.0688 - mean_iou: 0.848 - ETA: 53s - loss: 0.0672 - mean_iou: 0.848 - ETA: 50s - loss: 0.0675 - mean_iou: 0.848 - ETA: 46s - loss: 0.0688 - mean_iou: 0.848 - ETA: 42s - loss: 0.0680 - mean_iou: 0.848 - ETA: 39s - loss: 0.0681 - mean_iou: 0.848 - ETA: 35s - loss: 0.0671 - mean_iou: 0.848 - ETA: 31s - loss: 0.0663 - mean_iou: 0.848 - ETA: 27s - loss: 0.0658 - mean_iou: 0.848 - ETA: 24s - loss: 0.0667 - mean_iou: 0.848 - ETA: 20s - loss: 0.0677 - mean_iou: 0.848 - ETA: 16s - loss: 0.0670 - mean_iou: 0.848 - ETA: 13s - loss: 0.0674 - mean_iou: 0.848 - ETA: 9s - loss: 0.0678 - mean_iou: 0.848 - ETA: 5s - loss: 0.0683 - mean_iou: 0.84 - ETA: 1s - loss: 0.0686 - mean_iou: 0.8487Epoch 00024: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 136s - loss: 0.0683 - mean_iou: 0.8487 - val_loss: 0.0659 - val_mean_iou: 0.8490\n",
      "Epoch 26/100\n",
      "528/536 [============================>.] - ETA: 117s - loss: 0.0754 - mean_iou: 0.84 - ETA: 115s - loss: 0.0623 - mean_iou: 0.84 - ETA: 111s - loss: 0.0619 - mean_iou: 0.84 - ETA: 107s - loss: 0.0632 - mean_iou: 0.84 - ETA: 104s - loss: 0.0691 - mean_iou: 0.84 - ETA: 101s - loss: 0.0677 - mean_iou: 0.84 - ETA: 97s - loss: 0.0649 - mean_iou: 0.8491 - ETA: 94s - loss: 0.0645 - mean_iou: 0.849 - ETA: 90s - loss: 0.0644 - mean_iou: 0.849 - ETA: 87s - loss: 0.0634 - mean_iou: 0.849 - ETA: 83s - loss: 0.0616 - mean_iou: 0.849 - ETA: 79s - loss: 0.0632 - mean_iou: 0.849 - ETA: 76s - loss: 0.0651 - mean_iou: 0.849 - ETA: 72s - loss: 0.0642 - mean_iou: 0.849 - ETA: 68s - loss: 0.0655 - mean_iou: 0.849 - ETA: 64s - loss: 0.0664 - mean_iou: 0.849 - ETA: 61s - loss: 0.0683 - mean_iou: 0.849 - ETA: 57s - loss: 0.0692 - mean_iou: 0.849 - ETA: 53s - loss: 0.0695 - mean_iou: 0.849 - ETA: 49s - loss: 0.0692 - mean_iou: 0.849 - ETA: 46s - loss: 0.0693 - mean_iou: 0.849 - ETA: 42s - loss: 0.0688 - mean_iou: 0.849 - ETA: 38s - loss: 0.0686 - mean_iou: 0.849 - ETA: 35s - loss: 0.0679 - mean_iou: 0.849 - ETA: 31s - loss: 0.0685 - mean_iou: 0.849 - ETA: 27s - loss: 0.0690 - mean_iou: 0.849 - ETA: 24s - loss: 0.0688 - mean_iou: 0.849 - ETA: 20s - loss: 0.0690 - mean_iou: 0.849 - ETA: 16s - loss: 0.0688 - mean_iou: 0.849 - ETA: 12s - loss: 0.0683 - mean_iou: 0.849 - ETA: 9s - loss: 0.0673 - mean_iou: 0.849 - ETA: 5s - loss: 0.0668 - mean_iou: 0.84 - ETA: 1s - loss: 0.0680 - mean_iou: 0.8493Epoch 00025: val_loss did not improve\n",
      "536/536 [==============================] - 135s - loss: 0.0680 - mean_iou: 0.8493 - val_loss: 0.0654 - val_mean_iou: 0.8495\n",
      "Epoch 00025: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Fit model , #change epoch to [10, 20, 30, 50, 70]\n",
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model-dsbowl2018-ep-100.h5', verbose=1, save_best_only=True)\n",
    "results = model.fit(X_train, Y_train, validation_split=0.2, batch_size=16, epochs=100, \n",
    "                    callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1f381f5b-1b71-4daa-a417-e02f4894540b",
    "_uuid": "bb15226ea617cf91ed8f43179fccb5a15809e5a0"
   },
   "source": [
    "All right, looks good! Loss seems to be a bit erratic, though. I'll leave it to you to improve the model architecture and parameters! \n",
    "\n",
    "# Make predictions\n",
    "\n",
    "Let's make predictions both on the test set, the val set and the train set (as a sanity check). Remember to load the best saved model if you've used early stopping and checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "2daa48d5-ac98-4e18-af3f-a582baaa44f0",
    "_uuid": "f841760b4abca1a25cb750822f88268bd79bf2ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - ETA: 57 - ETA: 37 - ETA: 29 - ETA: 26 - ETA: 22 - ETA: 20 - ETA: 18 - ETA: 16 - ETA: 14 - ETA: 12 - ETA: 11 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 25s    \n",
      "67/67 [==============================] - ETA:  - ETA:  - 2s     \n",
      "65/65 [==============================] - ETA:  - ETA:  - 2s     \n"
     ]
    }
   ],
   "source": [
    "# Predict on train, val and test\n",
    "model = load_model('model-dsbowl2018-mode-simplecnn-ep-100.h5', custom_objects={'mean_iou': mean_iou})\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in range(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_cell_guid": "649248cd-a1fb-4da6-ade2-4bebad44bcab",
    "_uuid": "7e06242a50870e07a080064a4912b761775990fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sananand\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\skimage\\io\\_plugins\\matplotlib_plugin.py:51: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  out_of_range_float = (np.issubdtype(image.dtype, np.float) and\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASEAAAEYCAYAAAATaEB+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18136bf1710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASEAAAEYCAYAAAATaEB+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1813691b080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUQAAAEYCAYAAAAkpo9KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns8QB0cwscUA0M0scEM3Mkv8PLFSaEfY+upEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18133b0b0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform a sanity check on some random training samples\n",
    "ix = random.randint(0, len(preds_train_t))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_train_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "af602aea-5e56-42a8-9331-54b4b2650593",
    "_uuid": "5fcee2b9aee2fba5c60d43ad48a14139e9c1318c"
   },
   "source": [
    "The model is at least able to fit to the training data! Certainly a lot of room for improvement even here, but a decent start. How about the validation data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_cell_guid": "4f66b75c-c694-41a1-8c91-34bb6595837b",
    "_uuid": "d4ccbb559375bc2777ffb692a20adc313159f2cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sananand\\AppData\\Local\\Continuum\\miniconda3\\lib\\site-packages\\skimage\\io\\_plugins\\matplotlib_plugin.py:51: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  out_of_range_float = (np.issubdtype(image.dtype, np.float) and\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASEAAAEYCAYAAAATaEB+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnFHxQchxnFHxQchxnFHxQchxnFH5/844SgOJg860AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181340c1e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASEAAAEYCAYAAAATaEB+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4I51WgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181342cb588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUQAAAEYCAYAAAAkpo9KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncUA0M0scEM3MEgdEM7PEAdHMLPl/iFSh1dOb5SQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18133b16080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform a sanity check on some random validation samples\n",
    "ix = random.randint(0, len(preds_val_t))\n",
    "imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_val_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a6690535-b2e4-49ac-98d9-7191bfabfb6f",
    "_uuid": "6a34c98de7c6ae473f676a34fe7e099b46764eca"
   },
   "source": [
    "Not too shabby! Definitely needs some more training and tweaking.\n",
    "\n",
    "# Encode and submit our results\n",
    "\n",
    "Now it's time to submit our results. I've stolen [this](https://www.kaggle.com/rakhlin/fast-run-length-encoding-python) excellent implementation of run-length encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_cell_guid": "59a0af60-a7d7-41ef-a6fe-9e3c72defa07",
    "_uuid": "4f99c1bf852e82b60bd4f982ca0df293f712cdf0"
   },
   "outputs": [],
   "source": [
    "# Run-length encoding stolen from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\n",
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x, cutoff=0.5):\n",
    "    lab_img = label(x > cutoff)\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "31133f8c-3f40-4dff-8e1d-898d56672332",
    "_uuid": "2e07f6afc4787b068ba714428145dcb3951d718f"
   },
   "source": [
    "Let's iterate over the test IDs and generate run-length encodings for each seperate mask identified by skimage ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_cell_guid": "22fe24a1-7659-4cc9-9d23-211f38e5b99f",
    "_uuid": "089587843ed6a3955fdcb9b23a6ec3bf5d703688"
   },
   "outputs": [],
   "source": [
    "new_test_ids = []\n",
    "rles = []\n",
    "for n, id_ in enumerate(test_ids):\n",
    "    rle = list(prob_to_rles(preds_test_upsampled[n]))\n",
    "    rles.extend(rle)\n",
    "    new_test_ids.extend([id_] * len(rle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "20b6b627-0fd6-425d-888f-da7f39efb124",
    "_uuid": "849184a40a2c9c21506d8b8eb10ad9155fa229e8"
   },
   "source": [
    "... and then finally create our submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_cell_guid": "1ba0ee3a-cca0-4349-83f6-09a1ac6fcb44",
    "_uuid": "ba589f56f5be1e6886bc88f5bf9e7d0a408e4048"
   },
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "sub = pd.DataFrame()\n",
    "sub['ImageId'] = new_test_ids\n",
    "sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "sub.to_csv('sub-dsbowl2018-3rd.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "222475b9-3171-461a-90f0-a820a6bd2634",
    "_uuid": "fb5e6f8cca872f1bd7036f6d9ac2ed2cab615536",
    "collapsed": true
   },
   "source": [
    "###### This scored 0.226 on the LB for me.  - for the 1st submission \n",
    "\n",
    "\n",
    "You should easily be able to stabilize and improve the results just by changing a few parameters, tweaking the architecture a little bit and training longer with early stopping.\n",
    "\n",
    "**Have fun!**\n",
    "\n",
    "LB score history:\n",
    "- Version 7: 0.277 LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3f5e5a47-6133-4870-976a-a8e4fa7bf46c",
    "_uuid": "2a83eab66bf55194f300953bea5534b6a043130f",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
